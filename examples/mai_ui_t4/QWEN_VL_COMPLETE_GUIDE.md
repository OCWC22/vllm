# Qwen VL Complete Guide: Architecture, vLLM Optimization & MAI-UI

A comprehensive guide to running Qwen2-VL and Qwen3-VL models on vLLM across different GPU architectures (T4, A100, H100, B200), including the MAI-UI GUI agent application.

---

## Introduction

Qwen2-VL and Qwen3-VL are successive multimodal large language models from Alibaba's Qwen (Tongyi Qianwen) series, integrating vision and language capabilities. **Qwen2-VL (released 2024)** introduced dynamic image resolution handling and video understanding in a unified architecture. One year later, **Qwen3-VL (2025)** delivered comprehensive upgrades: stronger text and visual reasoning, a **256K token context** (vs ~16K in Qwen2-VL), and improved multimodal alignment.

This guide reviews their architectures and features, covering:
- **Vision encoders** and backbone integration
- **Positional encodings** (RoPE, M-RoPE, Interleaved-MRoPE)
- **Multimodal support** (images & video with DeepStack and Efficient Video Sampling)
- **Training/inference pipelines** (including GUI agent integration via MAI-UI)
- **Deployment recommendations** on various GPUs (T4, A100, H100, B200)
- **vLLM optimization** (PagedAttention, prefix caching, chunked prefill, FlashAttention)
- **Comparative analysis** of Qwen2-VL vs Qwen3-VL in capabilities, token handling, image resolution, model scales, and latency

---

## Table of Contents

1. [Quick Reference](#quick-reference)
2. [Vision-Language Architecture and Components](#vision-language-architecture-and-components)
   - Encoders and Backbone
   - Positional Encoding: RoPE and M-RoPE
   - MLP in Vision Pipeline: Dynamic Token Reduction
3. [How Vision-Language Models Work](#how-vision-language-models-work)
4. [Qwen2-VL vs Qwen3-VL Architecture](#qwen2-vl-vs-qwen3-vl-architecture)
5. [GPU Hardware Guide](#gpu-hardware-guide)
6. [vLLM Configuration Parameters](#vllm-configuration-parameters)
7. [MAI-UI: GUI Agents with Reinforcement Learning](#mai-ui-gui-agents-with-reinforcement-learning)
8. [Multimodal Support: Images, Video, and Advanced Mechanisms](#multimodal-support-images-video-and-advanced-mechanisms)
   - Unified Image & Video Pipeline
   - Efficient Video Sampling (EVS)
   - DeepStack: Multi-Level Vision Features
9. [Training and Inference Pipelines](#training-and-inference-pipelines)
   - Three-Stage Training Regimen
   - Inference Pipeline and vLLM Integration
10. [Complete Code Examples](#complete-code-examples)
11. [Comparative Analysis: Qwen2-VL vs Qwen3-VL](#comparative-analysis-qwen2-vl-vs-qwen3-vl)
    - Capability Improvements
    - Video Token Handling Comparison
    - Model Size and Architecture Comparison
    - Latency and Inference Performance
    - When to Choose Which Model
12. [Summary: Key Differences at a Glance](#summary-key-differences-at-a-glance)
13. [GPU Deployment Best Practices](#gpu-deployment-best-practices)
14. [References](#references)

---

## Quick Reference

### Model Selection Matrix

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ GPU                â”‚ VRAM         â”‚ Best Model     â”‚ Configuration                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ T4                 â”‚ 16 GB        â”‚ Qwen3-VL-4B    â”‚ 4-bit, FP16, 4K context, EVS        â”‚
â”‚ A100-40GB          â”‚ 40 GB        â”‚ Qwen3-VL-8B    â”‚ BF16, 16K context                   â”‚
â”‚ A100-80GB          â”‚ 80 GB        â”‚ Qwen3-VL-8B    â”‚ BF16, 32K context, prefix cache     â”‚
â”‚ H100               â”‚ 80 GB        â”‚ Qwen3-VL-8B    â”‚ FP8, 32K context, 32 concurrent     â”‚
â”‚ B200               â”‚ 192 GB       â”‚ Qwen3-VL-30B   â”‚ BF16, 128K context, 128 concurrent  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Key Architectural Differences

| Feature | Qwen2-VL | Qwen3-VL |
|---------|----------|----------|
| Position Encoding | 3D RoPE only | Learned + RoPE + Interpolation |
| MLP Activation | QuickGELU | SiLU |
| Multi-Scale Features | âŒ | âœ… DeepStack |
| Video Token Pruning | âŒ | âœ… EVS |
| Max Video Frames | 14 | 24,576 |
| Speculative Decoding | Basic | Eagle3 native |
| MoE Variants | âŒ | âœ… Qwen3-VL-30B-A3B |

---

## Vision-Language Architecture and Components

### Encoders and Backbone

Both Qwen2-VL and Qwen3-VL follow a two-part architecture: a **Vision Transformer (ViT)** as visual encoder feeding into a **transformer-based LLM decoder**.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              ENCODER-DECODER ARCHITECTURE                                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                                 â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚   â”‚       VISION ENCODER (ViT)        â”‚      â”‚              LLM DECODER                      â”‚ â”‚
â”‚   â”‚        ~675M parameters           â”‚      â”‚         (1.5B - 72B+ parameters)              â”‚ â”‚
â”‚   â”‚                                   â”‚      â”‚                                               â”‚ â”‚
â”‚   â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚      â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚ â”‚
â”‚   â”‚  â”‚  Patch Embedding (Conv3D)  â”‚  â”‚      â”‚  â”‚  Text Embedding Layer                   â”‚  â”‚ â”‚
â”‚   â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚      â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ â”‚
â”‚   â”‚                 â”‚                 â”‚      â”‚                     â”‚                         â”‚ â”‚
â”‚   â”‚                 â–¼                 â”‚      â”‚                     â–¼                         â”‚ â”‚
â”‚   â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚      â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚ â”‚
â”‚   â”‚  â”‚   Vision Transformer       â”‚  â”‚      â”‚  â”‚  [visual_tokens] + [text_tokens]        â”‚  â”‚ â”‚
â”‚   â”‚  â”‚   (32 attention layers)    â”‚  â”‚ â”€â”€â”€â”€â–ºâ”‚  â”‚       Concatenated sequence             â”‚  â”‚ â”‚
â”‚   â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚      â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ â”‚
â”‚   â”‚                 â”‚                 â”‚      â”‚                     â”‚                         â”‚ â”‚
â”‚   â”‚                 â–¼                 â”‚      â”‚                     â–¼                         â”‚ â”‚
â”‚   â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚      â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚ â”‚
â”‚   â”‚  â”‚   Patch Merger (MLP)       â”‚  â”‚      â”‚  â”‚  LLM Transformer Layers                 â”‚  â”‚ â”‚
â”‚   â”‚  â”‚   (Reduces token count)    â”‚  â”‚      â”‚  â”‚  (28-80 layers depending on size)       â”‚  â”‚ â”‚
â”‚   â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚      â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ â”‚
â”‚   â”‚                                   â”‚      â”‚                     â”‚                         â”‚ â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚                     â–¼                         â”‚ â”‚
â”‚                                              â”‚            Output: Generated Text             â”‚ â”‚
â”‚                                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Qwen2-VL** uses a ~675M-parameter ViT (vision encoder) across all model sizes:
- **Qwen2-VL-2B**: 675M ViT + 1.5B LLM = ~2.2B total parameters
- **Qwen2-VL-7B**: 675M ViT + 7.6B LLM = ~8.3B total parameters
- **Qwen2-VL-72B**: 675M ViT + 72B LLM = ~72.7B total parameters

**Qwen3-VL** upgrades the text backbone to the Qwen3 series with additional architectural innovations:
- Dense models: 2B, 4B, 8B, 32B
- MoE models: 30B-A3B (30B total, 3B active), 235B-A22B (235B total, 22B active)
- **DeepStack**: Fuses multi-level ViT features into the LLM at multiple layers
- Same vision encoder front-end, but with learned position embeddings + interpolation

### Positional Encoding: RoPE and M-RoPE

Qwen models use **Rotary Position Embeddings (RoPE)** to represent token positions. Qwen2-VL innovated **Multimodal RoPE (M-RoPE)** to handle 2D spatial and 3D temporal positions beyond 1D text.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              M-ROPE: MULTIMODAL ROTARY POSITION EMBEDDING                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                                 â”‚
â”‚  STANDARD 1D RoPE (Text Only):                                                                  â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                                                 â”‚
â”‚                                                                                                 â”‚
â”‚    Token:    [The]  [cat]  [sat]  [on]  [the]  [mat]                                           â”‚
â”‚    Position:   0      1      2     3      4      5                                              â”‚
â”‚                                                                                                 â”‚
â”‚    Each position gets a single rotation angle applied to embeddings.                           â”‚
â”‚                                                                                                 â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚                                                                                                 â”‚
â”‚  M-ROPE (Qwen2-VL): FACTORIZED INTO 3 COMPONENTS                                                â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                               â”‚
â”‚                                                                                                 â”‚
â”‚    For TEXT tokens: All three components use the same position index                           â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”‚
â”‚    â”‚  Temporal ID: 0  0  0  0  0  0                                      â”‚                     â”‚
â”‚    â”‚  Height ID:   0  1  2  3  4  5  (same as 1D position)              â”‚                     â”‚
â”‚    â”‚  Width ID:    0  1  2  3  4  5  (same as 1D position)              â”‚                     â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
â”‚    â†’ Reduces to normal 1D RoPE for text                                                        â”‚
â”‚                                                                                                 â”‚
â”‚    For IMAGE tokens: Constant temporal, varying height/width                                   â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”‚
â”‚    â”‚  Image patches in a 3Ã—3 grid:                                       â”‚                     â”‚
â”‚    â”‚                                                                      â”‚                     â”‚
â”‚    â”‚    Patch:      P00  P01  P02  P10  P11  P12  P20  P21  P22          â”‚                     â”‚
â”‚    â”‚    Temporal:    0    0    0    0    0    0    0    0    0           â”‚                     â”‚
â”‚    â”‚    Height:      0    0    0    1    1    1    2    2    2           â”‚                     â”‚
â”‚    â”‚    Width:       0    1    2    0    1    2    0    1    2           â”‚                     â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
â”‚    â†’ 2D spatial encoding for images                                                            â”‚
â”‚                                                                                                 â”‚
â”‚    For VIDEO tokens: Increasing temporal, varying height/width per frame                       â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”‚
â”‚    â”‚  Frame 0:     Temporal=0, Height=[0-H], Width=[0-W]                 â”‚                     â”‚
â”‚    â”‚  Frame 1:     Temporal=1, Height=[0-H], Width=[0-W]                 â”‚                     â”‚
â”‚    â”‚  Frame 2:     Temporal=2, Height=[0-H], Width=[0-W]                 â”‚                     â”‚
â”‚    â”‚  ...                                                                 â”‚                     â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
â”‚    â†’ 3D spatiotemporal encoding for videos                                                     â”‚
â”‚                                                                                                 â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚                                                                                                 â”‚
â”‚  INTERLEAVED M-ROPE (Qwen3-VL): FULL-FREQUENCY ALLOCATION                                       â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                      â”‚
â”‚                                                                                                 â”‚
â”‚    Enhancement: Distributes RoPE's frequency spectrum across all 3 axes                        â”‚
â”‚                                                                                                 â”‚
â”‚    Standard M-RoPE:   [freq_0-31: time] [freq_32-63: height] [freq_64-95: width]              â”‚
â”‚    Interleaved:       [freq interleaved across time, height, width uniformly]                 â”‚
â”‚                                                                                                 â”‚
â”‚    BENEFIT: All frequencies contribute across dimensions, mitigating single-axis dominance    â”‚
â”‚    RESULT: Improved video reasoning over long sequences                                        â”‚
â”‚                                                                                                 â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚                                                                                                 â”‚
â”‚  TEXT-TIMESTAMP ALIGNMENT (Qwen3-VL Only):                                                      â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                                      â”‚
â”‚                                                                                                 â”‚
â”‚    Instead of implicit temporal RoPE, Qwen3-VL injects explicit textual time tags:            â”‚
â”‚                                                                                                 â”‚
â”‚    [frame_0] <@ 0.0 seconds> [frame_1] <@ 0.5 seconds> [frame_2] <@ 1.0 seconds> ...          â”‚
â”‚                                                                                                 â”‚
â”‚    BENEFIT: More precise temporal grounding for video events                                   â”‚
â”‚    OUTPUT: Model can say "At <@ 5.0s>, a cat enters the scene"                                â”‚
â”‚                                                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Key Benefits of M-RoPE:**
- Position IDs for height/width remain much smaller than if the image were flattened
- Reduces position index magnitude, allowing extrapolation to longer sequences
- Qwen2-VL's 72B demonstrates robust length generalization on video inputs >16K tokens (~20 min video)

### MLP in Vision Pipeline: Dynamic Token Reduction

Both generations include an MLP component to reduce visual token length after the ViT encoder.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              NAIVE DYNAMIC RESOLUTION                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                                 â”‚
â”‚  PROBLEM: Prior LVLMs resized all images to 224Ã—224, losing detail in large images            â”‚
â”‚                                                                                                 â”‚
â”‚  SOLUTION: Process images at NATIVE resolution, then compress adaptively                       â”‚
â”‚                                                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Example Inputs and Their Token Counts:                                                  â”‚   â”‚
â”‚  â”‚                                                                                          â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚   â”‚
â”‚  â”‚  â”‚ Picture 1          â”‚  â”‚Picture 2 â”‚  â”‚  Picture 3   â”‚  â”‚  Video 1 (10s @ 2fps)      â”‚ â”‚   â”‚
â”‚  â”‚  â”‚ 8204Ã—1092          â”‚  â”‚ 28Ã—224   â”‚  â”‚  448Ã—448     â”‚  â”‚  20 frames Ã— 448Ã—448       â”‚ â”‚   â”‚
â”‚  â”‚  â”‚ (Tall webpage)     â”‚  â”‚ (Tiny)   â”‚  â”‚  (Standard)  â”‚  â”‚                            â”‚ â”‚   â”‚
â”‚  â”‚  â”‚                    â”‚  â”‚          â”‚  â”‚              â”‚  â”‚                            â”‚ â”‚   â”‚
â”‚  â”‚  â”‚ ViT: ~65K patches  â”‚  â”‚ ~4 ptch  â”‚  â”‚ ~1K patches  â”‚  â”‚  ~20K patches              â”‚ â”‚   â”‚
â”‚  â”‚  â”‚ After MLP: 11,427  â”‚  â”‚    8     â”‚  â”‚    256       â”‚  â”‚  5,000 tokens              â”‚ â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚   â”‚
â”‚  â”‚                                                                                          â”‚   â”‚
â”‚  â”‚  HIGH-RES = MORE TOKENS          LOW-RES = FEWER TOKENS                                 â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                                                 â”‚
â”‚  HOW IT WORKS:                                                                                  â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                                                                 â”‚
â”‚                                                                                                 â”‚
â”‚    1. ViT processes image at native resolution (patch size 14Ã—14)                              â”‚
â”‚    2. Produces patch sequence proportional to image size                                       â”‚
â”‚    3. MLP merges adjacent patches to reduce sequence length                                    â”‚
â”‚    4. Special tokens mark visual boundaries: <vision_start> ... <vision_end>                  â”‚
â”‚                                                                                                 â”‚
â”‚  QWEN3-VL ENHANCEMENT:                                                                          â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                                                          â”‚
â”‚                                                                                                 â”‚
â”‚    DeepStack means multi-scale information from early ViT layers is preserved:                â”‚
â”‚    â€¢ Early layers: Fine details (edges, textures, small text)                                 â”‚
â”‚    â€¢ Later layers: Semantic concepts (object types, relationships)                            â”‚
â”‚    â€¢ Both scales available to LLM â†’ Better fine-grained understanding                         â”‚
â”‚                                                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## How Vision-Language Models Work

### The Processing Pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           HOW A VISION-LANGUAGE MODEL PROCESSES AN IMAGE                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                                 â”‚
â”‚  STEP 1: IMAGE â†’ PATCHES                                                                        â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                                                        â”‚
â”‚                                                                                                 â”‚
â”‚   Original Image (1024Ã—1024)                                                                    â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                                â”‚
â”‚   â”‚                            â”‚       Split into 14Ã—14 pixel patches                           â”‚
â”‚   â”‚         ğŸ–¼ï¸                 â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º                         â”‚
â”‚   â”‚    Your Image Here         â”‚                                                                â”‚
â”‚   â”‚                            â”‚                                                                â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                                                â”‚
â”‚                                                                                                 â”‚
â”‚   Result: 73 Ã— 73 = 5,329 patches (each patch is 14Ã—14 pixels)                                  â”‚
â”‚                                                                                                 â”‚
â”‚  STEP 2: PATCHES â†’ EMBEDDINGS (Vision Encoder)                                                  â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                                  â”‚
â”‚                                                                                                 â”‚
â”‚   Each 14Ã—14 patch                  Conv3D                    Vision Transformer               â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”Œâ”€â”€â”€â”€â”€â”€â”                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚   â”‚ 14Ã—14Ã—3 pixels   â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º â”‚ Proj â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º â”‚ 32 layers of     â”‚               â”‚
â”‚   â”‚ = 588 numbers    â”‚             â””â”€â”€â”€â”€â”€â”€â”˜                  â”‚ Self-Attention   â”‚               â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             Output:                   â”‚ + MLP            â”‚               â”‚
â”‚                                    1152-dim vector           â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â”‚                                                                       â”‚                         â”‚
â”‚                                                                       â–¼                         â”‚
â”‚                                                              5,329 Ã— 1152-dim vectors           â”‚
â”‚                                                                                                 â”‚
â”‚  STEP 3: SPATIAL MERGING (Reduce Token Count)                                                   â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                                   â”‚
â”‚                                                                                                 â”‚
â”‚   5,329 tokens is too many! Merge 2Ã—2 patches into 1:                                           â”‚
â”‚                                                                                                 â”‚
â”‚   â”Œâ”€â”€â”€â”¬â”€â”€â”€â”                                                                                     â”‚
â”‚   â”‚ A â”‚ B â”‚                                                                                     â”‚
â”‚   â”œâ”€â”€â”€â”¼â”€â”€â”€â”¤  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º [A,B,C,D concatenated] â†’ MLP â†’ 1 merged token                    â”‚
â”‚   â”‚ C â”‚ D â”‚                                                                                     â”‚
â”‚   â””â”€â”€â”€â”´â”€â”€â”€â”˜                                                                                     â”‚
â”‚                                                                                                 â”‚
â”‚   Result: 5,329 Ã· 4 = 1,332 tokens (each is 3584-dim to match LLM)                              â”‚
â”‚                                                                                                 â”‚
â”‚  STEP 4: INJECT INTO LLM                                                                        â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                                                        â”‚
â”‚                                                                                                 â”‚
â”‚   Text prompt: "Describe this image <|image_pad|>"                                              â”‚
â”‚                                                                                                 â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚   â”‚  Token IDs:  [Describe] [this] [image] [img_0] [img_1] ... [img_1331]            â”‚         â”‚
â”‚   â”‚                   â†“        â†“      â†“       â†“       â†“           â†“                  â”‚         â”‚
â”‚   â”‚  Embeddings: [text_emb] [text] [text] [vis_0] [vis_1] ... [vis_1331]             â”‚         â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”‚                                           â”‚                                                     â”‚
â”‚                                           â–¼                                                     â”‚
â”‚                                     LLM Transformer                                             â”‚
â”‚                                     (28-80 layers)                                              â”‚
â”‚                                           â”‚                                                     â”‚
â”‚                                           â–¼                                                     â”‚
â”‚                                    Output: "This is a..."                                       â”‚
â”‚                                                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Token Count = Memory + Latency

```
Image Resolution    Patches    After 2Ã—2 Merge    Memory Impact
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
224 Ã— 224           16 Ã— 16    64 tokens          ~0.5 MB
512 Ã— 512           37 Ã— 37    342 tokens         ~2.5 MB
720 Ã— 720           51 Ã— 51    650 tokens         ~5 MB
1024 Ã— 1024         73 Ã— 73    1,332 tokens       ~10 MB
1920 Ã— 1080         137 Ã— 77   2,637 tokens       ~20 MB

More tokens = More memory = Longer processing time
```

---

## Qwen2-VL vs Qwen3-VL Architecture

### Component-by-Component Comparison Table

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    COMPONENT-BY-COMPONENT COMPARISON                                â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                                     â•‘
â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â•‘
â•‘  â”‚ Component            â”‚ Qwen2-VL                â”‚ Qwen3-VL                   â”‚   â•‘
â•‘  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â•‘
â•‘  â”‚ Patch Embedding      â”‚ Conv3D (no bias)        â”‚ Conv3D (WITH bias)         â”‚   â•‘
â•‘  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â•‘
â•‘  â”‚ Position Encoding    â”‚ 3D RoPE only            â”‚ Learned + RoPE + Interp    â”‚   â•‘
â•‘  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â•‘
â•‘  â”‚ MLP Activation       â”‚ QuickGELU               â”‚ SiLU (configurable)        â”‚   â•‘
â•‘  â”‚                      â”‚ x * Ïƒ(1.702x)           â”‚ x * Ïƒ(x)                   â”‚   â•‘
â•‘  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â•‘
â•‘  â”‚ MLP Bias             â”‚ Has bias                â”‚ No bias (linear_fc1/fc2)   â”‚   â•‘
â•‘  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â•‘
â•‘  â”‚ Feature Merging      â”‚ Single merger           â”‚ Main + DeepStack mergers   â”‚   â•‘
â•‘  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â•‘
â•‘  â”‚ Multi-Scale          â”‚ âŒ None                 â”‚ âœ… DeepStack               â”‚   â•‘
â•‘  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â•‘
â•‘  â”‚ Video Pruning        â”‚ âŒ None                 â”‚ âœ… EVS                     â”‚   â•‘
â•‘  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â•‘
â•‘  â”‚ Max Video Frames     â”‚ 14                      â”‚ 24,576                     â”‚   â•‘
â•‘  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â•‘
â•‘  â”‚ Attention Backend    â”‚ FA, SDPA, Xformers,     â”‚ FA, SDPA, ROCm only       â”‚   â•‘
â•‘  â”‚                      â”‚ ROCm, etc.              â”‚ (stricter requirement)     â”‚   â•‘
â•‘  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â•‘
â•‘  â”‚ Speculative Decode   â”‚ Basic                   â”‚ Eagle3 native support      â”‚   â•‘
â•‘  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â•‘
â•‘  â”‚ MoE Variants         â”‚ âŒ None                 â”‚ âœ… Qwen3-VL-30B-A3B        â”‚   â•‘
â•‘  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â•‘
â•‘  â”‚ LLM Backbone         â”‚ Qwen2ForCausalLM        â”‚ Qwen3LLMForCausalLM        â”‚   â•‘
â•‘  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â•‘
â•‘  â”‚ Torch Compile        â”‚ Limited                 â”‚ Decorated support          â”‚   â•‘
â•‘  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â•‘
â•‘                                                                                     â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

### High-Level Comparison

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    QWEN VISION-LANGUAGE MODEL EVOLUTION                               â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                                       â•‘
â•‘   QWEN2-VL (Late 2024)                    QWEN3-VL (2025)                             â•‘
â•‘   â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                      â•â•â•â•â•â•â•â•â•â•â•â•â•â•                              â•‘
â•‘                                                                                       â•‘
â•‘   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â•‘
â•‘   â”‚    Image/Video      â”‚                 â”‚    Image/Video      â”‚                     â•‘
â•‘   â”‚      Inputs         â”‚                 â”‚      Inputs         â”‚                     â•‘
â•‘   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â•‘
â•‘              â”‚                                       â”‚                                â•‘
â•‘              â–¼                                       â–¼                                â•‘
â•‘   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â•‘
â•‘   â”‚  Conv3D Patch Embed â”‚                 â”‚ Conv3D Patch Embed  â”‚                     â•‘
â•‘   â”‚    (no bias)        â”‚                 â”‚   (WITH bias)       â”‚                     â•‘
â•‘   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â•‘
â•‘              â”‚                                       â”‚                                â•‘
â•‘              â”‚                            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â•‘
â•‘              â”‚                            â”‚  Learned Position   â”‚                     â•‘
â•‘              â”‚                            â”‚  Embed + Interpolateâ”‚                     â•‘
â•‘              â”‚                            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â•‘
â•‘              â”‚                                       â”‚                                â•‘
â•‘              â–¼                                       â–¼                                â•‘
â•‘   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â•‘
â•‘   â”‚   Vision Blocks     â”‚                 â”‚   Vision Blocks     â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”            â•‘
â•‘   â”‚   (N layers)        â”‚                 â”‚   (N layers)        â”‚        â”‚            â•‘
â•‘   â”‚   QuickGELU         â”‚                 â”‚   SiLU activation   â”‚        â–¼            â•‘
â•‘   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  DeepStack          â•‘
â•‘              â”‚                                       â”‚             Mergers            â•‘
â•‘              â–¼                                       â–¼               â”‚                â•‘
â•‘   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚                â•‘
â•‘   â”‚   Single Merger     â”‚                 â”‚   Main Merger       â”‚â—„â”€â”€â”€â”˜                â•‘
â•‘   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â•‘
â•‘              â”‚                                       â”‚                                â•‘
â•‘              â–¼                                       â–¼                                â•‘
â•‘   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â•‘
â•‘   â”‚    Qwen2 LLM        â”‚                 â”‚    Qwen3 LLM        â”‚                     â•‘
â•‘   â”‚  (Qwen2ForCausalLM) â”‚                 â”‚ (DeepStack inject)  â”‚                     â•‘
â•‘   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â•‘
â•‘                                                                                       â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

### Qwen2-VL Vision Encoder Pipeline (Detailed)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          QWEN2-VL VISION ENCODER                                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                     â”‚
â”‚  INPUT: Image (H Ã— W Ã— 3) or Video (T Ã— H Ã— W Ã— 3)                                  â”‚
â”‚                                                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  STEP 1: PATCH EMBEDDING (Qwen2VisionPatchEmbed)                            â”‚   â”‚
â”‚  â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                            â”‚   â”‚
â”‚  â”‚                                                                             â”‚   â”‚
â”‚  â”‚    Input: (L, C) where C = 3 Ã— temporal_patch Ã— patchÂ² = 3 Ã— 2 Ã— 14Â² = 1176â”‚   â”‚
â”‚  â”‚                                                                             â”‚   â”‚
â”‚  â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚   â”‚
â”‚  â”‚    â”‚  Conv3D(in=3, out=embed_dim, kernel=(2,14,14))         â”‚             â”‚   â”‚
â”‚  â”‚    â”‚  **NO BIAS** (bias=False)                               â”‚             â”‚   â”‚
â”‚  â”‚    â”‚         â”‚                                               â”‚             â”‚   â”‚
â”‚  â”‚    â”‚         â–¼                                               â”‚             â”‚   â”‚
â”‚  â”‚    â”‚  Reshape: (L, embed_dim) = (L, 1152)                   â”‚             â”‚   â”‚
â”‚  â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚   â”‚
â”‚  â”‚                                                                             â”‚   â”‚
â”‚  â”‚    Output: (num_patches, 1152)                                              â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  STEP 2: ROTARY POSITION EMBEDDING (3D RoPE)                                â”‚   â”‚
â”‚  â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                â”‚   â”‚
â”‚  â”‚                                                                             â”‚   â”‚
â”‚  â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                             â”‚   â”‚
â”‚  â”‚    â”‚ h_pos_idsâ”‚    â”‚ w_pos_idsâ”‚  â† Computed from grid_thw                   â”‚   â”‚
â”‚  â”‚    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜                                             â”‚   â”‚
â”‚  â”‚         â”‚               â”‚                                                    â”‚   â”‚
â”‚  â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                                                    â”‚   â”‚
â”‚  â”‚                 â–¼                                                            â”‚   â”‚
â”‚  â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚   â”‚
â”‚  â”‚    â”‚  cos, sin = rotary_pos_emb.get_cos_sin(max_grid_size)  â”‚             â”‚   â”‚
â”‚  â”‚    â”‚  cos_combined = cos[pos_ids].flatten(1)                 â”‚             â”‚   â”‚
â”‚  â”‚    â”‚  sin_combined = sin[pos_ids].flatten(1)                 â”‚             â”‚   â”‚
â”‚  â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚   â”‚
â”‚  â”‚                                                                             â”‚   â”‚
â”‚  â”‚    RoPE applies FULL rotation to Q and K (no partial_rotary_factor)        â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  STEP 3: VISION TRANSFORMER BLOCKS Ã— N (Qwen2VisionBlock)                   â”‚   â”‚
â”‚  â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                    â”‚   â”‚
â”‚  â”‚                                                                             â”‚   â”‚
â”‚  â”‚    for each block in self.blocks:                                           â”‚   â”‚
â”‚  â”‚                                                                             â”‚   â”‚
â”‚  â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚   â”‚
â”‚  â”‚    â”‚  x                                                             â”‚      â”‚   â”‚
â”‚  â”‚    â”‚  â”‚                                                             â”‚      â”‚   â”‚
â”‚  â”‚    â”‚  â”œâ”€â”€â–¶ LayerNorm â”€â”€â–¶ Attention â”€â”€â–¶ Add â”€â”                       â”‚      â”‚   â”‚
â”‚  â”‚    â”‚  â”‚    (eps=1e-6)    (with RoPE)        â”‚                       â”‚      â”‚   â”‚
â”‚  â”‚    â”‚  â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â”‚      â”‚   â”‚
â”‚  â”‚    â”‚  â”‚                                                             â”‚      â”‚   â”‚
â”‚  â”‚    â”‚  â”œâ”€â”€â–¶ LayerNorm â”€â”€â–¶ MLP â”€â”€â–¶ Add â”€â”€â”€â”€â”€â”€â”€â”                       â”‚      â”‚   â”‚
â”‚  â”‚    â”‚  â”‚    (eps=1e-6)    (QuickGELU)        â”‚                       â”‚      â”‚   â”‚
â”‚  â”‚    â”‚  â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â”‚      â”‚   â”‚
â”‚  â”‚    â”‚  â”‚                                                             â”‚      â”‚   â”‚
â”‚  â”‚    â”‚  â–¼                                                             â”‚      â”‚   â”‚
â”‚  â”‚    â”‚  x (updated)                                                   â”‚      â”‚   â”‚
â”‚  â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚   â”‚
â”‚  â”‚                                                                             â”‚   â”‚
â”‚  â”‚    MLP Structure (Qwen2-VL):                                                â”‚   â”‚
â”‚  â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚   â”‚
â”‚  â”‚    â”‚  fc1: Linear(embed_dim, embed_dim * mlp_ratio, bias=True)    â”‚       â”‚   â”‚
â”‚  â”‚    â”‚  act: QuickGELU = x * sigmoid(1.702 * x)                      â”‚       â”‚   â”‚
â”‚  â”‚    â”‚  fc2: Linear(embed_dim * mlp_ratio, embed_dim, bias=True)    â”‚       â”‚   â”‚
â”‚  â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  STEP 4: PATCH MERGER (Qwen2VisionPatchMerger)                              â”‚   â”‚
â”‚  â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                â”‚   â”‚
â”‚  â”‚                                                                             â”‚   â”‚
â”‚  â”‚    spatial_merge_size = 2 â†’ Merge 2Ã—2 patches into 1                        â”‚   â”‚
â”‚  â”‚                                                                             â”‚   â”‚
â”‚  â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚   â”‚
â”‚  â”‚    â”‚  ln_q: LayerNorm(embed_dim)                                   â”‚       â”‚   â”‚
â”‚  â”‚    â”‚        â”‚                                                       â”‚       â”‚   â”‚
â”‚  â”‚    â”‚        â–¼                                                       â”‚       â”‚   â”‚
â”‚  â”‚    â”‚  reshape: (N, embed_dim) â†’ (N/4, embed_dim Ã— 4)               â”‚       â”‚   â”‚
â”‚  â”‚    â”‚        â”‚                                                       â”‚       â”‚   â”‚
â”‚  â”‚    â”‚        â–¼                                                       â”‚       â”‚   â”‚
â”‚  â”‚    â”‚  mlp[0]: Linear(embed_dim Ã— 4, embed_dim Ã— 4)                 â”‚       â”‚   â”‚
â”‚  â”‚    â”‚  mlp[1]: GELU()                                                â”‚       â”‚   â”‚
â”‚  â”‚    â”‚  mlp[2]: Linear(embed_dim Ã— 4, hidden_size)                   â”‚       â”‚   â”‚
â”‚  â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚   â”‚
â”‚  â”‚                                                                             â”‚   â”‚
â”‚  â”‚    Output: (num_patches / 4, hidden_size) = merged visual tokens            â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                                     â”‚
â”‚  OUTPUT: Visual embeddings ready for LLM integration                               â”‚
â”‚                                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Qwen3-VL Vision Encoder Pipeline (Detailed)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          QWEN3-VL VISION ENCODER                                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                     â”‚
â”‚  INPUT: Image (H Ã— W Ã— 3) or Video (T Ã— H Ã— W Ã— 3)                                  â”‚
â”‚                                                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  STEP 1: PATCH EMBEDDING (Qwen3_VisionPatchEmbed)                           â”‚   â”‚
â”‚  â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                             â”‚   â”‚
â”‚  â”‚                                                                             â”‚   â”‚
â”‚  â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚   â”‚
â”‚  â”‚    â”‚  Conv3D(in=3, out=hidden_size, kernel=(2,14,14))       â”‚             â”‚   â”‚
â”‚  â”‚    â”‚  **WITH BIAS** (bias=True) â—„â”€â”€ KEY DIFFERENCE          â”‚             â”‚   â”‚
â”‚  â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚   â”‚
â”‚  â”‚                                                                             â”‚   â”‚
â”‚  â”‚    The bias allows the model to learn per-channel offsets,                 â”‚   â”‚
â”‚  â”‚    improving representation flexibility                                     â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  STEP 2: LEARNED POSITION EMBEDDING + INTERPOLATION                         â”‚   â”‚
â”‚  â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                      â”‚   â”‚
â”‚  â”‚  **NEW IN QWEN3-VL** - Replaces simple 3D RoPE                              â”‚   â”‚
â”‚  â”‚                                                                             â”‚   â”‚
â”‚  â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚   â”‚
â”‚  â”‚    â”‚  pos_embed = nn.Embedding(num_pos_embeddings, hidden)   â”‚             â”‚   â”‚
â”‚  â”‚    â”‚                                                          â”‚             â”‚   â”‚
â”‚  â”‚    â”‚  BILINEAR INTERPOLATION for variable resolutions:       â”‚             â”‚   â”‚
â”‚  â”‚    â”‚                                                          â”‚             â”‚   â”‚
â”‚  â”‚    â”‚  for each (t, h, w) in grid_thw:                        â”‚             â”‚   â”‚
â”‚  â”‚    â”‚    h_idxs = linspace(0, num_grid-1, h)                  â”‚             â”‚   â”‚
â”‚  â”‚    â”‚    w_idxs = linspace(0, num_grid-1, w)                  â”‚             â”‚   â”‚
â”‚  â”‚    â”‚                                                          â”‚             â”‚   â”‚
â”‚  â”‚    â”‚    # Get 4 corner positions                              â”‚             â”‚   â”‚
â”‚  â”‚    â”‚    h_floor, h_ceil = floor(h_idxs), ceil(h_idxs)        â”‚             â”‚   â”‚
â”‚  â”‚    â”‚    w_floor, w_ceil = floor(w_idxs), ceil(w_idxs)        â”‚             â”‚   â”‚
â”‚  â”‚    â”‚                                                          â”‚             â”‚   â”‚
â”‚  â”‚    â”‚    # Bilinear weights                                    â”‚             â”‚   â”‚
â”‚  â”‚    â”‚    dh = h_idxs - h_floor                                â”‚             â”‚   â”‚
â”‚  â”‚    â”‚    dw = w_idxs - w_floor                                â”‚             â”‚   â”‚
â”‚  â”‚    â”‚    w00 = (1 - dh) * (1 - dw)                            â”‚             â”‚   â”‚
â”‚  â”‚    â”‚    w01 = (1 - dh) * dw                                  â”‚             â”‚   â”‚
â”‚  â”‚    â”‚    w10 = dh * (1 - dw)                                  â”‚             â”‚   â”‚
â”‚  â”‚    â”‚    w11 = dh * dw                                        â”‚             â”‚   â”‚
â”‚  â”‚    â”‚                                                          â”‚             â”‚   â”‚
â”‚  â”‚    â”‚    # Interpolated embedding                              â”‚             â”‚   â”‚
â”‚  â”‚    â”‚    embeds = w00*E[h0,w0] + w01*E[h0,w1]                 â”‚             â”‚   â”‚
â”‚  â”‚    â”‚           + w10*E[h1,w0] + w11*E[h1,w1]                 â”‚             â”‚   â”‚
â”‚  â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚   â”‚
â”‚  â”‚                                                                             â”‚   â”‚
â”‚  â”‚    hidden_states = patch_embed + interpolated_pos_embed                     â”‚   â”‚
â”‚  â”‚                                                                             â”‚   â”‚
â”‚  â”‚    BENEFIT: Handles arbitrary resolutions without retraining!               â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  STEP 3: VISION TRANSFORMER BLOCKS + DEEPSTACK EXTRACTION                   â”‚   â”‚
â”‚  â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                    â”‚   â”‚
â”‚  â”‚                                                                             â”‚   â”‚
â”‚  â”‚    deepstack_visual_indexes = [layer_k, layer_m, ...]  # e.g., [8, 16, 24] â”‚   â”‚
â”‚  â”‚                                                                             â”‚   â”‚
â”‚  â”‚    for layer_num, block in enumerate(self.blocks):                          â”‚   â”‚
â”‚  â”‚                                                                             â”‚   â”‚
â”‚  â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚   â”‚
â”‚  â”‚    â”‚  hidden = block(hidden, cu_seqlens, cos, sin, max_seqlen)      â”‚      â”‚   â”‚
â”‚  â”‚    â”‚                                                                 â”‚      â”‚   â”‚
â”‚  â”‚    â”‚  if layer_num in deepstack_visual_indexes:                     â”‚      â”‚   â”‚
â”‚  â”‚    â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚      â”‚   â”‚
â”‚  â”‚    â”‚    â”‚  deepstack_feature = deepstack_merger[idx](hidden)    â”‚   â”‚      â”‚   â”‚
â”‚  â”‚    â”‚    â”‚  deepstack_features.append(deepstack_feature)         â”‚   â”‚      â”‚   â”‚
â”‚  â”‚    â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚      â”‚   â”‚
â”‚  â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚   â”‚
â”‚  â”‚                                                                             â”‚   â”‚
â”‚  â”‚    Block Structure (Qwen3-VL, different from Qwen2-VL):                     â”‚   â”‚
â”‚  â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚   â”‚
â”‚  â”‚    â”‚  MLP:                                                         â”‚       â”‚   â”‚
â”‚  â”‚    â”‚    linear_fc1: Linear(dim, mlp_hidden_dim, bias=False)       â”‚       â”‚   â”‚
â”‚  â”‚    â”‚    act_fn: SiLU = x * sigmoid(x)  â—„â”€â”€ Different from QuickGELUâ”‚       â”‚   â”‚
â”‚  â”‚    â”‚    linear_fc2: Linear(mlp_hidden_dim, dim, bias=False)       â”‚       â”‚   â”‚
â”‚  â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚   â”‚
â”‚  â”‚                                                                             â”‚   â”‚
â”‚  â”‚    RoPE: partial_rotary_factor=0.5 (only 50% of dims rotated)              â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  STEP 4: MULTI-SCALE FEATURE MERGING                                        â”‚   â”‚
â”‚  â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                       â”‚   â”‚
â”‚  â”‚                                                                             â”‚   â”‚
â”‚  â”‚    # Main merger (similar to Qwen2-VL)                                      â”‚   â”‚
â”‚  â”‚    main_features = self.merger(hidden_states)                               â”‚   â”‚
â”‚  â”‚                                                                             â”‚   â”‚
â”‚  â”‚    # Concatenate with DeepStack features                                    â”‚   â”‚
â”‚  â”‚    output = torch.cat([main_features] + deepstack_features, dim=1)          â”‚   â”‚
â”‚  â”‚                                                                             â”‚   â”‚
â”‚  â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚   â”‚
â”‚  â”‚    â”‚  OUTPUT SHAPE:                                                  â”‚     â”‚   â”‚
â”‚  â”‚    â”‚  (seq_len, hidden_size * (1 + num_deepstack_levels))            â”‚     â”‚   â”‚
â”‚  â”‚    â”‚                                                                  â”‚     â”‚   â”‚
â”‚  â”‚    â”‚  Example: if hidden_size=3584 and 3 deepstack levels:           â”‚     â”‚   â”‚
â”‚  â”‚    â”‚  (seq_len, 3584 * 4) = (seq_len, 14336)                         â”‚     â”‚   â”‚
â”‚  â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### DeepStack Injection into LLM Layers

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     QWEN3-VL DEEPSTACK LLM INTEGRATION                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                     â”‚
â”‚  Vision Output: [main_emb | ds_emb_0 | ds_emb_1 | ds_emb_2]                         â”‚
â”‚                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â”‚
â”‚                                   â”‚                                                 â”‚
â”‚                                   â–¼                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  SPLIT INTO COMPONENTS:                                                     â”‚   â”‚
â”‚  â”‚                                                                             â”‚   â”‚
â”‚  â”‚  multimodal_embeddings_main = output[:, :visual_dim]                        â”‚   â”‚
â”‚  â”‚  multimodal_embeddings_multiscale = output[:, visual_dim:]                  â”‚   â”‚
â”‚  â”‚                                                                             â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                   â”‚                                                 â”‚
â”‚                                   â–¼                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  COMPUTE DEEPSTACK INPUT EMBEDS:                                            â”‚   â”‚
â”‚  â”‚                                                                             â”‚   â”‚
â”‚  â”‚  deepstack_input_embeds = zeros(seq_len, num_levels * hidden_size)          â”‚   â”‚
â”‚  â”‚                                                                             â”‚   â”‚
â”‚  â”‚  # Merge multiscale features at multimodal positions                        â”‚   â”‚
â”‚  â”‚  deepstack_input_embeds[is_multimodal] = multimodal_embeddings_multiscale   â”‚   â”‚
â”‚  â”‚                                                                             â”‚   â”‚
â”‚  â”‚  # Reshape for per-layer injection                                          â”‚   â”‚
â”‚  â”‚  deepstack_input_embeds = reshape(seq_len, num_levels, visual_dim)          â”‚   â”‚
â”‚  â”‚  deepstack_input_embeds = permute(num_levels, seq_len, visual_dim)          â”‚   â”‚
â”‚  â”‚                                                                             â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                   â”‚                                                 â”‚
â”‚                                   â–¼                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  LLM FORWARD WITH DEEPSTACK INJECTION (Qwen3LLMModel):                      â”‚   â”‚
â”‚  â”‚                                                                             â”‚   â”‚
â”‚  â”‚  for layer_idx, layer in enumerate(self.layers):                            â”‚   â”‚
â”‚  â”‚      hidden_states, residual = layer(positions, hidden_states, residual)    â”‚   â”‚
â”‚  â”‚                                                                             â”‚   â”‚
â”‚  â”‚      if layer_idx < len(deepstack_input_embeds):                            â”‚   â”‚
â”‚  â”‚          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚   â”‚
â”‚  â”‚          â”‚  # ADD deepstack features to hidden states                   â”‚  â”‚   â”‚
â”‚  â”‚          â”‚  hidden_states = hidden_states +                              â”‚  â”‚   â”‚
â”‚  â”‚          â”‚                  deepstack_input_embeds[layer_idx]            â”‚  â”‚   â”‚
â”‚  â”‚          â”‚                                                               â”‚  â”‚   â”‚
â”‚  â”‚          â”‚  This injects multi-scale visual features into EARLY layers! â”‚  â”‚   â”‚
â”‚  â”‚          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚   â”‚
â”‚  â”‚                                                                             â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                                     â”‚
â”‚  VISUALIZATION:                                                                     â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                                                     â”‚
â”‚                                                                                     â”‚
â”‚  Layer 0:  hidden + ds_emb_0 (edge/texture features from Vision Layer 8)           â”‚
â”‚  Layer 1:  hidden + ds_emb_1 (shape features from Vision Layer 16)                 â”‚
â”‚  Layer 2:  hidden + ds_emb_2 (pattern features from Vision Layer 24)               â”‚
â”‚  Layer 3+: hidden only (no more DeepStack injection)                               â”‚
â”‚                                                                                     â”‚
â”‚  BENEFIT: Multi-scale visual features are available throughout the LLM,            â”‚
â”‚           not just at the embedding level. Improves fine-grained understanding!    â”‚
â”‚                                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Attention Mechanism Comparison

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      VISION ATTENTION COMPARISON                                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                     â”‚
â”‚  QWEN2-VL ATTENTION:                                                                â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                                                â”‚
â”‚                                                                                     â”‚
â”‚    Input: x (seq_len, batch, embed_dim)                                             â”‚
â”‚                                                                                     â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚    â”‚  1. QKV Projection                                                        â”‚   â”‚
â”‚    â”‚     qkv = Linear(embed_dim, 3 * embed_dim)(x)                             â”‚   â”‚
â”‚    â”‚                                                                           â”‚   â”‚
â”‚    â”‚  2. Split into Q, K, V                                                    â”‚   â”‚
â”‚    â”‚     q, k, v = qkv.chunk(3, dim=-1)                                        â”‚   â”‚
â”‚    â”‚     Reshape: (seq, batch, num_heads, head_dim)                            â”‚   â”‚
â”‚    â”‚                                                                           â”‚   â”‚
â”‚    â”‚  3. Apply Rotary Embedding (FULL ROTATION)                                â”‚   â”‚
â”‚    â”‚     qk = cat([q, k], dim=0)                                               â”‚   â”‚
â”‚    â”‚     qk_rotated = apply_rotary_emb(qk, cos, sin)  # 100% of dims          â”‚   â”‚
â”‚    â”‚     q, k = qk_rotated.chunk(2, dim=0)                                     â”‚   â”‚
â”‚    â”‚                                                                           â”‚   â”‚
â”‚    â”‚  4. Compute Attention                                                     â”‚   â”‚
â”‚    â”‚     out = attention(q, k, v)                                              â”‚   â”‚
â”‚    â”‚                                                                           â”‚   â”‚
â”‚    â”‚  5. Output Projection                                                     â”‚   â”‚
â”‚    â”‚     out = Linear(embed_dim, embed_dim)(out)                               â”‚   â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                                     â”‚
â”‚  QWEN3-VL ATTENTION:                                                                â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                                                â”‚
â”‚                                                                                     â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚    â”‚  Same as Qwen2-VL EXCEPT:                                                 â”‚   â”‚
â”‚    â”‚                                                                           â”‚   â”‚
â”‚    â”‚  3. Apply Rotary Embedding (PARTIAL ROTATION)                             â”‚   â”‚
â”‚    â”‚     partial_rotary_factor = 0.5  # Only 50% of dims rotated              â”‚   â”‚
â”‚    â”‚                                                                           â”‚   â”‚
â”‚    â”‚     rotary_dims = head_dim * 0.5                                          â”‚   â”‚
â”‚    â”‚     q_rot, q_pass = q.split([rotary_dims, head_dim-rotary_dims], dim=-1)  â”‚   â”‚
â”‚    â”‚     k_rot, k_pass = k.split([rotary_dims, head_dim-rotary_dims], dim=-1)  â”‚   â”‚
â”‚    â”‚                                                                           â”‚   â”‚
â”‚    â”‚     q_rot = apply_rotary_emb(q_rot, cos, sin)                             â”‚   â”‚
â”‚    â”‚     k_rot = apply_rotary_emb(k_rot, cos, sin)                             â”‚   â”‚
â”‚    â”‚                                                                           â”‚   â”‚
â”‚    â”‚     q = cat([q_rot, q_pass], dim=-1)  # Combine rotated + non-rotated    â”‚   â”‚
â”‚    â”‚     k = cat([k_rot, k_pass], dim=-1)                                      â”‚   â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                                     â”‚
â”‚  SUPPORTED BACKENDS:                                                                â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                                                â”‚
â”‚                                                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚ Backend            â”‚ GPU Require â”‚ Notes                                  â”‚     â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤     â”‚
â”‚  â”‚ FLASH_ATTN         â”‚ SM â‰¥ 8.0    â”‚ Fastest, A100+                         â”‚     â”‚
â”‚  â”‚ TORCH_SDPA         â”‚ Any         â”‚ Universal fallback, T4 compatible      â”‚     â”‚
â”‚  â”‚ XFORMERS           â”‚ SM â‰¥ 7.0    â”‚ Qwen2-VL only                          â”‚     â”‚
â”‚  â”‚ ROCM_AITER_FA      â”‚ AMD GPUs    â”‚ ROCm support                           â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### DeepStack Multi-Scale Features (Qwen3-VL Only)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              DEEPSTACK EXPLAINED                                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                                 â”‚
â”‚  PROBLEM: Standard vision encoders only output FINAL layer features                            â”‚
â”‚           Early layers have edge/texture info that gets lost!                                  â”‚
â”‚                                                                                                 â”‚
â”‚  SOLUTION: DeepStack extracts features at MULTIPLE layers                                       â”‚
â”‚                                                                                                 â”‚
â”‚   Vision Transformer Layers:                                                                    â”‚
â”‚   â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                                                     â”‚
â”‚                                                                                                 â”‚
â”‚   Layer 0  â”€â”€â–º ... â”€â”€â–º Layer 8  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º DeepStack Merger 0 â”€â”€â”€â”€â”€â”              â”‚
â”‚                           â”‚                                                       â”‚              â”‚
â”‚                           â–¼                                                       â”‚              â”‚
â”‚   Layer 9  â”€â”€â–º ... â”€â”€â–º Layer 16 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º DeepStack Merger 1 â”€â”€â”  â”‚              â”‚
â”‚                           â”‚                                                   â”‚  â”‚              â”‚
â”‚                           â–¼                                                   â”‚  â”‚              â”‚
â”‚   Layer 17 â”€â”€â–º ... â”€â”€â–º Layer 24 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º DeepStack Merger 2 â”€â”â”‚  â”‚              â”‚
â”‚                           â”‚                                                  â”‚â”‚  â”‚              â”‚
â”‚                           â–¼                                                  â–¼â–¼  â–¼              â”‚
â”‚   Layer 25 â”€â”€â–º ... â”€â”€â–º Layer 32 â”€â”€â–º Main Merger â”€â”€â”€â”€â”€â”€â–º [Main | DS0 | DS1 | DS2]               â”‚
â”‚                                                                   â”‚                             â”‚
â”‚                                                                   â–¼                             â”‚
â”‚                                         Concatenated output sent to LLM                         â”‚
â”‚                                                                                                 â”‚
â”‚  BENEFIT FOR GUI AGENTS:                                                                        â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                                                        â”‚
â”‚  â€¢ Layer 8 features: Button borders, icon edges                                                â”‚
â”‚  â€¢ Layer 16 features: UI component shapes                                                       â”‚
â”‚  â€¢ Layer 24 features: Widget patterns                                                          â”‚
â”‚  â€¢ Layer 32 features: Semantic understanding ("Settings button")                               â”‚
â”‚                                                                                                 â”‚
â”‚  All scales available to LLM â†’ Better at finding small UI elements!                            â”‚
â”‚                                                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### EVS: Efficient Video Sampling (Qwen3-VL Only)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              EVS EXPLAINED                                                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                                 â”‚
â”‚  PROBLEM: Long videos = Too many tokens = Out of memory!                                        â”‚
â”‚                                                                                                 â”‚
â”‚  100-frame video Ã— 160 tokens/frame = 16,000 tokens = HUGE memory                               â”‚
â”‚                                                                                                 â”‚
â”‚  SOLUTION: Content-aware pruning of SIMILAR frames                                              â”‚
â”‚                                                                                                 â”‚
â”‚   WITHOUT EVS (Qwen2-VL):                                                                       â”‚
â”‚   Frame 1 â–ˆâ–ˆ Frame 2 â–ˆâ–ˆ Frame 3 â–ˆâ–ˆ Frame 4 â–ˆâ–ˆ ... Frame 100 â–ˆâ–ˆ                                  â”‚
â”‚   ALL tokens sent to LLM â†’ 16,000 tokens â†’ OOM on T4!                                           â”‚
â”‚                                                                                                 â”‚
â”‚   WITH EVS (Qwen3-VL, video_pruning_rate=0.5):                                                  â”‚
â”‚   Frame 1 â–ˆâ–ˆ Frame 2 â–‘â–‘ Frame 3 â–ˆâ–ˆ Frame 4 â–‘â–‘ ... Frame 100 â–ˆâ–ˆ                                  â”‚
â”‚   ONLY different frames kept â†’ 8,000 tokens â†’ Fits on T4!                                       â”‚
â”‚                                                                                                 â”‚
â”‚   HOW IT WORKS:                                                                                 â”‚
â”‚   â•â•â•â•â•â•â•â•â•â•â•â•â•                                                                                 â”‚
â”‚   1. Compute embedding similarity between adjacent frames                                       â”‚
â”‚   2. Frames with similarity > threshold are pruned                                             â”‚
â”‚   3. Keep diverse frames, remove redundant ones                                                â”‚
â”‚                                                                                                 â”‚
â”‚   PERFORMANCE IMPACT:                                                                           â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                            â”‚
â”‚   â”‚ Pruning Rate  â”‚ Tokens Kept  â”‚ Quality Loss â”‚ Speed Gain      â”‚                            â”‚
â”‚   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                            â”‚
â”‚   â”‚ 0.3 (30%)     â”‚ 70%          â”‚ Minimal      â”‚ ~1.4x faster    â”‚                            â”‚
â”‚   â”‚ 0.5 (50%)     â”‚ 50%          â”‚ Slight       â”‚ ~2x faster      â”‚                            â”‚
â”‚   â”‚ 0.7 (70%)     â”‚ 30%          â”‚ Noticeable   â”‚ ~3x faster      â”‚                            â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                            â”‚
â”‚                                                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## GPU Hardware Guide

### Architecture Comparison

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                              GPU ARCHITECTURE COMPARISON                                        â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                                                 â•‘
â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â•‘
â•‘  â”‚ Specification       â”‚ T4 (Turing)   â”‚ A100 (Ampere) â”‚ H100 (Hopper) â”‚ B200 (Blackwell)â”‚    â•‘
â•‘  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â•‘
â•‘  â”‚ Compute Capability  â”‚ SM 7.5        â”‚ SM 8.0        â”‚ SM 9.0        â”‚ SM 10.0         â”‚    â•‘
â•‘  â”‚ VRAM                â”‚ 16 GB         â”‚ 40/80 GB      â”‚ 80 GB         â”‚ 192 GB          â”‚    â•‘
â•‘  â”‚ Memory Bandwidth    â”‚ 320 GB/s      â”‚ 2,039 GB/s    â”‚ 3,350 GB/s    â”‚ 8,000 GB/s      â”‚    â•‘
â•‘  â”‚ FP16 TFLOPS         â”‚ 65            â”‚ 312           â”‚ 1,979         â”‚ ~4,000          â”‚    â•‘
â•‘  â”‚ FP8 TFLOPS          â”‚ âŒ            â”‚ âŒ            â”‚ 3,958         â”‚ ~8,000          â”‚    â•‘
â•‘  â”‚ FP4 TFLOPS          â”‚ âŒ            â”‚ âŒ            â”‚ âŒ            â”‚ ~16,000         â”‚    â•‘
â•‘  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â•‘
â•‘  â”‚ BF16 Support        â”‚ âŒ            â”‚ âœ…            â”‚ âœ…            â”‚ âœ…              â”‚    â•‘
â•‘  â”‚ FlashAttention 2    â”‚ âŒ            â”‚ âœ…            â”‚ âœ…            â”‚ âœ…              â”‚    â•‘
â•‘  â”‚ FlashAttention 3    â”‚ âŒ            â”‚ âŒ            â”‚ âœ…            â”‚ âœ…              â”‚    â•‘
â•‘  â”‚ FP8 Quantization    â”‚ âŒ            â”‚ âŒ            â”‚ âœ…            â”‚ âœ…              â”‚    â•‘
â•‘  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â•‘
â•‘  â”‚ Expected Latency    â”‚ ~1000ms       â”‚ ~300ms        â”‚ ~200ms        â”‚ ~100ms          â”‚    â•‘
â•‘  â”‚ Expected Throughput â”‚ ~1 req/s      â”‚ ~4 req/s      â”‚ ~6 req/s      â”‚ ~15 req/s       â”‚    â•‘
â•‘  â”‚ Max Concurrent      â”‚ 4             â”‚ 32            â”‚ 64            â”‚ 128             â”‚    â•‘
â•‘  â”‚ Max Context         â”‚ 4K            â”‚ 32K           â”‚ 32K           â”‚ 128K            â”‚    â•‘
â•‘  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â•‘
â•‘                                                                                                 â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

### Model Fit by GPU

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              WHICH MODELS FIT ON WHICH GPU?                                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                                 â”‚
â”‚  T4 (16 GB):                                                                                    â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•                                                                                    â”‚
â”‚  âœ… Qwen2-VL-2B (FP16)      - 4 GB weights, comfortable                                        â”‚
â”‚  âœ… Qwen3-VL-4B (4-bit)     - 2 GB weights + EVS helps videos                                  â”‚
â”‚  âš ï¸  Qwen2-VL-7B (4-bit)     - 4 GB weights, tight, small batches                              â”‚
â”‚  âš ï¸  Qwen3-VL-8B (4-bit)     - 4 GB weights, very tight                                        â”‚
â”‚  âŒ Larger models           - Won't fit                                                        â”‚
â”‚                                                                                                 â”‚
â”‚  A100-80GB:                                                                                     â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•                                                                                    â”‚
â”‚  âœ… Qwen2-VL-2B/7B (BF16)   - Plenty of room                                                   â”‚
â”‚  âœ… Qwen3-VL-4B/8B (BF16)   - Excellent, high throughput                                       â”‚
â”‚  âœ… Qwen3-VL-30B-A3B (MoE)  - Fits! Only 3B active at a time                                   â”‚
â”‚  âš ï¸  Qwen2-VL-72B           - Needs tensor parallelism (2 GPUs)                                â”‚
â”‚                                                                                                 â”‚
â”‚  H100-80GB:                                                                                     â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•                                                                                   â”‚
â”‚  âœ… All Qwen2-VL models     - Excellent with FP8                                               â”‚
â”‚  âœ… All Qwen3-VL models     - FlashAttention 3, DeepStack + EVS                                â”‚
â”‚  âœ… Qwen3-VL-30B-A3B (MoE)  - High throughput with FP8                                         â”‚
â”‚                                                                                                 â”‚
â”‚  B200-192GB:                                                                                    â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•                                                                                   â”‚
â”‚  âœ… Qwen2-VL-72B (BF16)     - Single GPU! No tensor parallelism needed                         â”‚
â”‚  âœ… Qwen3-VL-235B-A22B      - Full MoE model fits                                              â”‚
â”‚  âœ… 4K resolution           - max_pixels=4,147,200                                              â”‚
â”‚  âœ… 128K context            - Massive conversation history                                     â”‚
â”‚                                                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### GPU-Specific Optimization Matrix

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                        GPU OPTIMIZATION MATRIX                                      â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                                     â•‘
â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â•‘
â•‘  â”‚                              T4 (16GB, SM 7.5)                              â”‚   â•‘
â•‘  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â•‘
â•‘  â”‚  Qwen2-VL-2B: âœ… FP16 full precision, SDPA attention, 2K context           â”‚   â•‘
â•‘  â”‚  Qwen2-VL-7B: âš ï¸  4-bit required, BitsAndBytes, very limited               â”‚   â•‘
â•‘  â”‚  Qwen3-VL-4B: âœ… 4-bit quantization, small batch, EVS helps videos!        â”‚   â•‘
â•‘  â”‚  Qwen3-VL-8B: âš ï¸  Very tight, needs aggressive 4-bit quantization          â”‚   â•‘
â•‘  â”‚                                                                             â”‚   â•‘
â•‘  â”‚  LIMITATIONS:                                                               â”‚   â•‘
â•‘  â”‚  â”œâ”€ âŒ No FlashAttention 2 (uses TORCH_SDPA)                                â”‚   â•‘
â•‘  â”‚  â”œâ”€ âŒ No BF16 support (FP16 only)                                          â”‚   â•‘
â•‘  â”‚  â”œâ”€ âŒ No FP8 quantization                                                  â”‚   â•‘
â•‘  â”‚  â””â”€ âš ï¸ 320 GB/s bandwidth (memory-bound decode)                             â”‚   â•‘
â•‘  â”‚                                                                             â”‚   â•‘
â•‘  â”‚  BEST CONFIG:                                                               â”‚   â•‘
â•‘  â”‚  enforce_eager=True, max_num_seqs=4, max_pixels=512000, max_model_len=4096 â”‚   â•‘
â•‘  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â•‘
â•‘                                                                                     â•‘
â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â•‘
â•‘  â”‚                            A100 (40/80GB, SM 8.0)                           â”‚   â•‘
â•‘  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â•‘
â•‘  â”‚  Qwen2-VL-2B/7B: âœ… Full precision (BF16), FlashAttention v2               â”‚   â•‘
â•‘  â”‚  Qwen3-VL-4B:    âœ… Excellent, full precision, high throughput              â”‚   â•‘
â•‘  â”‚  Qwen3-VL-8B:    âœ… Full precision (80GB), good concurrency                 â”‚   â•‘
â•‘  â”‚  Qwen3-VL-30B-A3B: âœ… MoE fits in 80GB! Only 3B active per token           â”‚   â•‘
â•‘  â”‚                                                                             â”‚   â•‘
â•‘  â”‚  ADVANTAGES:                                                                â”‚   â•‘
â•‘  â”‚  â”œâ”€ âœ… FlashAttention 2 (2-4x faster attention)                             â”‚   â•‘
â•‘  â”‚  â”œâ”€ âœ… Native BF16 support (better numerical stability)                     â”‚   â•‘
â•‘  â”‚  â”œâ”€ âœ… 2,039 GB/s bandwidth (6x faster than T4)                             â”‚   â•‘
â•‘  â”‚  â””â”€ âœ… Tensor cores for mixed precision                                     â”‚   â•‘
â•‘  â”‚                                                                             â”‚   â•‘
â•‘  â”‚  BEST CONFIG:                                                               â”‚   â•‘
â•‘  â”‚  dtype=bfloat16, max_num_seqs=32, enable_prefix_caching=True               â”‚   â•‘
â•‘  â”‚  max_model_len=32768, max_pixels=2073600                                    â”‚   â•‘
â•‘  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â•‘
â•‘                                                                                     â•‘
â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â•‘
â•‘  â”‚                             H100 (80GB, SM 9.0)                             â”‚   â•‘
â•‘  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â•‘
â•‘  â”‚  All Qwen2-VL: âœ… Excellent with optional FP8 quantization                  â”‚   â•‘
â•‘  â”‚  All Qwen3-VL: âœ… FlashAttention 3, DeepStack + EVS leverage bandwidth      â”‚   â•‘
â•‘  â”‚                                                                             â”‚   â•‘
â•‘  â”‚  ADVANTAGES:                                                                â”‚   â•‘
â•‘  â”‚  â”œâ”€ âœ… FlashAttention 3 (Hopper-specific optimizations)                     â”‚   â•‘
â•‘  â”‚  â”œâ”€ âœ… Native FP8 support (2x throughput vs BF16)                           â”‚   â•‘
â•‘  â”‚  â”œâ”€ âœ… FP8 KV cache (halves KV cache memory)                                â”‚   â•‘
â•‘  â”‚  â”œâ”€ âœ… 3,350 GB/s bandwidth (10x faster than T4)                            â”‚   â•‘
â•‘  â”‚  â””â”€ âœ… Transformer Engine for automatic mixed precision                     â”‚   â•‘
â•‘  â”‚                                                                             â”‚   â•‘
â•‘  â”‚  BEST CONFIG:                                                               â”‚   â•‘
â•‘  â”‚  quantization="fp8", kv_cache_dtype="fp8", max_num_seqs=64                 â”‚   â•‘
â•‘  â”‚  max_model_len=32768, max_pixels=2073600                                    â”‚   â•‘
â•‘  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â•‘
â•‘                                                                                     â•‘
â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â•‘
â•‘  â”‚                            B200 (192GB, SM 10.0)                            â”‚   â•‘
â•‘  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â•‘
â•‘  â”‚  Qwen2-VL-72B:      âœ… Full precision on single GPU!                        â”‚   â•‘
â•‘  â”‚  Qwen3-VL-235B-A22B:âœ… Full MoE model fits                                  â”‚   â•‘
â•‘  â”‚                                                                             â”‚   â•‘
â•‘  â”‚  ADVANTAGES:                                                                â”‚   â•‘
â•‘  â”‚  â”œâ”€ âœ… 192 GB VRAM (12x T4, 2.4x H100)                                      â”‚   â•‘
â•‘  â”‚  â”œâ”€ âœ… 8,000 GB/s bandwidth (25x faster than T4)                            â”‚   â•‘
â•‘  â”‚  â”œâ”€ âœ… FP4 quantization (when available, 4x throughput)                     â”‚   â•‘
â•‘  â”‚  â”œâ”€ âœ… 4K resolution images (max_pixels=4,147,200)                          â”‚   â•‘
â•‘  â”‚  â””â”€ âœ… 128K context length                                                  â”‚   â•‘
â•‘  â”‚                                                                             â”‚   â•‘
â•‘  â”‚  BEST CONFIG:                                                               â”‚   â•‘
â•‘  â”‚  max_num_seqs=128, max_model_len=131072, max_pixels=4147200                â”‚   â•‘
â•‘  â”‚  enable_prefix_caching=True, enable_chunked_prefill=True                   â”‚   â•‘
â•‘  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â•‘
â•‘                                                                                     â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

### Memory Budget Breakdown by GPU

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           T4 MEMORY BUDGET (16 GB)                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                     â”‚
â”‚  QWEN3-VL-4B (4-bit BitsAndBytes):                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Model Weights (4-bit):     ~2.0 GB (12.5%)  â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  â”‚   â”‚
â”‚  â”‚  Vision Encoder:            ~1.5 GB (9.4%)   â–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  â”‚   â”‚
â”‚  â”‚  KV Cache (4K ctx, 4 seqs): ~2.5 GB (15.6%)  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  â”‚   â”‚
â”‚  â”‚  Activations:               ~1.5 GB (9.4%)   â–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  â”‚   â”‚
â”‚  â”‚  CUDA Overhead:             ~1.5 GB (9.4%)   â–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  â”‚   â”‚
â”‚  â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                   â”‚   â”‚
â”‚  â”‚  USED:                      ~9.0 GB (56%)                                    â”‚   â”‚
â”‚  â”‚  FREE:                      ~7.0 GB (44%)   âœ… Comfortable                   â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                                     â”‚
â”‚  QWEN3-VL-8B (4-bit BitsAndBytes):                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Model Weights (4-bit):     ~4.0 GB (25%)    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  â”‚   â”‚
â”‚  â”‚  Vision Encoder:            ~2.0 GB (12.5%)  â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  â”‚   â”‚
â”‚  â”‚  KV Cache (2K ctx, 2 seqs): ~3.0 GB (18.8%)  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  â”‚   â”‚
â”‚  â”‚  Activations:               ~2.0 GB (12.5%)  â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  â”‚   â”‚
â”‚  â”‚  CUDA Overhead:             ~2.0 GB (12.5%)  â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  â”‚   â”‚
â”‚  â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                   â”‚   â”‚
â”‚  â”‚  USED:                     ~13.0 GB (81%)                                    â”‚   â”‚
â”‚  â”‚  FREE:                      ~3.0 GB (19%)   âš ï¸  Very Tight                   â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           A100-80GB MEMORY BUDGET                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                     â”‚
â”‚  QWEN3-VL-8B (BF16 Full Precision):                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Model Weights (BF16):     ~16.0 GB (20%)    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  â”‚   â”‚
â”‚  â”‚  Vision Encoder:            ~4.0 GB (5%)     â–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  â”‚   â”‚
â”‚  â”‚  KV Cache (32K, 32 seqs):  ~20.0 GB (25%)    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  â”‚   â”‚
â”‚  â”‚  Activations:               ~5.0 GB (6.3%)   â–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  â”‚   â”‚
â”‚  â”‚  CUDA Graphs:               ~3.0 GB (3.8%)   â–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  â”‚   â”‚
â”‚  â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                   â”‚   â”‚
â”‚  â”‚  USED:                     ~48.0 GB (60%)                                    â”‚   â”‚
â”‚  â”‚  FREE:                     ~32.0 GB (40%)   âœ… Plenty of room                â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                                     â”‚
â”‚  QWEN3-VL-30B-A3B (MoE, BF16):                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Model Weights (all experts): ~60.0 GB (75%) â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  â”‚   â”‚
â”‚  â”‚  Active Weights (3B):         ~6.0 GB        (compute like a 3B model!)      â”‚   â”‚
â”‚  â”‚  Vision Encoder:              ~4.0 GB (5%)   â–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  â”‚   â”‚
â”‚  â”‚  KV Cache (16K, 16 seqs):    ~8.0 GB (10%)   â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  â”‚   â”‚
â”‚  â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                   â”‚   â”‚
â”‚  â”‚  USED:                      ~72.0 GB (90%)                                   â”‚   â”‚
â”‚  â”‚  FREE:                       ~8.0 GB (10%)  âš ï¸  Tight but works              â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           H100-80GB MEMORY BUDGET (WITH FP8)                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                     â”‚
â”‚  QWEN3-VL-8B (FP8 Quantization):                                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Model Weights (FP8):       ~8.0 GB (10%)    â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  â”‚   â”‚
â”‚  â”‚  Vision Encoder:            ~4.0 GB (5%)     â–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  â”‚   â”‚
â”‚  â”‚  KV Cache (FP8, 32K, 64):  ~16.0 GB (20%)    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  â”‚   â”‚
â”‚  â”‚  Activations:               ~4.0 GB (5%)     â–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  â”‚   â”‚
â”‚  â”‚  CUDA Graphs:               ~4.0 GB (5%)     â–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  â”‚   â”‚
â”‚  â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                   â”‚   â”‚
â”‚  â”‚  USED:                     ~36.0 GB (45%)                                    â”‚   â”‚
â”‚  â”‚  FREE:                     ~44.0 GB (55%)   âœ… Room for 64+ concurrent       â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                                     â”‚
â”‚  FP8 BENEFITS:                                                                      â”‚
â”‚  â”œâ”€ Weights: 16 GB â†’ 8 GB (50% reduction)                                          â”‚
â”‚  â”œâ”€ KV Cache: 32 GB â†’ 16 GB (50% reduction)                                        â”‚
â”‚  â”œâ”€ Throughput: ~2x faster matmul operations                                       â”‚
â”‚  â””â”€ Quality: <1% accuracy loss for most tasks                                      â”‚
â”‚                                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           B200-192GB MEMORY BUDGET                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                     â”‚
â”‚  QWEN3-VL-235B-A22B (Full MoE, BF16):                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Model Weights (all experts): ~140 GB (73%)  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  â”‚   â”‚
â”‚  â”‚  Active Weights (22B):        ~44 GB         (compute like a 22B model!)     â”‚   â”‚
â”‚  â”‚  Vision Encoder:              ~8.0 GB (4%)   â–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  â”‚   â”‚
â”‚  â”‚  KV Cache (128K, 128 seqs):  ~30.0 GB (16%)  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  â”‚   â”‚
â”‚  â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                   â”‚   â”‚
â”‚  â”‚  USED:                      ~178 GB (93%)                                    â”‚   â”‚
â”‚  â”‚  FREE:                       ~14 GB (7%)    âš ï¸  Tight but workable           â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                                     â”‚
â”‚  ALTERNATIVE: QWEN3-VL-32B (Dense) with room for 4K images + 128K context          â”‚
â”‚                                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Performance Benchmarks

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    EXPECTED PERFORMANCE (Image Inference)                           â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                                     â•‘
â•‘  Single Image (1024Ã—1024), 256 output tokens:                                       â•‘
â•‘                                                                                     â•‘
â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â•‘
â•‘  â”‚ Model              â”‚ T4 (16GB)       â”‚ H100 (80GB)     â”‚ B200 (192GB)      â”‚    â•‘
â•‘  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â•‘
â•‘  â”‚ Qwen2-VL-2B        â”‚ ~800ms, 20 t/s  â”‚ ~150ms, 120 t/s â”‚ ~80ms, 200 t/s    â”‚    â•‘
â•‘  â”‚ Qwen2-VL-7B        â”‚ ~2000ms*, 8 t/s â”‚ ~250ms, 80 t/s  â”‚ ~120ms, 150 t/s   â”‚    â•‘
â•‘  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â•‘
â•‘  â”‚ Qwen3-VL-4B        â”‚ ~1000ms, 18 t/s â”‚ ~120ms, 150 t/s â”‚ ~60ms, 280 t/s    â”‚    â•‘
â•‘  â”‚ Qwen3-VL-8B        â”‚ ~1800ms*, 10 t/sâ”‚ ~180ms, 100 t/s â”‚ ~90ms, 200 t/s    â”‚    â•‘
â•‘  â”‚ Qwen3-VL-30B-A3B   â”‚ âŒ OOM          â”‚ ~300ms, 60 t/s  â”‚ ~150ms, 120 t/s   â”‚    â•‘
â•‘  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â•‘
â•‘  * = Requires 4-bit quantization                                                    â•‘
â•‘  t/s = tokens per second                                                            â•‘
â•‘                                                                                     â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    EXPECTED PERFORMANCE (Video Inference)                           â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                                     â•‘
â•‘  60-second video (30 fps â†’ 1800 frames â†’ sampled to ~100 frames):                   â•‘
â•‘                                                                                     â•‘
â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â•‘
â•‘  â”‚ Model              â”‚ A100 (80GB)     â”‚ H100 (80GB)     â”‚ B200 (192GB)      â”‚    â•‘
â•‘  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â•‘
â•‘  â”‚ Qwen2-VL-7B        â”‚ ~5s, 16K tokens â”‚ ~2s, 16K tokens â”‚ ~1s, 16K tokens   â”‚    â•‘
â•‘  â”‚ (no pruning)       â”‚                 â”‚                 â”‚                   â”‚    â•‘
â•‘  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â•‘
â•‘  â”‚ Qwen3-VL-8B        â”‚ ~3s, 8K tokens  â”‚ ~1.2s, 8K tokensâ”‚ ~0.6s, 8K tokens  â”‚    â•‘
â•‘  â”‚ (EVS 50%)          â”‚ 50% pruned!     â”‚ 50% pruned!     â”‚ 50% pruned!       â”‚    â•‘
â•‘  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â•‘
â•‘                                                                                     â•‘
â•‘  EVS IMPACT: ~2x speedup on long videos with minimal quality degradation           â•‘
â•‘                                                                                     â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    THROUGHPUT COMPARISON (Concurrent Users)                         â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                                     â•‘
â•‘  Qwen3-VL-8B, 1024Ã—1024 images, 256 tokens output:                                  â•‘
â•‘                                                                                     â•‘
â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â•‘
â•‘  â”‚ GPU                â”‚ Max Batch   â”‚ Throughput   â”‚ p95 Latency                 â”‚ â•‘
â•‘  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â•‘
â•‘  â”‚ T4 (4-bit)         â”‚ 4           â”‚ ~1 req/s     â”‚ ~2000ms                     â”‚ â•‘
â•‘  â”‚ A100-80GB          â”‚ 32          â”‚ ~4 req/s     â”‚ ~800ms                      â”‚ â•‘
â•‘  â”‚ H100 (FP8)         â”‚ 64          â”‚ ~8 req/s     â”‚ ~400ms                      â”‚ â•‘
â•‘  â”‚ B200               â”‚ 128         â”‚ ~20 req/s    â”‚ ~200ms                      â”‚ â•‘
â•‘  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â•‘
â•‘                                                                                     â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

---

## vLLM Configuration Parameters

### Parameter Reference

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         VLLM CONFIGURATION PARAMETERS EXPLAINED                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                                 â”‚
â”‚  MEMORY PARAMETERS                                                                              â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                                                              â”‚
â”‚                                                                                                 â”‚
â”‚  gpu_memory_utilization (0.0-1.0)                                                               â”‚
â”‚  â””â”€ What % of GPU memory vLLM can use                                                          â”‚
â”‚     â€¢ T4:   0.90-0.92 (leave room for CUDA overhead)                                           â”‚
â”‚     â€¢ A100: 0.95 (more stable)                                                                 â”‚
â”‚     â€¢ H100: 0.95                                                                               â”‚
â”‚                                                                                                 â”‚
â”‚  max_model_len (integer)                                                                        â”‚
â”‚  â””â”€ Maximum tokens in context window (prompt + response)                                       â”‚
â”‚     â€¢ T4:   2048-4096 (limited memory)                                                         â”‚
â”‚     â€¢ A100: 8192-32768                                                                         â”‚
â”‚     â€¢ H100: 16384-65536                                                                        â”‚
â”‚     â€¢ Each 1K tokens â‰ˆ 50-100 MB memory for KV cache                                           â”‚
â”‚                                                                                                 â”‚
â”‚  max_num_seqs (integer)                                                                         â”‚
â”‚  â””â”€ Maximum concurrent requests (batch size)                                                   â”‚
â”‚     â€¢ T4:   4-8                                                                                â”‚
â”‚     â€¢ A100: 16-32                                                                              â”‚
â”‚     â€¢ H100: 32-64                                                                              â”‚
â”‚     â€¢ More concurrent = higher throughput but more memory                                      â”‚
â”‚                                                                                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                                 â”‚
â”‚  PRECISION PARAMETERS                                                                           â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                                                           â”‚
â”‚                                                                                                 â”‚
â”‚  dtype ("half" | "bfloat16" | "auto")                                                           â”‚
â”‚  â””â”€ Data type for model weights                                                                â”‚
â”‚     â€¢ "half" (FP16): T4 only option, 2 bytes per parameter                                     â”‚
â”‚     â€¢ "bfloat16": Better numerical stability, A100+ recommended                                â”‚
â”‚     â€¢ "auto": Let vLLM choose based on GPU                                                     â”‚
â”‚                                                                                                 â”‚
â”‚  quantization (null | "bitsandbytes" | "awq" | "gptq" | "fp8")                                  â”‚
â”‚  â””â”€ Compress model weights to use less memory                                                  â”‚
â”‚     â€¢ null: Full precision (best quality)                                                      â”‚
â”‚     â€¢ "bitsandbytes": 4-bit, easy to use, slight quality loss                                  â”‚
â”‚     â€¢ "awq": 4-bit, optimized for inference                                                    â”‚
â”‚     â€¢ "fp8": 8-bit, H100 only, 2x faster with minimal loss                                     â”‚
â”‚                                                                                                 â”‚
â”‚  kv_cache_dtype ("auto" | "fp8")                                                                â”‚
â”‚  â””â”€ Data type for key-value cache                                                              â”‚
â”‚     â€¢ "auto": Same as model weights                                                            â”‚
â”‚     â€¢ "fp8": H100 only, saves 50% KV cache memory                                              â”‚
â”‚                                                                                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                                 â”‚
â”‚  PERFORMANCE PARAMETERS                                                                         â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                                                         â”‚
â”‚                                                                                                 â”‚
â”‚  enforce_eager (true | false)                                                                   â”‚
â”‚  â””â”€ Disable CUDA graph compilation                                                             â”‚
â”‚     â€¢ true: Slower but uses less memory, better for T4                                         â”‚
â”‚     â€¢ false: Faster via CUDA graphs, needs more memory                                         â”‚
â”‚                                                                                                 â”‚
â”‚  enable_prefix_caching (true | false)                                                           â”‚
â”‚  â””â”€ Cache repeated prompt prefixes (like system prompts)                                       â”‚
â”‚     â€¢ true: Faster for repeated prompts, small memory overhead                                 â”‚
â”‚     â€¢ false: Recompute every time                                                              â”‚
â”‚                                                                                                 â”‚
â”‚  enable_chunked_prefill (true | false)                                                          â”‚
â”‚  â””â”€ Process long prompts in chunks                                                             â”‚
â”‚     â€¢ true: Better for mixed short/long requests                                               â”‚
â”‚     â€¢ false: Process entire prompt at once                                                     â”‚
â”‚                                                                                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                                 â”‚
â”‚  VISION PARAMETERS                                                                              â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                                                              â”‚
â”‚                                                                                                 â”‚
â”‚  limit_mm_per_prompt (dict)                                                                     â”‚
â”‚  â””â”€ Maximum images/videos per prompt                                                           â”‚
â”‚     â€¢ {"image": 4, "video": 1}: Max 4 images OR 1 video                                        â”‚
â”‚                                                                                                 â”‚
â”‚  mm_processor_kwargs (dict)                                                                     â”‚
â”‚  â””â”€ Vision processor settings                                                                  â”‚
â”‚     â€¢ min_pixels: Minimum image size (default 784 = 28Ã—28)                                     â”‚
â”‚     â€¢ max_pixels: Maximum image size (memory vs quality tradeoff)                              â”‚
â”‚       - T4:   500,000 (~700Ã—700)                                                               â”‚
â”‚       - A100: 2,073,600 (1920Ã—1080)                                                            â”‚
â”‚       - B200: 4,147,200 (3840Ã—1080 or 2KÃ—2K)                                                   â”‚
â”‚     â€¢ video_pruning_rate (Qwen3-VL only): 0.0-0.7                                              â”‚
â”‚       - 0.0: Keep all frames                                                                   â”‚
â”‚       - 0.5: Keep ~50% most different frames                                                   â”‚
â”‚                                                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### What Happens When You Change Each Number

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      IMPACT OF CHANGING EACH PARAMETER                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                                 â”‚
â”‚  max_pixels: 500,000 â†’ 2,000,000                                                                â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                                               â”‚
â”‚  BEFORE: 720Ã—720 max image, ~650 tokens, ~5 MB per image                                        â”‚
â”‚  AFTER:  1920Ã—1080 max image, ~2600 tokens, ~20 MB per image                                    â”‚
â”‚  IMPACT: 4x more detail, 4x more memory, 2-3x slower                                           â”‚
â”‚                                                                                                 â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚                                                                                                 â”‚
â”‚  max_model_len: 4096 â†’ 16384                                                                    â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                                                   â”‚
â”‚  BEFORE: 4K context, 1 image + short conversation                                               â”‚
â”‚  AFTER:  16K context, 4 images + long conversation history                                      â”‚
â”‚  IMPACT: 4x longer conversations, 4x more KV cache memory (~400 MB â†’ ~1.6 GB)                  â”‚
â”‚                                                                                                 â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚                                                                                                 â”‚
â”‚  max_num_seqs: 4 â†’ 16                                                                           â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                                                           â”‚
â”‚  BEFORE: 4 concurrent users, low throughput                                                     â”‚
â”‚  AFTER:  16 concurrent users, 4x throughput potential                                           â”‚
â”‚  IMPACT: 4x more KV cache memory needed, may cause OOM on small GPUs                           â”‚
â”‚                                                                                                 â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚                                                                                                 â”‚
â”‚  video_pruning_rate: 0.0 â†’ 0.5                                                                  â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                                                   â”‚
â”‚  BEFORE: All 100 video frames processed, 16,000 tokens                                          â”‚
â”‚  AFTER:  ~50 frames kept, 8,000 tokens                                                          â”‚
â”‚  IMPACT: 50% less memory, 2x faster, slight quality loss on fast-changing videos               â”‚
â”‚                                                                                                 â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚                                                                                                 â”‚
â”‚  quantization: null â†’ "bitsandbytes"                                                            â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                                           â”‚
â”‚  BEFORE: 8B model = 16 GB weights (BF16)                                                        â”‚
â”‚  AFTER:  8B model = 4 GB weights (4-bit)                                                        â”‚
â”‚  IMPACT: 4x smaller, fits on smaller GPUs, ~5-10% quality loss                                 â”‚
â”‚                                                                                                 â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚                                                                                                 â”‚
â”‚  enforce_eager: false â†’ true                                                                    â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                                                    â”‚
â”‚  BEFORE: CUDA graphs enabled, 0.5 GB extra memory, fast decode                                  â”‚
â”‚  AFTER:  CUDA graphs disabled, saves memory, ~20% slower decode                                â”‚
â”‚  IMPACT: Use on T4 to save memory, avoid on H100                                               â”‚
â”‚                                                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Optimization Decision Tree

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              VLLM OPTIMIZATION DECISION TREE                                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                                 â”‚
â”‚  START: What GPU do you have?                                                                   â”‚
â”‚                                                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                                                                                          â”‚   â”‚
â”‚  â”‚                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                     â”‚   â”‚
â”‚  â”‚                              â”‚  What is your GPU?  â”‚                                     â”‚   â”‚
â”‚  â”‚                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                     â”‚   â”‚
â”‚  â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”‚   â”‚
â”‚  â”‚              â–¼                          â–¼                          â–¼                     â”‚   â”‚
â”‚  â”‚      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚   â”‚
â”‚  â”‚      â”‚     T4       â”‚          â”‚  A100/H100   â”‚          â”‚     B200     â”‚               â”‚   â”‚
â”‚  â”‚      â”‚   (16 GB)    â”‚          â”‚  (40-80 GB)  â”‚          â”‚   (192 GB)   â”‚               â”‚   â”‚
â”‚  â”‚      â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚   â”‚
â”‚  â”‚             â”‚                          â”‚                          â”‚                      â”‚   â”‚
â”‚  â”‚             â–¼                          â–¼                          â–¼                      â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚   â”‚
â”‚  â”‚  â”‚ dtype="half"         â”‚  â”‚ dtype="bfloat16"     â”‚  â”‚ dtype="bfloat16"     â”‚           â”‚   â”‚
â”‚  â”‚  â”‚ quantization=        â”‚  â”‚                       â”‚  â”‚ max_model_len=131072 â”‚           â”‚   â”‚
â”‚  â”‚  â”‚   "bitsandbytes"     â”‚  â”‚ Is it H100?          â”‚  â”‚ max_num_seqs=128     â”‚           â”‚   â”‚
â”‚  â”‚  â”‚ enforce_eager=True   â”‚  â”‚   Yesâ†’ quantization= â”‚  â”‚ max_pixels=4147200   â”‚           â”‚   â”‚
â”‚  â”‚  â”‚ max_model_len=4096   â”‚  â”‚         "fp8"        â”‚  â”‚                       â”‚           â”‚   â”‚
â”‚  â”‚  â”‚ max_num_seqs=4       â”‚  â”‚   No â†’ None          â”‚  â”‚                       â”‚           â”‚   â”‚
â”‚  â”‚  â”‚ max_pixels=512000    â”‚  â”‚                       â”‚  â”‚                       â”‚           â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚   â”‚
â”‚  â”‚                                                                                          â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                                                 â”‚
â”‚  ADDITIONAL DECISIONS:                                                                          â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                                                          â”‚
â”‚                                                                                                 â”‚
â”‚  Do you process VIDEOS?                                                                         â”‚
â”‚  â”œâ”€ Yes + Qwen3-VL â†’ Set video_pruning_rate=0.3-0.5                                            â”‚
â”‚  â”œâ”€ Yes + Qwen2-VL â†’ Reduce max_pixels, limit frames                                           â”‚
â”‚  â””â”€ No â†’ video_pruning_rate=0.0 or omit                                                        â”‚
â”‚                                                                                                 â”‚
â”‚  Do you have REPEATED SYSTEM PROMPTS?                                                           â”‚
â”‚  â”œâ”€ Yes â†’ enable_prefix_caching=True                                                           â”‚
â”‚  â””â”€ No  â†’ enable_prefix_caching=False                                                          â”‚
â”‚                                                                                                 â”‚
â”‚  Do you have MIXED SHORT/LONG PROMPTS?                                                          â”‚
â”‚  â”œâ”€ Yes â†’ enable_chunked_prefill=True                                                          â”‚
â”‚  â””â”€ No  â†’ enable_chunked_prefill=False                                                         â”‚
â”‚                                                                                                 â”‚
â”‚  Are you MEMORY CONSTRAINED?                                                                    â”‚
â”‚  â”œâ”€ Yes â†’ enforce_eager=True (disables CUDA graphs, saves ~0.5 GB)                             â”‚
â”‚  â””â”€ No  â†’ enforce_eager=False (faster decode)                                                  â”‚
â”‚                                                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Configuration Checklist

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              BEFORE DEPLOYING: CHECK THESE                                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                                 â”‚
â”‚  â–¡ Match dtype to GPU: FP16 for T4, BF16 for A100+                                             â”‚
â”‚  â–¡ Set max_model_len to fit your longest expected input                                        â”‚
â”‚  â–¡ Set max_num_seqs based on your memory budget                                                â”‚
â”‚  â–¡ Enable prefix caching if you have repeated system prompts                                   â”‚
â”‚  â–¡ Enable chunked prefill if you have mixed long/short prompts                                 â”‚
â”‚  â–¡ For Qwen3-VL with videos: Set video_pruning_rate (0.3-0.5)                                  â”‚
â”‚  â–¡ Set max_pixels based on how much detail you need                                            â”‚
â”‚  â–¡ Use FP8 on H100 for 2x throughput                                                           â”‚
â”‚  â–¡ Use 4-bit quantization on T4 for larger models                                              â”‚
â”‚  â–¡ Test memory usage with gpu_memory_utilization=0.9 first                                     â”‚
â”‚                                                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## MAI-UI: GUI Agents with Reinforcement Learning

### What is MAI-UI?

MAI-UI is a family of GUI agents developed by Tongyi Lab (Alibaba) that uses Qwen3-VL as its vision-language backbone, trained with reinforcement learning to automate mobile and desktop applications.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              MAI-UI: GUI AGENTS POWERED BY QWEN-VL                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                                 â”‚
â”‚  WHAT IT DOES:                                                                                  â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•                                                                                  â”‚
â”‚                                                                                                 â”‚
â”‚   User Task: "Send a message to John saying 'Hello!'"                                           â”‚
â”‚                                                                                                 â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚
â”‚   â”‚ Screenshot      â”‚        â”‚ Qwen3-VL        â”‚        â”‚ Action          â”‚                    â”‚
â”‚   â”‚ of phone        â”‚â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚ Model           â”‚â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚ CLICK(150, 500) â”‚                    â”‚
â”‚   â”‚ home screen     â”‚        â”‚ (MAI-UI-8B)     â”‚        â”‚                 â”‚                    â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚
â”‚                                                                   â”‚                             â”‚
â”‚                                                                   â–¼                             â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚
â”‚   â”‚ Messages app    â”‚        â”‚ Qwen3-VL        â”‚        â”‚ Action          â”‚                    â”‚
â”‚   â”‚ opened          â”‚â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚ Model           â”‚â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚ CLICK(300, 200) â”‚                    â”‚
â”‚   â”‚                 â”‚        â”‚                 â”‚        â”‚                 â”‚                    â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚
â”‚                                                                   â”‚                             â”‚
â”‚                                         ... continues until task complete ...                   â”‚
â”‚                                                                                                 â”‚
â”‚  MODEL VARIANTS:                                                                                â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                                                                â”‚
â”‚  â€¢ MAI-UI-2B:   Based on Qwen3-VL-2B  â†’ Runs on T4!                                            â”‚
â”‚  â€¢ MAI-UI-8B:   Based on Qwen3-VL-8B  â†’ A100/H100                                              â”‚
â”‚  â€¢ MAI-UI-32B:  Based on Qwen3-VL-32B â†’ H100/B200                                              â”‚
â”‚  â€¢ MAI-UI-235B: MoE (235B total, 22B active) â†’ Multi-GPU                                       â”‚
â”‚                                                                                                 â”‚
â”‚  PERFORMANCE (Dec 2025):                                                                        â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                                                        â”‚
â”‚  â€¢ 76.7% on AndroidWorld (mobile navigation) - SOTA!                                           â”‚
â”‚  â€¢ 73.5% on ScreenSpot-Pro (GUI grounding)                                                     â”‚
â”‚  â€¢ Beats Gemini-3-Pro and Seed1.8 on several benchmarks                                        â”‚
â”‚                                                                                                 â”‚
â”‚  Paper: https://arxiv.org/abs/2512.22047                                                       â”‚
â”‚  GitHub: https://github.com/Tongyi-MAI/MAI-UI                                                  â”‚
â”‚                                                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### GRPO Reinforcement Learning Training

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      HOW MAI-UI IS TRAINED WITH REINFORCEMENT LEARNING                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                                 â”‚
â”‚  STAGE 1: SUPERVISED FINE-TUNING (SFT)                                                          â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                                          â”‚
â”‚  â€¢ Start with pre-trained Qwen3-VL                                                              â”‚
â”‚  â€¢ Train on (screenshot, instruction, action) triplets from human demos                        â”‚
â”‚  â€¢ Learn basic GUI understanding and action prediction                                          â”‚
â”‚                                                                                                 â”‚
â”‚  STAGE 2: ONLINE REINFORCEMENT LEARNING (GRPO)                                                  â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                                 â”‚
â”‚                                                                                                 â”‚
â”‚  GRPO = Group Relative Policy Optimization                                                      â”‚
â”‚                                                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚                                THE GRPO ALGORITHM                                       â”‚    â”‚
â”‚  â”‚                                                                                         â”‚    â”‚
â”‚  â”‚   for each state s (screenshot + task):                                                 â”‚    â”‚
â”‚  â”‚                                                                                         â”‚    â”‚
â”‚  â”‚       # 1. Sample N actions from current policy                                         â”‚    â”‚
â”‚  â”‚       actions = [model.generate() for _ in range(8)]                                   â”‚    â”‚
â”‚  â”‚       # e.g., [CLICK(100,200), CLICK(105,198), CLICK(500,300), ...]                    â”‚    â”‚
â”‚  â”‚                                                                                         â”‚    â”‚
â”‚  â”‚       # 2. Compute reward for each action                                               â”‚    â”‚
â”‚  â”‚       rewards = [1.0 if inside_target_box(a) else 0.0 for a in actions]                â”‚    â”‚
â”‚  â”‚       # e.g., [1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]                                 â”‚    â”‚
â”‚  â”‚                                                                                         â”‚    â”‚
â”‚  â”‚       # 3. Normalize within group (KEY INNOVATION!)                                     â”‚    â”‚
â”‚  â”‚       mean_r = mean(rewards)  # 0.375                                                   â”‚    â”‚
â”‚  â”‚       std_r = std(rewards)    # 0.48                                                    â”‚    â”‚
â”‚  â”‚       advantages = [(r - mean_r) / std_r for r in rewards]                              â”‚    â”‚
â”‚  â”‚       # [+1.3, +1.3, -0.78, -0.78, +1.3, -0.78, -0.78, -0.78]                          â”‚    â”‚
â”‚  â”‚                                                                                         â”‚    â”‚
â”‚  â”‚       # 4. Policy gradient update                                                       â”‚    â”‚
â”‚  â”‚       loss = -sum(log_prob(a) * adv for a, adv in zip(actions, advantages))             â”‚    â”‚
â”‚  â”‚       optimizer.step(loss)                                                              â”‚    â”‚
â”‚  â”‚                                                                                         â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                                                 â”‚
â”‚  WHY GRPO IS SIMPLER THAN PPO:                                                                  â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                                                  â”‚
â”‚  â€¢ PPO needs a separate "critic" network to estimate value                                     â”‚
â”‚  â€¢ GRPO just normalizes rewards within the sampled group                                       â”‚
â”‚  â€¢ No critic = less GPU memory = larger batch sizes = faster training                          â”‚
â”‚                                                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Multimodal Support: Images, Video, and Advanced Mechanisms

### Unified Image & Video Pipeline

A hallmark of Qwen2-VL was treating video within the same architecture as images (rather than requiring a separate video-specific model).

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              UNIFIED IMAGE & VIDEO PROCESSING                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                                 â”‚
â”‚  QWEN2-VL VIDEO APPROACH:                                                                       â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                                                       â”‚
â”‚                                                                                                 â”‚
â”‚    1. Sample videos at 2 frames per second (2 Hz) during training/inference                   â”‚
â”‚    2. Apply 3D convolutions of depth 2 on adjacent frames' patches                            â”‚
â”‚    3. Creates "spatiotemporal tube" patches spanning 2 consecutive frames                     â”‚
â”‚                                                                                                 â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚    â”‚                                                                                        â”‚   â”‚
â”‚    â”‚   Frame t    Frame t+1                  3D Conv (depth=2)                             â”‚   â”‚
â”‚    â”‚   â”Œâ”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                           â”‚   â”‚
â”‚    â”‚   â”‚patchâ”‚    â”‚patchâ”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º   â”‚ Spatiotemporal  â”‚                           â”‚   â”‚
â”‚    â”‚   â”‚ (i) â”‚    â”‚ (i) â”‚                    â”‚   Tube Patch    â”‚                           â”‚   â”‚
â”‚    â”‚   â””â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”˜                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                           â”‚   â”‚
â”‚    â”‚                                                                                        â”‚   â”‚
â”‚    â”‚   BENEFIT: Motion features encoded without exploding sequence length                  â”‚   â”‚
â”‚    â”‚   Combining 2 frames into 1 patch HALVES the token count per temporal unit            â”‚   â”‚
â”‚    â”‚                                                                                        â”‚   â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                                                 â”‚
â”‚    â€¢ Every IMAGE is treated as two identical frames (fits the 3D scheme)                      â”‚
â”‚    â€¢ Max visual tokens per video: 16,384 during training                                      â”‚
â”‚    â€¢ With patch merging: supports videos ~20+ minutes in length                               â”‚
â”‚                                                                                                 â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚                                                                                                 â”‚
â”‚  QWEN3-VL VIDEO ENHANCEMENTS:                                                                   â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                                                   â”‚
â”‚                                                                                                 â”‚
â”‚    â€¢ Native 256K token context window for interleaved text+images+video                       â”‚
â”‚    â€¢ Can process HOURS-long videos with transcripts or frame-by-frame descriptions            â”‚
â”‚    â€¢ "Second-level indexing" - pinpoint events at specific time offsets accurately            â”‚
â”‚                                                                                                 â”‚
â”‚    Text-Timestamp Alignment:                                                                    â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚    â”‚  [frame_0] <@ 0.0 seconds>                                                             â”‚   â”‚
â”‚    â”‚  [frame_1] <@ 0.5 seconds>                                                             â”‚   â”‚
â”‚    â”‚  [frame_2] <@ 1.0 seconds>                                                             â”‚   â”‚
â”‚    â”‚  ...                                                                                    â”‚   â”‚
â”‚    â”‚  [frame_N] <@ 120.0 seconds>                                                           â”‚   â”‚
â”‚    â”‚                                                                                        â”‚   â”‚
â”‚    â”‚  Model can output: "At <@ 5.0s>, a cat enters the scene"                              â”‚   â”‚
â”‚    â”‚  Model can answer: "What happened between 00:10 and 00:20 in the video?"              â”‚   â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                                                 â”‚
â”‚    â€¢ Ranks #1 on MMMU (Massive Multimodal Multitask Unified benchmark)                        â”‚
â”‚    â€¢ Excels at visual mathematical reasoning (MathVista, MathVision)                          â”‚
â”‚                                                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Efficient Video Sampling (EVS) - Deep Dive

EVS is a plug-and-play method to prune redundant tokens by detecting static patches across frames.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              EVS: EFFICIENT VIDEO SAMPLING (DETAILED)                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                                 â”‚
â”‚  HOW EVS WORKS:                                                                                 â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                                                                 â”‚
â”‚                                                                                                 â”‚
â”‚  1. COMPUTE PATCH SIMILARITY: For each patch position, compare across adjacent frames         â”‚
â”‚                                                                                                 â”‚
â”‚     Frame t    Frame t+1    Similarity                                                         â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”                                                                         â”‚
â”‚     â”‚ 0.8 â”‚    â”‚ 0.8 â”‚  â†’  0.99 (nearly identical, PRUNE)                                     â”‚
â”‚     â””â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”˜                                                                         â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”                                                                         â”‚
â”‚     â”‚ cat â”‚    â”‚ dog â”‚  â†’  0.15 (very different, KEEP)                                        â”‚
â”‚     â””â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”˜                                                                         â”‚
â”‚                                                                                                 â”‚
â”‚  2. THRESHOLD-BASED PRUNING: Patches above similarity threshold are merged                    â”‚
â”‚                                                                                                 â”‚
â”‚  3. POSITION-AWARE PRESERVATION: Maintains original RoPE indices for retained patches         â”‚
â”‚     â€¢ The model can still attend correctly to the compressed sequence                         â”‚
â”‚     â€¢ Spatial relationships preserved even after pruning                                      â”‚
â”‚                                                                                                 â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚                                                                                                 â”‚
â”‚  EXAMPLE: SURVEILLANCE VIDEO                                                                    â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                                                   â”‚
â”‚                                                                                                 â”‚
â”‚    Input: 5-minute hallway surveillance (600 frames @ 2fps)                                    â”‚
â”‚                                                                                                 â”‚
â”‚    Without EVS:                                                                                 â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚    â”‚ Frame 1 â–ˆâ–ˆ Frame 2 â–ˆâ–ˆ Frame 3 â–ˆâ–ˆ ... Frame 600 â–ˆâ–ˆ                                   â”‚    â”‚
â”‚    â”‚ ALL frames processed â†’ 96,000 tokens â†’ OOM on most GPUs!                            â”‚    â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                                                 â”‚
â”‚    With EVS (75% pruning):                                                                     â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚    â”‚ Frame 1 â–ˆâ–ˆ Frame 2 â–‘â–‘ Frame 3 â–‘â–‘ Frame 4 â–ˆâ–ˆ ... (only motion frames kept)          â”‚    â”‚
â”‚    â”‚ 150 frames kept â†’ 24,000 tokens â†’ Fits on A100!                                    â”‚    â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                                                 â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚                                                                                                 â”‚
â”‚  PERFORMANCE BENCHMARKS (From NVIDIA Research):                                                 â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                                â”‚
â”‚                                                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Video Type         â”‚ Pruning Rate     â”‚ Accuracy Loss      â”‚ Speed Improvement           â”‚  â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚
â”‚  â”‚ Static scenes      â”‚ 75%              â”‚ <1%                â”‚ 4Ã— faster                   â”‚  â”‚
â”‚  â”‚ (surveillance)     â”‚                  â”‚                    â”‚                             â”‚  â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚
â”‚  â”‚ Moderate motion    â”‚ 50%              â”‚ 1-2%               â”‚ 2Ã— faster                   â”‚  â”‚
â”‚  â”‚ (lectures, talks)  â”‚                  â”‚                    â”‚                             â”‚  â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚
â”‚  â”‚ High motion        â”‚ 30%              â”‚ 2-3%               â”‚ 1.4Ã— faster                 â”‚  â”‚
â”‚  â”‚ (sports, action)   â”‚                  â”‚                    â”‚                             â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                                                 â”‚
â”‚  VLLM INTEGRATION:                                                                              â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                                                              â”‚
â”‚                                                                                                 â”‚
â”‚    Enable EVS with: --video-pruning-rate 0.5                                                   â”‚
â”‚                                                                                                 â”‚
â”‚    mm_processor_kwargs={                                                                        â”‚
â”‚        "video_pruning_rate": 0.5,  # Prune 50% of similar frames                               â”‚
â”‚    }                                                                                            â”‚
â”‚                                                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### DeepStack: Multi-Level Vision Features

DeepStack creates multiple entry points for visual features in the LLM decoder.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              DEEPSTACK: MULTI-LEVEL FEATURE FUSION                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                                 â”‚
â”‚  THE PROBLEM WITH SINGLE-LAYER OUTPUT:                                                          â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                                         â”‚
â”‚                                                                                                 â”‚
â”‚    Standard approach: Only FINAL ViT layer output feeds into LLM                               â”‚
â”‚                                                                                                 â”‚
â”‚    ViT Layer 0  â†’ Layer 8  â†’ Layer 16 â†’ Layer 24 â†’ Layer 32 â†’ [Output] â†’ LLM                  â”‚
â”‚       edges       shapes      patterns   objects    concepts                                    â”‚
â”‚       textures                                                                                  â”‚
â”‚                                                                                                 â”‚
â”‚    PROBLEM: Fine details from early layers get "washed out" by deeper layers                  â”‚
â”‚             Small text, thin lines, subtle edges are LOST                                      â”‚
â”‚                                                                                                 â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚                                                                                                 â”‚
â”‚  DEEPSTACK SOLUTION (Qwen3-VL):                                                                 â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                                                 â”‚
â”‚                                                                                                 â”‚
â”‚    Extract features at MULTIPLE layers and inject them into corresponding LLM layers          â”‚
â”‚                                                                                                 â”‚
â”‚    ViT Layer 8  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º LLM Layer 0           â”‚
â”‚         â”‚                                                                    â”‚                  â”‚
â”‚         â”‚  (edge/texture features)                                           â”‚                  â”‚
â”‚         â”‚                                                                    â–¼                  â”‚
â”‚    ViT Layer 16 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º LLM Layer 1           â”‚
â”‚         â”‚                                                                    â”‚                  â”‚
â”‚         â”‚  (shape/structure features)                                        â”‚                  â”‚
â”‚         â”‚                                                                    â–¼                  â”‚
â”‚    ViT Layer 24 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º LLM Layer 2           â”‚
â”‚         â”‚                                                                    â”‚                  â”‚
â”‚         â”‚  (pattern/widget features)                                         â”‚                  â”‚
â”‚         â”‚                                                                    â–¼                  â”‚
â”‚    ViT Layer 32 â”€â”€â”€â”€â”€â–º Main Merger â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º LLM Embedding          â”‚
â”‚                        (semantic features)                                                      â”‚
â”‚                                                                                                 â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚                                                                                                 â”‚
â”‚  IMPLEMENTATION DETAILS:                                                                        â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                                                        â”‚
â”‚                                                                                                 â”‚
â”‚    # Vision encoder outputs multi-scale features                                               â”‚
â”‚    deepstack_visual_indexes = [8, 16, 24]  # Which ViT layers to extract                      â”‚
â”‚                                                                                                 â”‚
â”‚    # Output format from vision encoder:                                                         â”‚
â”‚    vision_output = [main_emb | ds_emb_0 | ds_emb_1 | ds_emb_2]                                 â”‚
â”‚                                                                                                 â”‚
â”‚    # Split into components:                                                                     â”‚
â”‚    multimodal_embeddings_main = output[:, :visual_dim]        # Final layer                   â”‚
â”‚    multimodal_embeddings_multiscale = output[:, visual_dim:]  # Early layers                  â”‚
â”‚                                                                                                 â”‚
â”‚    # Inject into early LLM layers:                                                              â”‚
â”‚    for layer_idx, layer in enumerate(self.layers):                                             â”‚
â”‚        hidden_states = layer(hidden_states)                                                     â”‚
â”‚        if layer_idx < len(deepstack_features):                                                 â”‚
â”‚            hidden_states = hidden_states + deepstack_features[layer_idx]                       â”‚
â”‚                                                                                                 â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚                                                                                                 â”‚
â”‚  BENEFITS FOR DIFFERENT TASKS:                                                                  â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                                                 â”‚
â”‚                                                                                                 â”‚
â”‚    GUI Agents:                                                                                  â”‚
â”‚    â€¢ Layer 8 features: Button borders, icon edges â†’ Precise click targets                     â”‚
â”‚    â€¢ Layer 16 features: UI component shapes â†’ Widget identification                           â”‚
â”‚    â€¢ Layer 24 features: Layout patterns â†’ Navigation understanding                            â”‚
â”‚                                                                                                 â”‚
â”‚    Document OCR:                                                                                â”‚
â”‚    â€¢ Layer 8 features: Character strokes, thin lines â†’ Small text recognition                â”‚
â”‚    â€¢ Layer 16 features: Word boundaries, table cells â†’ Layout parsing                         â”‚
â”‚    â€¢ Layer 24 features: Section headers, diagrams â†’ Document structure                        â”‚
â”‚                                                                                                 â”‚
â”‚    Medical Imaging:                                                                             â”‚
â”‚    â€¢ Layer 8 features: Tissue textures, fine structures â†’ Lesion detection                   â”‚
â”‚    â€¢ Layer 16 features: Organ boundaries â†’ Anatomical localization                            â”‚
â”‚    â€¢ Layer 24 features: Pathological patterns â†’ Diagnosis support                             â”‚
â”‚                                                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Training and Inference Pipelines

### Three-Stage Training Regimen

Both Qwen2-VL and Qwen3-VL follow a multi-stage training strategy:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              THREE-STAGE TRAINING PIPELINE                                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                                 â”‚
â”‚  STAGE 1: VISION ENCODER ALIGNMENT                                                              â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                                              â”‚
â”‚                                                                                                 â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚    â”‚  Goal: Teach ViT to produce embeddings the LLM can understand                        â”‚   â”‚
â”‚    â”‚                                                                                        â”‚   â”‚
â”‚    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                         â”‚   â”‚
â”‚    â”‚  â”‚  ViT Encoder â”‚      â”‚  Projection  â”‚      â”‚  LLM (frozen)â”‚                         â”‚   â”‚
â”‚    â”‚  â”‚  (trainable) â”‚  â†’   â”‚  Layer       â”‚  â†’   â”‚              â”‚                         â”‚   â”‚
â”‚    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                         â”‚   â”‚
â”‚    â”‚                                                                                        â”‚   â”‚
â”‚    â”‚  Data: Image-text pairs, image captioning, OCR data                                   â”‚   â”‚
â”‚    â”‚  Objective: Align visual representations with language model embedding space         â”‚   â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                                                 â”‚
â”‚  STAGE 2: JOINT MULTIMODAL TRAINING                                                             â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                                             â”‚
â”‚                                                                                                 â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚    â”‚  Goal: Learn to reason across images, videos, and text together                      â”‚   â”‚
â”‚    â”‚                                                                                        â”‚   â”‚
â”‚    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                         â”‚   â”‚
â”‚    â”‚  â”‚  ViT Encoder â”‚      â”‚  Projection  â”‚      â”‚     LLM      â”‚                         â”‚   â”‚
â”‚    â”‚  â”‚  (trainable) â”‚  â†’   â”‚  Layer       â”‚  â†’   â”‚  (trainable) â”‚                         â”‚   â”‚
â”‚    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                         â”‚   â”‚
â”‚    â”‚                                                                                        â”‚   â”‚
â”‚    â”‚  Data:                                                                                 â”‚   â”‚
â”‚    â”‚  â€¢ Image-text pairs (captioning, VQA)                                                 â”‚   â”‚
â”‚    â”‚  â€¢ Interleaved text with images (documents, webpages)                                 â”‚   â”‚
â”‚    â”‚  â€¢ Video dialogues (temporal reasoning)                                               â”‚   â”‚
â”‚    â”‚  â€¢ Image knowledge datasets (world knowledge)                                         â”‚   â”‚
â”‚    â”‚                                                                                        â”‚   â”‚
â”‚    â”‚  Objective: Next-token prediction on multimodal sequences                            â”‚   â”‚
â”‚    â”‚  Scale: Qwen2-VL investigated scaling laws â†’ bigger model + more data = better       â”‚   â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                                                 â”‚
â”‚  STAGE 3: INSTRUCTION FINE-TUNING (RLHF/SFT)                                                    â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                                    â”‚
â”‚                                                                                                 â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚    â”‚  Goal: Align model with human preferences and instruction following                  â”‚   â”‚
â”‚    â”‚                                                                                        â”‚   â”‚
â”‚    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                         â”‚   â”‚
â”‚    â”‚  â”‚  ViT Encoder â”‚      â”‚  Projection  â”‚      â”‚     LLM      â”‚                         â”‚   â”‚
â”‚    â”‚  â”‚   (frozen)   â”‚  â†’   â”‚  Layer       â”‚  â†’   â”‚  (trainable) â”‚                         â”‚   â”‚
â”‚    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                         â”‚   â”‚
â”‚    â”‚                                                                                        â”‚   â”‚
â”‚    â”‚  Methods: RLHF (Reinforcement Learning from Human Feedback)                           â”‚   â”‚
â”‚    â”‚           SFT (Supervised Fine-Tuning on instruction data)                            â”‚   â”‚
â”‚    â”‚                                                                                        â”‚   â”‚
â”‚    â”‚  Qwen3-VL Variants:                                                                    â”‚   â”‚
â”‚    â”‚  â€¢ Instruct: Polite, safety-aligned, follows user instructions                       â”‚   â”‚
â”‚    â”‚  â€¢ Thinking: Enhanced reasoning, less filtered, for complex tasks                    â”‚   â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Inference Pipeline and vLLM Integration

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              VLLM INFERENCE ARCHITECTURE                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                                 â”‚
â”‚  PAGEDATTENTION: EFFICIENT KV CACHE MANAGEMENT                                                  â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                                â”‚
â”‚                                                                                                 â”‚
â”‚    Problem: Standard KV cache allocates one giant contiguous tensor                            â”‚
â”‚             â†’ Memory fragmentation with variable-length prompts                                â”‚
â”‚             â†’ Can't share KV cache between requests with common prefixes                       â”‚
â”‚                                                                                                 â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚    â”‚  NAIVE KV CACHE (Wasteful)            PAGEDATTENTION (Efficient)                      â”‚   â”‚
â”‚    â”‚                                                                                        â”‚   â”‚
â”‚    â”‚  Request 1: [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘]    Request 1: [â–ˆ][â–ˆ][â–ˆ]                            â”‚   â”‚
â”‚    â”‚  Request 2: [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘]    Request 2: [â–ˆ][â–ˆ][â–ˆ][â–ˆ][â–ˆ]                      â”‚   â”‚
â”‚    â”‚  Request 3: [â–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘]    Request 3: [â–ˆ]                                  â”‚   â”‚
â”‚    â”‚                                                                                        â”‚   â”‚
â”‚    â”‚  Wasted: 60% of allocated memory      Wasted: <5% (small fragmentation)              â”‚   â”‚
â”‚    â”‚                                                                                        â”‚   â”‚
â”‚    â”‚  Each [â–ˆ] = 256 tokens of KV cache (one "page")                                       â”‚   â”‚
â”‚    â”‚  Pages allocated on-demand, freed when request completes                              â”‚   â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                                                 â”‚
â”‚    Benefits:                                                                                    â”‚
â”‚    â€¢ 2.5Ã—â€“5Ã— less memory overhead compared to naive caching                                   â”‚
â”‚    â€¢ Supports far more concurrent requests                                                     â”‚
â”‚    â€¢ Enables efficient sharing of prefix KV segments                                          â”‚
â”‚                                                                                                 â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚                                                                                                 â”‚
â”‚  AUTOMATIC PREFIX CACHING                                                                       â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                                                       â”‚
â”‚                                                                                                 â”‚
â”‚    If multiple requests share the same initial tokens (system prompt),                        â”‚
â”‚    reuse the previously computed KV cache for that prefix.                                    â”‚
â”‚                                                                                                 â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚    â”‚                                                                                        â”‚   â”‚
â”‚    â”‚  Request 1: [System Prompt: You are a GUI agent...] + [User: Click settings]         â”‚   â”‚
â”‚    â”‚             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ CACHED â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€ NEW â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚   â”‚
â”‚    â”‚                                                                                        â”‚   â”‚
â”‚    â”‚  Request 2: [System Prompt: You are a GUI agent...] + [User: Open browser]           â”‚   â”‚
â”‚    â”‚             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ REUSED â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€ NEW â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚   â”‚
â”‚    â”‚                                                                                        â”‚   â”‚
â”‚    â”‚  Request 2 skips computing KV cache for 500 tokens â†’ Much faster!                    â”‚   â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                                                 â”‚
â”‚    Enable: enable_prefix_caching=True                                                          â”‚
â”‚                                                                                                 â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚                                                                                                 â”‚
â”‚  CHUNKED PREFILL (STREAMED PREFILL)                                                             â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                                             â”‚
â”‚                                                                                                 â”‚
â”‚    Problem: Long input (50K tokens) must be fully encoded before any output                   â”‚
â”‚    Solution: Process in chunks, start generation before prefill completes                     â”‚
â”‚                                                                                                 â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚    â”‚                                                                                        â”‚   â”‚
â”‚    â”‚  STANDARD PREFILL:                                                                     â”‚   â”‚
â”‚    â”‚  [Encode 50K tokens â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€] â†’ [Start generating]       â”‚   â”‚
â”‚    â”‚                              Long wait time                                           â”‚   â”‚
â”‚    â”‚                                                                                        â”‚   â”‚
â”‚    â”‚  CHUNKED PREFILL:                                                                      â”‚   â”‚
â”‚    â”‚  [Encode 5K] â†’ [Start generating partial] â†’ [Continue encoding 45K in background]    â”‚   â”‚
â”‚    â”‚       â”‚                                                                                â”‚   â”‚
â”‚    â”‚       â””â”€â”€â–º User sees first tokens ~30% faster!                                        â”‚   â”‚
â”‚    â”‚                                                                                        â”‚   â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                                                 â”‚
â”‚    Enable: enable_chunked_prefill=True                                                         â”‚
â”‚    Critical for Qwen3-VL's 256K context window                                                 â”‚
â”‚                                                                                                 â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚                                                                                                 â”‚
â”‚  FLASHATTENTION INTEGRATION                                                                     â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                                                     â”‚
â”‚                                                                                                 â”‚
â”‚    Qwen3-VL recommends: attn_implementation="flash_attention_2"                                â”‚
â”‚                                                                                                 â”‚
â”‚    FlashAttention uses CUDA kernels to compute attention with:                                 â”‚
â”‚    â€¢ Lower memory usage (no full attention matrix materialization)                            â”‚
â”‚    â€¢ Higher throughput (kernel fusion, memory hierarchy optimization)                         â”‚
â”‚    â€¢ Critical for multi-image and video scenarios                                              â”‚
â”‚                                                                                                 â”‚
â”‚    Requirements:                                                                                â”‚
â”‚    â€¢ SM 8.0+ for FlashAttention 2 (A100, H100)                                                â”‚
â”‚    â€¢ SM 9.0+ for FlashAttention 3 (H100, B200)                                                â”‚
â”‚    â€¢ T4 (SM 7.5): Falls back to TORCH_SDPA                                                    â”‚
â”‚                                                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### Why Qwen3-VL is Ideal for GUI Agents

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          WHY QWEN3-VL IS IDEAL FOR GUI AGENTS                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                                 â”‚
â”‚  1. DEEPSTACK = FINE-GRAINED UI DETECTION                                                       â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                                      â”‚
â”‚                                                                                                 â”‚
â”‚     GUI Challenge: Buttons and icons are TINY (20Ã—20 pixels on a 1080Ã—2400 screen)             â”‚
â”‚                                                                                                 â”‚
â”‚     DeepStack Solution:                                                                         â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚     â”‚ Vision Layer 8:  Edge detection, button borders â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚      â”‚
â”‚     â”‚ Vision Layer 16: Shape patterns, icon outlines â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚â”‚      â”‚
â”‚     â”‚ Vision Layer 24: Widget structures, UI components â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚   â”‚â”‚      â”‚
â”‚     â”‚ Vision Layer 32: Semantic meaning ("Settings button") â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚      â”‚   â”‚â”‚      â”‚
â”‚     â”‚                                                                 â”‚      â”‚      â”‚   â”‚â”‚      â”‚
â”‚     â”‚                     LLM Layer 0  â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”˜â”‚      â”‚
â”‚     â”‚                     LLM Layer 1  â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”˜    â”‚      â”‚
â”‚     â”‚                     LLM Layer 2  â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”˜           â”‚      â”‚
â”‚     â”‚                     LLM Layer 3+ â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚      â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚                                                                                                 â”‚
â”‚     All scales available to LLM â†’ Better at finding small UI elements!                         â”‚
â”‚                                                                                                 â”‚
â”‚  2. HIGH RESOLUTION SUPPORT                                                                     â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                                                     â”‚
â”‚                                                                                                 â”‚
â”‚     Phone screens: 1080Ã—2400 (very tall!)                                                       â”‚
â”‚     Tablets: 2560Ã—1600                                                                          â”‚
â”‚     Desktop: 1920Ã—1080 or higher                                                                â”‚
â”‚                                                                                                 â”‚
â”‚     Qwen3-VL handles this via:                                                                  â”‚
â”‚     â€¢ Learned position embeddings with bilinear interpolation                                  â”‚
â”‚     â€¢ Dynamic resolution (no fixed aspect ratio)                                               â”‚
â”‚     â€¢ Up to 24,576 visual tokens possible                                                       â”‚
â”‚                                                                                                 â”‚
â”‚  3. EVS FOR EFFICIENT TRAINING DATA PROCESSING                                                  â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                                  â”‚
â”‚                                                                                                 â”‚
â”‚     Training data: Screen recordings of humans using apps                                       â”‚
â”‚     Problem: Most frames are nearly identical (user reading, not scrolling)                    â”‚
â”‚     Solution: EVS prunes similar frames automatically                                           â”‚
â”‚                                                                                                 â”‚
â”‚     50-frame video:                                                                             â”‚
â”‚     â€¢ Without EVS: 50 frames Ã— 2000 tokens = 100,000 tokens (OOM!)                              â”‚
â”‚     â€¢ With EVS (50% pruning): 25 frames Ã— 2000 = 50,000 tokens                                 â”‚
â”‚                                                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### MAI-UI Inference Pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        MAI-UI INFERENCE PIPELINE                                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                                 â”‚
â”‚  USER: "Send a message to John saying 'Hello!'"                                                 â”‚
â”‚                                                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚                          STEP 1: CAPTURE SCREENSHOT                                     â”‚    â”‚
â”‚  â”‚                                                                                         â”‚    â”‚
â”‚  â”‚   Android Device/Emulator                                                               â”‚    â”‚
â”‚  â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                         â”‚    â”‚
â”‚  â”‚   â”‚ ğŸ“± Home Screen            â”‚                                                         â”‚    â”‚
â”‚  â”‚   â”‚                           â”‚  â†’ Capture 1080Ã—2400 screenshot                         â”‚    â”‚
â”‚  â”‚   â”‚  [Messages] [Chrome]      â”‚  â†’ Resize to fit max_pixels                              â”‚    â”‚
â”‚  â”‚   â”‚  [Camera]   [Settings]    â”‚  â†’ ~2000 visual tokens                                   â”‚    â”‚
â”‚  â”‚   â”‚                           â”‚                                                         â”‚    â”‚
â”‚  â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                                         â”‚    â”‚
â”‚  â”‚                                                                                         â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                           â”‚                                                     â”‚
â”‚                                           â–¼                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚                          STEP 2: PROCESS WITH QWEN3-VL                                  â”‚    â”‚
â”‚  â”‚                                                                                         â”‚    â”‚
â”‚  â”‚   Prompt template:                                                                      â”‚    â”‚
â”‚  â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚    â”‚
â”‚  â”‚   â”‚ <|im_start|>system                                                              â”‚  â”‚    â”‚
â”‚  â”‚   â”‚ You are a GUI agent. Given a screenshot and task, output the next action.       â”‚  â”‚    â”‚
â”‚  â”‚   â”‚ <|im_end|>                                                                      â”‚  â”‚    â”‚
â”‚  â”‚   â”‚ <|im_start|>user                                                                â”‚  â”‚    â”‚
â”‚  â”‚   â”‚ <|vision_start|><|image_pad|><|vision_end|>                                     â”‚  â”‚    â”‚
â”‚  â”‚   â”‚ Task: Send a message to John saying 'Hello!'                                    â”‚  â”‚    â”‚
â”‚  â”‚   â”‚ Current step: 1/10                                                              â”‚  â”‚    â”‚
â”‚  â”‚   â”‚ Previous actions: None                                                          â”‚  â”‚    â”‚
â”‚  â”‚   â”‚ <|im_end|>                                                                      â”‚  â”‚    â”‚
â”‚  â”‚   â”‚ <|im_start|>assistant                                                           â”‚  â”‚    â”‚
â”‚  â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚    â”‚
â”‚  â”‚                                                                                         â”‚    â”‚
â”‚  â”‚   Model output: "CLICK(150, 500)"  # Click on Messages app                             â”‚    â”‚
â”‚  â”‚                                                                                         â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                           â”‚                                                     â”‚
â”‚                                           â–¼                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚                          STEP 3: EXECUTE ACTION                                         â”‚    â”‚
â”‚  â”‚                                                                                         â”‚    â”‚
â”‚  â”‚   Parse action: CLICK(150, 500)                                                         â”‚    â”‚
â”‚  â”‚   Send ADB command: adb shell input tap 150 500                                         â”‚    â”‚
â”‚  â”‚   Wait for screen to update (~500ms)                                                    â”‚    â”‚
â”‚  â”‚                                                                                         â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                           â”‚                                                     â”‚
â”‚                                           â–¼                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚                          STEP 4: REPEAT UNTIL DONE                                      â”‚    â”‚
â”‚  â”‚                                                                                         â”‚    â”‚
â”‚  â”‚   Screenshot: Messages app opened                                                       â”‚    â”‚
â”‚  â”‚   Model output: "CLICK(300, 200)"  # Click on John's conversation                      â”‚    â”‚
â”‚  â”‚   Execute: adb shell input tap 300 200                                                  â”‚    â”‚
â”‚  â”‚                                                                                         â”‚    â”‚
â”‚  â”‚   Screenshot: Conversation with John                                                    â”‚    â”‚
â”‚  â”‚   Model output: "CLICK(540, 2300)"  # Click on text input field                        â”‚    â”‚
â”‚  â”‚   Execute: adb shell input tap 540 2300                                                 â”‚    â”‚
â”‚  â”‚                                                                                         â”‚    â”‚
â”‚  â”‚   Screenshot: Keyboard visible                                                          â”‚    â”‚
â”‚  â”‚   Model output: "TYPE('Hello!')"  # Type the message                                   â”‚    â”‚
â”‚  â”‚   Execute: adb shell input text "Hello!"                                                â”‚    â”‚
â”‚  â”‚                                                                                         â”‚    â”‚
â”‚  â”‚   Screenshot: Message typed                                                             â”‚    â”‚
â”‚  â”‚   Model output: "CLICK(1000, 2300)"  # Click send button                               â”‚    â”‚
â”‚  â”‚   Execute: adb shell input tap 1000 2300                                                â”‚    â”‚
â”‚  â”‚                                                                                         â”‚    â”‚
â”‚  â”‚   Model output: "DONE"  # Task completed!                                               â”‚    â”‚
â”‚  â”‚                                                                                         â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Device-Cloud Collaboration

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        DEVICE-CLOUD COLLABORATION                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                                 â”‚
â”‚  PROBLEM: Large models (8B+) can't run on-device (phone, tablet)                                â”‚
â”‚  SOLUTION: Route tasks based on complexity                                                      â”‚
â”‚                                                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚                 â”‚                    â”‚                   CLOUD                          â”‚    â”‚
â”‚  â”‚  ğŸ“± DEVICE      â”‚                    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚    â”‚
â”‚  â”‚                 â”‚                    â”‚  â”‚ MAI-UI-8B/32B/235B                          â”‚â”‚    â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚    Complex task    â”‚  â”‚ Running on H100/B200                        â”‚â”‚    â”‚
â”‚  â”‚  â”‚ MAI-UI-2B â”‚  â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º â”‚  â”‚                                             â”‚â”‚    â”‚
â”‚  â”‚  â”‚ (on-device)â”‚ â”‚                    â”‚  â”‚ â€¢ High accuracy                             â”‚â”‚    â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚                    â”‚  â”‚ â€¢ Complex UI understanding                  â”‚â”‚    â”‚
â”‚  â”‚       â”‚         â”‚                    â”‚  â”‚ â€¢ Multi-step planning                       â”‚â”‚    â”‚
â”‚  â”‚       â”‚         â”‚                    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚    â”‚
â”‚  â”‚  Simple task    â”‚                    â”‚                                                  â”‚    â”‚
â”‚  â”‚       â”‚         â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚  â”‚       â–¼         â”‚                                                                           â”‚
â”‚  â”‚  Execute        â”‚                                                                           â”‚
â”‚  â”‚  locally        â”‚                                                                           â”‚
â”‚  â”‚                 â”‚                                                                           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                                                           â”‚
â”‚                                                                                                 â”‚
â”‚  ROUTING LOGIC:                                                                                 â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                                                                 â”‚
â”‚                                                                                                 â”‚
â”‚  def route_task(task, screenshot):                                                              â”‚
â”‚      complexity = estimate_complexity(task)  # NLP classifier                                  â”‚
â”‚                                                                                                 â”‚
â”‚      if complexity == "simple":  # e.g., "Click the back button"                               â”‚
â”‚          return device_model.predict(screenshot)  # Fast, private                              â”‚
â”‚      else:  # e.g., "Book a flight to Tokyo for next week"                                     â”‚
â”‚          return cloud_model.predict(screenshot)   # Accurate, powerful                         â”‚
â”‚                                                                                                 â”‚
â”‚  BENEFITS:                                                                                      â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                                                      â”‚
â”‚  â€¢ Privacy: Simple actions stay on-device (no data sent to cloud)                              â”‚
â”‚  â€¢ Latency: Simple actions are instant (~100ms on-device vs ~500ms cloud)                      â”‚
â”‚  â€¢ Accuracy: Complex tasks get the best model (8B+ parameters)                                 â”‚
â”‚  â€¢ Cost: Only pay for cloud compute when needed                                                â”‚
â”‚                                                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### MAI-UI Memory Requirements

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        MAI-UI MEMORY REQUIREMENTS BY GPU                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                                 â”‚
â”‚  Model             â”‚ Weights  â”‚ KV Cache â”‚ Vision  â”‚ Total    â”‚ GPU Required                   â”‚
â”‚                    â”‚          â”‚ (2K ctx) â”‚ Encoder â”‚          â”‚                                â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• â”‚
â”‚  MAI-UI-2B         â”‚ ~4.5 GB  â”‚ ~1 GB    â”‚ ~2 GB   â”‚ ~8 GB    â”‚ T4 (16GB) âœ…                   â”‚
â”‚  MAI-UI-2B (4-bit) â”‚ ~1.5 GB  â”‚ ~1 GB    â”‚ ~2 GB   â”‚ ~5 GB    â”‚ T4 (16GB) âœ…âœ…                 â”‚
â”‚  MAI-UI-8B         â”‚ ~17 GB   â”‚ ~3 GB    â”‚ ~4 GB   â”‚ ~25 GB   â”‚ A100-40GB âœ…                   â”‚
â”‚  MAI-UI-8B (FP8)   â”‚ ~9 GB    â”‚ ~2 GB    â”‚ ~4 GB   â”‚ ~15 GB   â”‚ T4 âŒ, H100 âœ…                 â”‚
â”‚  MAI-UI-32B        â”‚ ~65 GB   â”‚ ~10 GB   â”‚ ~6 GB   â”‚ ~82 GB   â”‚ H100-80GB âš ï¸ tight             â”‚
â”‚  MAI-UI-235B-A22B  â”‚ ~50 GB*  â”‚ ~8 GB    â”‚ ~6 GB   â”‚ ~65 GB   â”‚ H100-80GB âœ… (MoE sparse)      â”‚
â”‚                    â”‚ *active  â”‚          â”‚         â”‚          â”‚                                â”‚
â”‚                                                                                                 â”‚
â”‚  LATENCY EXPECTATIONS:                                                                          â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                                                          â”‚
â”‚  T4 + MAI-UI-2B (4-bit): ~1.5-2s per action                                                    â”‚
â”‚  A100 + MAI-UI-8B:       ~300-500ms per action                                                 â”‚
â”‚  H100 + MAI-UI-8B (FP8): ~150-300ms per action                                                 â”‚
â”‚  B200 + MAI-UI-235B:     ~200-400ms per action                                                 â”‚
â”‚                                                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Complete Code Examples

### GPU-Specific Configurations

```python
from vllm import LLM, SamplingParams

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# T4 (16GB) - 4-bit Quantization
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def create_qwen3_vl_t4():
    """
    Qwen3-VL-4B on T4 with 4-bit quantization.
    
    Memory: ~4 GB weights + ~2 GB KV cache + ~2 GB vision = ~8 GB used
    Latency: ~1-1.5s per image
    """
    return LLM(
        model="Qwen/Qwen3-VL-4B-Instruct",
        trust_remote_code=True,
        dtype="half",                        # FP16 (T4 doesn't support BF16)
        quantization="bitsandbytes",         # 4-bit quantization
        load_format="bitsandbytes",
        gpu_memory_utilization=0.92,
        max_model_len=4096,
        enforce_eager=True,                  # Save memory by disabling CUDA graphs
        max_num_seqs=4,
        limit_mm_per_prompt={"image": 2, "video": 1},
        mm_processor_kwargs={
            "min_pixels": 784,
            "max_pixels": 500000,            # ~700Ã—700 max resolution
            "video_pruning_rate": 0.5,       # Keep 50% of video frames
        },
    )

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# A100-80GB - Full Precision
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def create_qwen3_vl_a100():
    """
    Qwen3-VL-8B on A100 with full BF16 precision.
    
    Memory: ~16 GB weights + ~8 GB KV cache + ~4 GB vision = ~28 GB used
    Latency: ~300-500ms per image
    """
    return LLM(
        model="Qwen/Qwen3-VL-8B-Instruct",
        trust_remote_code=True,
        dtype="bfloat16",
        gpu_memory_utilization=0.95,
        max_model_len=16384,
        enforce_eager=False,                 # Enable CUDA graphs for speed
        max_num_seqs=16,
        limit_mm_per_prompt={"image": 8, "video": 2},
        mm_processor_kwargs={
            "min_pixels": 784,
            "max_pixels": 2073600,           # 1920Ã—1080 full HD
            "video_pruning_rate": 0.3,
        },
        enable_prefix_caching=True,
        enable_chunked_prefill=True,
    )

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# H100 (80GB) - FP8 for Maximum Throughput
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def create_qwen3_vl_h100():
    """
    Qwen3-VL-8B on H100 with FP8 quantization.
    
    Memory: ~8 GB weights + ~8 GB KV cache + ~4 GB vision = ~20 GB used
    Latency: ~150-300ms per image
    """
    return LLM(
        model="Qwen/Qwen3-VL-8B-Instruct",
        trust_remote_code=True,
        dtype="bfloat16",
        quantization="fp8",                  # FP8 weights (2x smaller)
        kv_cache_dtype="fp8",                # FP8 KV cache
        gpu_memory_utilization=0.95,
        max_model_len=32768,
        enforce_eager=False,
        max_num_seqs=32,                     # High concurrency
        limit_mm_per_prompt={"image": 16, "video": 4},
        mm_processor_kwargs={
            "min_pixels": 784,
            "max_pixels": 2073600,
            "video_pruning_rate": 0.3,
        },
        enable_prefix_caching=True,
        enable_chunked_prefill=True,
    )

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# B200 (192GB) - Maximum Everything
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def create_qwen3_vl_b200():
    """
    Qwen3-VL-30B-A3B MoE on B200.
    
    Memory: ~60 GB weights + ~20 GB KV cache + ~6 GB vision = ~86 GB used
    Latency: ~200-400ms per image (MoE overhead)
    """
    return LLM(
        model="Qwen/Qwen3-VL-30B-A3B-Instruct",
        trust_remote_code=True,
        dtype="bfloat16",
        gpu_memory_utilization=0.95,
        max_model_len=65536,                 # 64K context
        enforce_eager=False,
        max_num_seqs=64,
        limit_mm_per_prompt={"image": 32, "video": 8},
        mm_processor_kwargs={
            "min_pixels": 784,
            "max_pixels": 4147200,           # 4K resolution
            "video_pruning_rate": 0.2,
        },
        enable_prefix_caching=True,
        enable_chunked_prefill=True,
    )
```

### GUI Agent Inference Example

```python
from vllm import SamplingParams

def run_gui_agent_step(llm, screenshot_path: str, task: str, history: list[str]):
    """
    Execute one step of GUI agent reasoning.
    
    Args:
        llm: vLLM model instance
        screenshot_path: Path to current screenshot
        task: User's task description
        history: List of previous actions taken
        
    Returns:
        Action string like "CLICK(542, 1203)" or "TYPE('Hello!')"
    """
    
    prompt = f"""<|im_start|>system
You are a GUI agent. Given a screenshot and task, output the next action.
Available actions:
- CLICK(x, y): Click at coordinates
- TYPE("text"): Type text
- SCROLL(x1, y1, x2, y2): Scroll from start to end
- PRESS_KEY(key): Press key (back, home, enter)
- DONE: Task is complete
<|im_end|>
<|im_start|>user
<|vision_start|><|image_pad|><|vision_end|>

Task: {task}
Previous actions: {history if history else 'None'}

What is the next action?
<|im_end|>
<|im_start|>assistant
"""
    
    inputs = [{
        "prompt": prompt,
        "multi_modal_data": {"image": screenshot_path}
    }]
    
    sampling_params = SamplingParams(
        temperature=0.0,      # Deterministic for GUI tasks
        max_tokens=50,
        stop=["<|im_end|>"]
    )
    
    outputs = llm.generate(inputs, sampling_params)
    return outputs[0].outputs[0].text.strip()


# Example usage
if __name__ == "__main__":
    import torch
    
    # Auto-select GPU configuration
    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9
    
    if gpu_memory < 20:
        llm = create_qwen3_vl_t4()
    elif gpu_memory < 50:
        llm = create_qwen3_vl_a100()
    else:
        llm = create_qwen3_vl_h100()
    
    # Run agent loop
    task = "Open Settings and enable Dark Mode"
    history = []
    
    for step in range(10):
        screenshot = f"screenshot_{step}.png"
        action = run_gui_agent_step(llm, screenshot, task, history)
        
        print(f"Step {step + 1}: {action}")
        
        if action == "DONE":
            print("Task completed!")
            break
            
        history.append(action)
```

---

## Comparative Analysis: Qwen2-VL vs Qwen3-VL

### Capability Improvements

Qwen3-VL is a major leap over Qwen2-VL in both breadth and depth of abilities:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              CAPABILITY COMPARISON                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                                 â”‚
â”‚  LANGUAGE ABILITY                                                                               â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                                                               â”‚
â”‚  â€¢ Qwen2-VL: Based on Qwen2 backbone, strong but not matching text-only LLMs                  â”‚
â”‚  â€¢ Qwen3-VL: "Surpasses comparable text-only backbones" on some NLP tasks                     â”‚
â”‚              Better training + MoE scaling = competitive even without images                   â”‚
â”‚                                                                                                 â”‚
â”‚  MULTILINGUAL OCR                                                                               â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                                                              â”‚
â”‚  â€¢ Qwen2-VL: ~10 languages supported                                                          â”‚
â”‚  â€¢ Qwen3-VL: 32 languages supported (3Ã— expansion)                                            â”‚
â”‚                                                                                                 â”‚
â”‚  MATH & STEM REASONING                                                                          â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                                                          â”‚
â”‚  â€¢ Qwen2-VL: Good at DocVQA (tables, math in documents)                                       â”‚
â”‚  â€¢ Qwen3-VL: State-of-the-art on MathVista, MathVision                                        â”‚
â”‚              Excels at visual math problems (charts, equations from images)                    â”‚
â”‚                                                                                                 â”‚
â”‚  AGENTIC CAPABILITIES                                                                           â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                                                           â”‚
â”‚  â€¢ Qwen2-VL: Suggested integration with robots (not demonstrated)                             â”‚
â”‚  â€¢ Qwen3-VL: Full "Visual Agent" capability                                                   â”‚
â”‚              - Operates PC/mobile GUIs                                                         â”‚
â”‚              - Recognizes elements, understands functions                                      â”‚
â”‚              - Invokes tools, completes tasks                                                  â”‚
â”‚              - Writes HTML/CSS from design images                                              â”‚
â”‚                                                                                                 â”‚
â”‚  BENCHMARK PERFORMANCE                                                                          â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                                                          â”‚
â”‚  â€¢ Qwen2-VL-72B: Comparable to GPT-4o and Claude 3.5 Sonnet                                   â”‚
â”‚  â€¢ Qwen3-VL: #1 on MMMU leaderboard (late 2025)                                               â”‚
â”‚              State-of-the-art across vision, language, and temporal reasoning                 â”‚
â”‚                                                                                                 â”‚
â”‚  VISUAL RECOGNITION                                                                             â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                                                             â”‚
â”‚  â€¢ Qwen2-VL: Good general recognition                                                         â”‚
â”‚  â€¢ Qwen3-VL: "Recognizes everything" - celebrities, anime, products,                          â”‚
â”‚              landmarks, flora/fauna, niche categories                                          â”‚
â”‚              Improved robustness to low-light, blur, tilted imagery                           â”‚
â”‚                                                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Video Token Handling Comparison

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              VIDEO HANDLING COMPARISON                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Feature                  â”‚ Qwen2-VL                     â”‚ Qwen3-VL                       â”‚  â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚
â”‚  â”‚ Native Context           â”‚ ~16K tokens                  â”‚ 256K tokens (16Ã— larger)       â”‚  â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚
â”‚  â”‚ Max Video Length         â”‚ ~20 minutes                  â”‚ ~2+ hours at 2fps              â”‚  â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚
â”‚  â”‚ Temporal Understanding   â”‚ Implicit via M-RoPE          â”‚ Explicit timestamp tokens      â”‚  â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚
â”‚  â”‚ Event Localization       â”‚ General answers              â”‚ "At <@5.0s>, X happens"       â”‚  â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚
â”‚  â”‚ EVS Support              â”‚ Not available at release     â”‚ Full support via vLLM          â”‚  â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚
â”‚  â”‚ Efficiency on Static     â”‚ Process all frames           â”‚ 75% pruning with EVS           â”‚  â”‚
â”‚  â”‚ Videos                   â”‚                              â”‚                                â”‚  â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚
â”‚  â”‚ Expandable Context       â”‚ Limited extrapolation        â”‚ Up to 1M with fine-tuning      â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                                                 â”‚
â”‚  PRACTICAL EXAMPLE:                                                                             â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                                                             â”‚
â”‚                                                                                                 â”‚
â”‚    2-hour video at 2fps = 14,400 frames                                                         â”‚
â”‚    Each frame ~10 tokens after merging = 144,000 tokens                                        â”‚
â”‚                                                                                                 â”‚
â”‚    Qwen2-VL: Would need to skip frames or truncate â†’ loses information                        â”‚
â”‚    Qwen3-VL: Fits within 256K context â†’ full video understanding                              â”‚
â”‚              With EVS 50%: Only 72,000 tokens â†’ even faster                                   â”‚
â”‚                                                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Model Size and Architecture Comparison

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              MODEL VARIANTS AND HARDWARE REQUIREMENTS                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Model                â”‚ Param Count       â”‚ Precision    â”‚ Min Hardware                   â”‚  â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚
â”‚  â”‚ Qwen2-VL-2B          â”‚ 2.2B (1.5B LLM +  â”‚ FP16/BF16    â”‚ 8-16 GB GPU (T4 or better)     â”‚  â”‚
â”‚  â”‚                      â”‚ 0.7B ViT)         â”‚              â”‚ ~6 GB in BF16, mobile capable  â”‚  â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚
â”‚  â”‚ Qwen2-VL-7B          â”‚ ~8.3B total       â”‚ FP16/BF16    â”‚ 16-24 GB GPU (T4 with int8)    â”‚  â”‚
â”‚  â”‚                      â”‚                   â”‚ or int8      â”‚ ~16 GB in BF16                 â”‚  â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚
â”‚  â”‚ Qwen2-VL-72B         â”‚ ~72.7B + 0.7B ViT â”‚ BF16         â”‚ 2Ã—80 GB A100 (multi-GPU)       â”‚  â”‚
â”‚  â”‚                      â”‚                   â”‚              â”‚ 144 GB in BF16                 â”‚  â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚
â”‚  â”‚ Qwen3-VL-2B          â”‚ 2B (dense)        â”‚ BF16/FP8     â”‚ 16 GB GPU                      â”‚  â”‚
â”‚  â”‚                      â”‚                   â”‚              â”‚ Similar to Qwen2-VL-2B         â”‚  â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚
â”‚  â”‚ Qwen3-VL-4B          â”‚ 4B (dense)        â”‚ BF16/FP8     â”‚ 24 GB GPU                      â”‚  â”‚
â”‚  â”‚                      â”‚                   â”‚              â”‚ New size, fills 2B-7B gap      â”‚  â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚
â”‚  â”‚ Qwen3-VL-8B          â”‚ 8B (dense)        â”‚ BF16/FP8     â”‚ 40-48 GB GPU                   â”‚  â”‚
â”‚  â”‚                      â”‚                   â”‚              â”‚ Single 40GB with FP8           â”‚  â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚
â”‚  â”‚ Qwen3-VL-32B         â”‚ 32B (dense)       â”‚ BF16/FP8     â”‚ 1Ã—80 GB H100 (FP8)             â”‚  â”‚
â”‚  â”‚                      â”‚                   â”‚              â”‚ or 2Ã—40 GB A100                â”‚  â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚
â”‚  â”‚ Qwen3-VL-30B-A3B     â”‚ ~30B + 3Ã—experts  â”‚ BF16/FP8     â”‚ 2Ã—80 GB (for full MoE)         â”‚  â”‚
â”‚  â”‚ (MoE)                â”‚ Only 3B active    â”‚              â”‚ Faster than dense 32B!         â”‚  â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚
â”‚  â”‚ Qwen3-VL-235B-A22B   â”‚ 235B + 22 experts â”‚ BF16/FP8     â”‚ 8Ã—80 GB H100 or 8Ã—B200         â”‚  â”‚
â”‚  â”‚ (MoE)                â”‚ (~657B total)     â”‚              â”‚ FP8 + 8Ã—H100 needed            â”‚  â”‚
â”‚  â”‚                      â”‚ 22B active        â”‚              â”‚ Ideally Blackwell for 15Ã—      â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                                                 â”‚
â”‚  NOTES:                                                                                         â”‚
â”‚  â•â•â•â•â•â•                                                                                         â”‚
â”‚  â€¢ MoE "Param Count" indicates base + expert parameters (only subset active per token)        â”‚
â”‚  â€¢ Blackwell B200 (192 GB) significantly reduces GPUs needed due to larger memory             â”‚
â”‚  â€¢ All Qwen3-VL models support 256K context (expandable to 1M with fine-tuning)               â”‚
â”‚  â€¢ Practical context may be lower on smaller GPUs due to KV cache memory                      â”‚
â”‚                                                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Latency and Inference Performance

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              INFERENCE PERFORMANCE COMPARISON                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                                 â”‚
â”‚  FACTORS AFFECTING QWEN3-VL PERFORMANCE:                                                        â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                                       â”‚
â”‚                                                                                                 â”‚
â”‚    Despite being larger, Qwen3-VL achieves competitive latency due to:                        â”‚
â”‚                                                                                                 â”‚
â”‚    1. FP8 SUPPORT (Hopper GPUs)                                                                â”‚
â”‚       â””â”€ ~2Ã— speedup vs FP16, Qwen2-VL was FP16/BF16 only                                     â”‚
â”‚                                                                                                 â”‚
â”‚    2. FLASHATTENTION V2/V3                                                                      â”‚
â”‚       â””â”€ Faster attention for long sequences                                                  â”‚
â”‚                                                                                                 â”‚
â”‚    3. MoE ARCHITECTURE                                                                          â”‚
â”‚       â””â”€ 235B-A22B doesn't use all parameters per token                                       â”‚
â”‚       â””â”€ Effective compute lower than a hypothetical dense 130B                               â”‚
â”‚                                                                                                 â”‚
â”‚    4. VLLM OPTIMIZATIONS                                                                        â”‚
â”‚       â””â”€ Chunked prefill: ~30% reduction in time-to-first-token                               â”‚
â”‚       â””â”€ Prefix caching: Skip recomputation for repeated prompts                              â”‚
â”‚       â””â”€ Continuous batching: Higher GPU utilization                                          â”‚
â”‚                                                                                                 â”‚
â”‚    5. EVS FOR VIDEOS                                                                            â”‚
â”‚       â””â”€ 75% token reduction â†’ 4Ã— speedup for static scenes                                  â”‚
â”‚       â””â”€ Qwen2-VL takes linearly longer with more frames                                      â”‚
â”‚                                                                                                 â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚                                                                                                 â”‚
â”‚  COMPARABLE SIZE COMPARISONS:                                                                   â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                                                   â”‚
â”‚                                                                                                 â”‚
â”‚    Qwen2-VL-7B vs Qwen3-VL-8B:                                                                 â”‚
â”‚    â€¢ Qwen3-VL-8B slightly more compute, but not dramatically slower                           â”‚
â”‚    â€¢ Better quality per latency dollar                                                         â”‚
â”‚                                                                                                 â”‚
â”‚    Qwen2-VL-72B vs Qwen3-VL-32B:                                                               â”‚
â”‚    â€¢ Qwen3-VL-32B is MUCH faster (less than half the parameters)                              â”‚
â”‚    â€¢ May match or surpass 72B performance due to improved training                            â”‚
â”‚                                                                                                 â”‚
â”‚    Qwen3-VL-235B on B200 vs Qwen2-VL-72B on A100:                                              â”‚
â”‚    â€¢ Similar latency due to B200's 15Ã— throughput advantage                                   â”‚
â”‚    â€¢ Much better quality from 235B                                                             â”‚
â”‚                                                                                                 â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚                                                                                                 â”‚
â”‚  MULTI-TURN CONVERSATION ADVANTAGE:                                                             â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                                             â”‚
â”‚                                                                                                 â”‚
â”‚    With PREFIX CACHING in vLLM:                                                                 â”‚
â”‚                                                                                                 â”‚
â”‚    Turn 1: [System Prompt + Image] â†’ Full encoding                                            â”‚
â”‚    Turn 2: [Same context] + [New question] â†’ Reuse cached KV, only encode new question       â”‚
â”‚    Turn 3: [Same context] + [New question] â†’ Same, even faster                                â”‚
â”‚                                                                                                 â”‚
â”‚    Qwen3-VL/vLLM: Reuses image tokens from cache â†’ 2nd query much faster                      â”‚
â”‚    Qwen2-VL naive: Recomputes vision every time â†’ Consistently slow                           â”‚
â”‚                                                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### When to Choose Which Model

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              DECISION GUIDE: QWEN2-VL vs QWEN3-VL                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                                 â”‚
â”‚  CHOOSE QWEN2-VL IF:                                                                            â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                                                            â”‚
â”‚                                                                                                 â”‚
â”‚    âœ“ You have a T4 and want the simplest possible setup                                       â”‚
â”‚    âœ“ You don't process videos (images only)                                                   â”‚
â”‚    âœ“ You need Xformers attention backend (not supported in Qwen3-VL)                          â”‚
â”‚    âœ“ You have existing Qwen2-VL fine-tuned weights you want to reuse                          â”‚
â”‚    âœ“ You need proven production stability (more mature codebase)                              â”‚
â”‚    âœ“ Your use case is well-served by the 2B/7B/72B size options                               â”‚
â”‚                                                                                                 â”‚
â”‚  CHOOSE QWEN3-VL IF:                                                                            â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                                                            â”‚
â”‚                                                                                                 â”‚
â”‚    âœ“ You need better fine-grained visual understanding (DeepStack)                            â”‚
â”‚    âœ“ You process videos (EVS dramatically reduces token count)                                â”‚
â”‚    âœ“ You want faster inference with Eagle3 speculative decoding                               â”‚
â”‚    âœ“ You have A100+ and want best quality                                                     â”‚
â”‚    âœ“ You're building GUI agents (MAI-UI is based on Qwen3-VL)                                â”‚
â”‚    âœ“ You need 256K+ context for long documents or videos                                      â”‚
â”‚    âœ“ You want the 4B or 8B size options (not available in Qwen2-VL)                           â”‚
â”‚    âœ“ You need MoE efficiency (30B-A3B or 235B-A22B)                                           â”‚
â”‚    âœ“ You need multilingual OCR beyond 10 languages                                            â”‚
â”‚    âœ“ You need state-of-the-art benchmark performance                                          â”‚
â”‚                                                                                                 â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚                                                                                                 â”‚
â”‚  GPU-BASED DECISION:                                                                            â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                                                            â”‚
â”‚                                                                                                 â”‚
â”‚    T4 (16 GB):                                                                                  â”‚
â”‚    â€¢ Qwen2-VL-2B (full precision) OR Qwen3-VL-4B (4-bit)                                      â”‚
â”‚    â€¢ Qwen3-VL better if you need video with EVS                                               â”‚
â”‚                                                                                                 â”‚
â”‚    A100 (40-80 GB):                                                                             â”‚
â”‚    â€¢ Qwen3-VL-8B (BF16) recommended                                                           â”‚
â”‚    â€¢ Qwen3-VL-30B-A3B MoE if you have 80GB                                                    â”‚
â”‚                                                                                                 â”‚
â”‚    H100 (80 GB):                                                                                â”‚
â”‚    â€¢ Qwen3-VL-8B or 32B with FP8                                                              â”‚
â”‚    â€¢ FlashAttention 3 benefits Qwen3-VL more                                                  â”‚
â”‚                                                                                                 â”‚
â”‚    B200 (192 GB):                                                                               â”‚
â”‚    â€¢ Qwen3-VL-235B-A22B for maximum quality                                                   â”‚
â”‚    â€¢ 15Ã— throughput advantage makes huge models practical                                     â”‚
â”‚                                                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Summary: Key Differences at a Glance

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              FINAL COMPARISON TABLE                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ Feature            â”‚ Qwen2-VL                â”‚ Qwen3-VL                                â”‚    â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”‚
â”‚  â”‚ Release            â”‚ 2024                    â”‚ 2025                                    â”‚    â”‚
â”‚  â”‚ LLM Backbone       â”‚ Qwen2                   â”‚ Qwen3                                   â”‚    â”‚
â”‚  â”‚ Vision Encoder     â”‚ 32 layers, QuickGELU    â”‚ 32 layers, SiLU                         â”‚    â”‚
â”‚  â”‚ Patch Embedding    â”‚ Conv3D, no bias         â”‚ Conv3D, with bias                       â”‚    â”‚
â”‚  â”‚ Position Encoding  â”‚ 3D RoPE                 â”‚ Learned + RoPE + Interpolation          â”‚    â”‚
â”‚  â”‚ RoPE Application   â”‚ 100% of dims            â”‚ 50% of dims (partial_rotary_factor)     â”‚    â”‚
â”‚  â”‚ MLP Bias           â”‚ Has bias                â”‚ No bias                                 â”‚    â”‚
â”‚  â”‚ Multi-Scale        â”‚ âŒ                      â”‚ âœ… DeepStack                            â”‚    â”‚
â”‚  â”‚ Video Pruning      â”‚ âŒ                      â”‚ âœ… EVS                                  â”‚    â”‚
â”‚  â”‚ Max Video Frames   â”‚ 14                      â”‚ 24,576                                  â”‚    â”‚
â”‚  â”‚ Eagle3 Speculative â”‚ âŒ                      â”‚ âœ…                                      â”‚    â”‚
â”‚  â”‚ MoE Variants       â”‚ âŒ                      â”‚ âœ… Qwen3-VL-30B-A3B                     â”‚    â”‚
â”‚  â”‚ Best for T4        â”‚ 2B model (full prec)    â”‚ 4B model (4-bit + EVS)                  â”‚    â”‚
â”‚  â”‚ Best for H100      â”‚ 7B model                â”‚ 8B or 30B-A3B (MoE)                     â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                                                 â”‚
â”‚  WHEN TO USE WHICH:                                                                             â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                                                             â”‚
â”‚                                                                                                 â”‚
â”‚  Choose Qwen2-VL if:                                                                            â”‚
â”‚  â€¢ You have a T4 and want simplest setup                                                        â”‚
â”‚  â€¢ You don't process videos                                                                     â”‚
â”‚  â€¢ You need Xformers attention backend                                                          â”‚
â”‚  â€¢ You have existing Qwen2-VL fine-tuned weights                                               â”‚
â”‚                                                                                                 â”‚
â”‚  Choose Qwen3-VL if:                                                                            â”‚
â”‚  â€¢ You need better fine-grained visual understanding (DeepStack)                                â”‚
â”‚  â€¢ You process videos (EVS dramatically reduces token count)                                    â”‚
â”‚  â€¢ You want faster inference with Eagle3 speculative decoding                                   â”‚
â”‚  â€¢ You have A100+ and want best quality                                                         â”‚
â”‚  â€¢ You're building GUI agents (MAI-UI is based on Qwen3-VL)                                    â”‚
â”‚                                                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Key Takeaways

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                  KEY TAKEAWAYS                                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                                 â”‚
â”‚  1. ARCHITECTURE EVOLUTION                                                                      â”‚
â”‚     â€¢ Qwen3-VL adds DeepStack (multi-scale features) for better fine-grained detection         â”‚
â”‚     â€¢ Qwen3-VL adds EVS for efficient video processing (50%+ token reduction)                  â”‚
â”‚     â€¢ Qwen3-VL uses learned position embeddings with interpolation (better variable res)       â”‚
â”‚     â€¢ Qwen3-VL changes activation from QuickGELU to SiLU                                       â”‚
â”‚                                                                                                 â”‚
â”‚  2. GPU OPTIMIZATION                                                                            â”‚
â”‚     â€¢ T4: Use 4-bit quantization, FP16, enforce_eager=True, max_model_len=4096                 â”‚
â”‚     â€¢ A100: Use BF16, FlashAttention 2, enable_prefix_caching, max_model_len=32768             â”‚
â”‚     â€¢ H100: Use FP8 quantization + FP8 KV cache for 2x throughput                              â”‚
â”‚     â€¢ B200: Can run 72B dense or 235B MoE models on single GPU                                 â”‚
â”‚                                                                                                 â”‚
â”‚  3. VLLM CONFIGURATION                                                                          â”‚
â”‚     â€¢ max_pixels: Controls image resolution (500K for T4, 2M for A100+)                        â”‚
â”‚     â€¢ max_model_len: Controls context length (affects KV cache memory)                         â”‚
â”‚     â€¢ max_num_seqs: Controls concurrent requests (affects throughput)                          â”‚
â”‚     â€¢ video_pruning_rate: Qwen3-VL only, 0.3-0.5 recommended for videos                        â”‚
â”‚                                                                                                 â”‚
â”‚  4. MAI-UI GUI AGENTS                                                                           â”‚
â”‚     â€¢ Uses Qwen3-VL backbone with DeepStack for small UI element detection                     â”‚
â”‚     â€¢ Trained with GRPO (Group Relative Policy Optimization)                                   â”‚
â”‚     â€¢ SOTA results: 76.7% AndroidWorld, 73.5% ScreenSpot-Pro                                   â”‚
â”‚     â€¢ Supports device-cloud collaboration for privacy + accuracy                               â”‚
â”‚                                                                                                 â”‚
â”‚  5. PRACTICAL DEPLOYMENT                                                                        â”‚
â”‚     â€¢ Start with smaller models and quantization on limited GPUs                               â”‚
â”‚     â€¢ Use prefix caching for repeated system prompts                                           â”‚
â”‚     â€¢ Use chunked prefill for mixed short/long requests                                        â”‚
â”‚     â€¢ Monitor memory with gpu_memory_utilization=0.9 first                                     â”‚
â”‚                                                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## GPU Deployment Best Practices

### Detailed Recommendations by GPU

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              GPU-SPECIFIC DEPLOYMENT GUIDE                                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                                 â”‚
â”‚  NVIDIA T4 (16 GB, Turing SM 7.5)                                                               â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                                             â”‚
â”‚                                                                                                 â”‚
â”‚    LIMITATIONS:                                                                                 â”‚
â”‚    â€¢ No BF16 support (FP16 only)                                                               â”‚
â”‚    â€¢ No FP8/TensorRT support                                                                   â”‚
â”‚    â€¢ No FlashAttention (uses TORCH_SDPA)                                                       â”‚
â”‚    â€¢ 320 GB/s bandwidth (memory-bound decode)                                                  â”‚
â”‚                                                                                                 â”‚
â”‚    RECOMMENDED MODELS:                                                                          â”‚
â”‚    â€¢ Qwen2-VL-2B (FP16): ~4-6 GB, comfortable fit                                              â”‚
â”‚    â€¢ Qwen3-VL-4B (4-bit BitsAndBytes): ~2 GB weights + EVS for videos                         â”‚
â”‚    â€¢ Qwen2-VL-7B (4-bit GPTQ/int8): ~4 GB weights, tight but works                            â”‚
â”‚                                                                                                 â”‚
â”‚    CONFIGURATION:                                                                               â”‚
â”‚    â€¢ dtype="half"                                                                               â”‚
â”‚    â€¢ quantization="bitsandbytes" or "gptq"                                                     â”‚
â”‚    â€¢ enforce_eager=True (saves ~0.5 GB)                                                        â”‚
â”‚    â€¢ max_model_len=2048-4096                                                                   â”‚
â”‚    â€¢ max_num_seqs=4                                                                            â”‚
â”‚    â€¢ max_pixels=500000 (~700Ã—700)                                                              â”‚
â”‚                                                                                                 â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚                                                                                                 â”‚
â”‚  NVIDIA A100 (40/80 GB, Ampere SM 8.0)                                                          â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                                         â”‚
â”‚                                                                                                 â”‚
â”‚    ADVANTAGES:                                                                                  â”‚
â”‚    â€¢ Native BF16 support (better numerical stability)                                          â”‚
â”‚    â€¢ FlashAttention 2 (2-4Ã— faster attention)                                                  â”‚
â”‚    â€¢ 2,039 GB/s bandwidth (6Ã— faster than T4)                                                  â”‚
â”‚    â€¢ Tensor cores for mixed precision                                                          â”‚
â”‚                                                                                                 â”‚
â”‚    RECOMMENDED MODELS:                                                                          â”‚
â”‚    â€¢ Qwen2-VL-7B/72B (BF16): Full precision on 80GB                                           â”‚
â”‚    â€¢ Qwen3-VL-8B (BF16): Excellent fit on 80GB                                                â”‚
â”‚    â€¢ Qwen3-VL-30B-A3B (MoE): Only 3B active per token, fits in 80GB                           â”‚
â”‚                                                                                                 â”‚
â”‚    CONFIGURATION:                                                                               â”‚
â”‚    â€¢ dtype="bfloat16"                                                                          â”‚
â”‚    â€¢ enable_prefix_caching=True                                                                â”‚
â”‚    â€¢ max_model_len=16384-32768                                                                 â”‚
â”‚    â€¢ max_num_seqs=16-32                                                                        â”‚
â”‚    â€¢ max_pixels=2073600 (1920Ã—1080)                                                            â”‚
â”‚                                                                                                 â”‚
â”‚    FOR QWEN3-VL-235B:                                                                           â”‚
â”‚    â€¢ Requires 8Ã—80 GB A100s                                                                    â”‚
â”‚    â€¢ May need --max-model-len 128000 (not full 256K)                                          â”‚
â”‚    â€¢ Or disable video: --limit-mm-per-prompt.video 0                                          â”‚
â”‚                                                                                                 â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚                                                                                                 â”‚
â”‚  NVIDIA H100 (80 GB, Hopper SM 9.0)                                                             â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                                            â”‚
â”‚                                                                                                 â”‚
â”‚    ADVANTAGES:                                                                                  â”‚
â”‚    â€¢ Native FP8 support (2Ã— throughput vs BF16)                                               â”‚
â”‚    â€¢ FP8 KV cache (halves KV cache memory)                                                     â”‚
â”‚    â€¢ FlashAttention 3 (Hopper-specific optimizations)                                          â”‚
â”‚    â€¢ 3,350 GB/s bandwidth (10Ã— faster than T4)                                                 â”‚
â”‚    â€¢ Transformer Engine for automatic mixed precision                                          â”‚
â”‚                                                                                                 â”‚
â”‚    RECOMMENDED MODELS:                                                                          â”‚
â”‚    â€¢ Qwen3-VL-8B (FP8): ~8 GB weights, room for 64+ concurrent                                â”‚
â”‚    â€¢ Qwen3-VL-32B (FP8): Fits comfortably with long context                                   â”‚
â”‚    â€¢ Qwen3-VL-235B-A22B (FP8): Full 256K context + video enabled                              â”‚
â”‚                                                                                                 â”‚
â”‚    CONFIGURATION:                                                                               â”‚
â”‚    â€¢ quantization="fp8"                                                                        â”‚
â”‚    â€¢ kv_cache_dtype="fp8"                                                                      â”‚
â”‚    â€¢ max_model_len=32768-65536                                                                 â”‚
â”‚    â€¢ max_num_seqs=32-64                                                                        â”‚
â”‚    â€¢ max_pixels=2073600                                                                        â”‚
â”‚    â€¢ enable_prefix_caching=True                                                                â”‚
â”‚    â€¢ enable_chunked_prefill=True                                                               â”‚
â”‚                                                                                                 â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚                                                                                                 â”‚
â”‚  NVIDIA B200 (192 GB, Blackwell SM 10.0)                                                        â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                                       â”‚
â”‚                                                                                                 â”‚
â”‚    ADVANTAGES:                                                                                  â”‚
â”‚    â€¢ 192 GB HBM3e (12Ã— T4, 2.4Ã— H100)                                                         â”‚
â”‚    â€¢ 8,000 GB/s bandwidth (25Ã— faster than T4)                                                 â”‚
â”‚    â€¢ FP4 support (when available, 4Ã— throughput)                                              â”‚
â”‚    â€¢ 11-15Ã— higher LLM inference throughput vs H100                                           â”‚
â”‚    â€¢ Can run Qwen2-VL-72B on SINGLE GPU                                                        â”‚
â”‚                                                                                                 â”‚
â”‚    RECOMMENDED MODELS:                                                                          â”‚
â”‚    â€¢ Qwen2-VL-72B (BF16): Single GPU, no tensor parallelism needed                            â”‚
â”‚    â€¢ Qwen3-VL-235B-A22B: Full MoE model fits with 256K context                                â”‚
â”‚    â€¢ 4K resolution images supported (max_pixels=4,147,200)                                    â”‚
â”‚                                                                                                 â”‚
â”‚    CONFIGURATION:                                                                               â”‚
â”‚    â€¢ max_model_len=65536-131072                                                                â”‚
â”‚    â€¢ max_num_seqs=64-128                                                                       â”‚
â”‚    â€¢ max_pixels=4147200 (4K resolution)                                                        â”‚
â”‚    â€¢ enable_prefix_caching=True                                                                â”‚
â”‚    â€¢ enable_chunked_prefill=True                                                               â”‚
â”‚                                                                                                 â”‚
â”‚    Run out-of-the-box: Full context length + concurrent image & video processing              â”‚
â”‚                                                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### vLLM Launch Commands by GPU

```bash
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# T4 (16 GB) - Qwen3-VL-4B with 4-bit Quantization
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

vllm serve Qwen/Qwen3-VL-4B-Instruct \
    --dtype half \
    --quantization bitsandbytes \
    --load-format bitsandbytes \
    --gpu-memory-utilization 0.92 \
    --max-model-len 4096 \
    --enforce-eager \
    --max-num-seqs 4 \
    --limit-mm-per-prompt image=2,video=1

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# A100-80GB - Qwen3-VL-8B Full Precision
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

vllm serve Qwen/Qwen3-VL-8B-Instruct \
    --dtype bfloat16 \
    --gpu-memory-utilization 0.95 \
    --max-model-len 32768 \
    --max-num-seqs 32 \
    --enable-prefix-caching \
    --enable-chunked-prefill \
    --limit-mm-per-prompt image=8,video=2

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# H100-80GB - Qwen3-VL-8B with FP8 (Maximum Throughput)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

vllm serve Qwen/Qwen3-VL-8B-Instruct \
    --dtype bfloat16 \
    --quantization fp8 \
    --kv-cache-dtype fp8 \
    --gpu-memory-utilization 0.95 \
    --max-model-len 32768 \
    --max-num-seqs 64 \
    --enable-prefix-caching \
    --enable-chunked-prefill \
    --limit-mm-per-prompt image=16,video=4

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 8Ã—H100 - Qwen3-VL-235B-A22B MoE (Full Model)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

OMP_NUM_THREADS=1 vllm serve Qwen/Qwen3-VL-235B-A22B-Instruct \
    --dtype bfloat16 \
    --quantization fp8 \
    --kv-cache-dtype fp8 \
    --tensor-parallel-size 8 \
    --enable-expert-parallel \
    --gpu-memory-utilization 0.95 \
    --max-model-len 131072 \
    --max-num-seqs 32 \
    --enable-prefix-caching \
    --enable-chunked-prefill

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# B200-192GB - Qwen3-VL-235B-A22B (Full Features)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

vllm serve Qwen/Qwen3-VL-235B-A22B-Instruct \
    --dtype bfloat16 \
    --tensor-parallel-size 8 \
    --enable-expert-parallel \
    --gpu-memory-utilization 0.95 \
    --max-model-len 262144 \
    --max-num-seqs 128 \
    --enable-prefix-caching \
    --enable-chunked-prefill \
    --limit-mm-per-prompt image=32,video=8
```

---

## References

### Official Papers and Technical Reports

- **[Qwen2-VL Technical Report](https://arxiv.org/abs/2409.12191)** - "Qwen2-VL: Enhancing Vision-Language Model's Perception of the World at Any Resolution" (arXiv:2409.12191)
- **[Qwen3-VL Technical Report](https://arxiv.org/abs/2501.18789)** - Comprehensive architectural improvements including DeepStack, EVS, and 256K context
- **[MAI-UI Paper](https://arxiv.org/abs/2512.22047)** - "MAI-UI: A Foundation GUI Agent Model Family" (arXiv:2512.22047)

### Official GitHub Repositories

- **[Qwen-VL GitHub](https://github.com/QwenLM/Qwen-VL)** - Official Qwen2-VL repository with model weights and examples
- **[Qwen3-VL GitHub](https://github.com/QwenLM/Qwen3-VL)** - Official Qwen3-VL repository
- **[MAI-UI GitHub](https://github.com/Tongyi-MAI/MAI-UI)** - GUI agent implementation based on Qwen3-VL
- **[vLLM GitHub](https://github.com/vllm-project/vllm)** - High-performance inference engine with Qwen-VL support

### Project Pages and Documentation

- **[MAI-UI Project Page](https://tongyi-mai.github.io/MAI-UI/)** - Demos and benchmarks for GUI agents
- **[vLLM Documentation](https://docs.vllm.ai/)** - Official vLLM documentation
- **[vLLM Vision-Language Models](https://docs.vllm.ai/en/latest/models/vlm.html)** - VLM-specific configuration
- **[Qwen Model Cards on Hugging Face](https://huggingface.co/Qwen)** - Model weights and usage instructions

### Blog Posts and Tutorials

- **[GRPO for GUI Grounding](https://huggingface.co/blog/HelloKKMe/grounding-r1)** - Training GUI agents with reinforcement learning
- **[Qwen2-VL Blog Post](https://qwenlm.github.io/blog/qwen2-vl/)** - Official release announcement
- **[Efficient Video Sampling (EVS)](https://nvidia.github.io/EVS)** - NVIDIA research on video token pruning

### Hardware References

- **[NVIDIA H100 Datasheet](https://www.nvidia.com/en-us/data-center/h100/)** - FP8, FlashAttention 3 capabilities
- **[NVIDIA B200 Architecture](https://www.nvidia.com/en-us/data-center/grace-blackwell/)** - Blackwell GPU specifications
- **[Exxact HPC Blog: Blackwell vs Hopper](https://blog.exxactcorp.com/)** - B200 performance comparisons

### Citation

If you use this guide or the Qwen-VL models in your research, please cite:

```bibtex
@article{qwen2vl2024,
  title={Qwen2-VL: Enhancing Vision-Language Model's Perception of the World at Any Resolution},
  author={Wang, Peng and others},
  journal={arXiv preprint arXiv:2409.12191},
  year={2024}
}

@article{maiui2025,
  title={MAI-UI: A Foundation GUI Agent Model Family},
  author={Tongyi Lab},
  journal={arXiv preprint arXiv:2512.22047},
  year={2025}
}
```

