# Qwen VL Complete Guide: Architecture, vLLM Optimization & MAI-UI

A comprehensive guide to running Qwen2-VL and Qwen3-VL models on vLLM across different GPU architectures (T4, A100, H100, B200), including the MAI-UI GUI agent application.

---

## Table of Contents

1. [Quick Reference](#quick-reference)
2. [How Vision-Language Models Work](#how-vision-language-models-work)
3. [Qwen2-VL vs Qwen3-VL Architecture](#qwen2-vl-vs-qwen3-vl-architecture)
4. [GPU Hardware Guide](#gpu-hardware-guide)
5. [vLLM Configuration Parameters](#vllm-configuration-parameters)
6. [MAI-UI: GUI Agents with Reinforcement Learning](#mai-ui-gui-agents-with-reinforcement-learning)
7. [Complete Code Examples](#complete-code-examples)

---

## Quick Reference

### Model Selection Matrix

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ GPU                â”‚ VRAM         â”‚ Best Model     â”‚ Configuration                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ T4                 â”‚ 16 GB        â”‚ Qwen3-VL-4B    â”‚ 4-bit, FP16, 4K context, EVS        â”‚
â”‚ A100-40GB          â”‚ 40 GB        â”‚ Qwen3-VL-8B    â”‚ BF16, 16K context                   â”‚
â”‚ A100-80GB          â”‚ 80 GB        â”‚ Qwen3-VL-8B    â”‚ BF16, 32K context, prefix cache     â”‚
â”‚ H100               â”‚ 80 GB        â”‚ Qwen3-VL-8B    â”‚ FP8, 32K context, 32 concurrent     â”‚
â”‚ B200               â”‚ 192 GB       â”‚ Qwen3-VL-30B   â”‚ BF16, 128K context, 128 concurrent  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Key Architectural Differences

| Feature | Qwen2-VL | Qwen3-VL |
|---------|----------|----------|
| Position Encoding | 3D RoPE only | Learned + RoPE + Interpolation |
| MLP Activation | QuickGELU | SiLU |
| Multi-Scale Features | âŒ | âœ… DeepStack |
| Video Token Pruning | âŒ | âœ… EVS |
| Max Video Frames | 14 | 24,576 |
| Speculative Decoding | Basic | Eagle3 native |
| MoE Variants | âŒ | âœ… Qwen3-VL-30B-A3B |

---

## How Vision-Language Models Work

### The Processing Pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           HOW A VISION-LANGUAGE MODEL PROCESSES AN IMAGE                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                                 â”‚
â”‚  STEP 1: IMAGE â†’ PATCHES                                                                        â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                                                        â”‚
â”‚                                                                                                 â”‚
â”‚   Original Image (1024Ã—1024)                                                                    â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                                â”‚
â”‚   â”‚                            â”‚       Split into 14Ã—14 pixel patches                           â”‚
â”‚   â”‚         ğŸ–¼ï¸                 â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º                         â”‚
â”‚   â”‚    Your Image Here         â”‚                                                                â”‚
â”‚   â”‚                            â”‚                                                                â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                                                â”‚
â”‚                                                                                                 â”‚
â”‚   Result: 73 Ã— 73 = 5,329 patches (each patch is 14Ã—14 pixels)                                  â”‚
â”‚                                                                                                 â”‚
â”‚  STEP 2: PATCHES â†’ EMBEDDINGS (Vision Encoder)                                                  â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                                  â”‚
â”‚                                                                                                 â”‚
â”‚   Each 14Ã—14 patch                  Conv3D                    Vision Transformer               â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”Œâ”€â”€â”€â”€â”€â”€â”                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚   â”‚ 14Ã—14Ã—3 pixels   â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º â”‚ Proj â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º â”‚ 32 layers of     â”‚               â”‚
â”‚   â”‚ = 588 numbers    â”‚             â””â”€â”€â”€â”€â”€â”€â”˜                  â”‚ Self-Attention   â”‚               â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             Output:                   â”‚ + MLP            â”‚               â”‚
â”‚                                    1152-dim vector           â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â”‚                                                                       â”‚                         â”‚
â”‚                                                                       â–¼                         â”‚
â”‚                                                              5,329 Ã— 1152-dim vectors           â”‚
â”‚                                                                                                 â”‚
â”‚  STEP 3: SPATIAL MERGING (Reduce Token Count)                                                   â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                                   â”‚
â”‚                                                                                                 â”‚
â”‚   5,329 tokens is too many! Merge 2Ã—2 patches into 1:                                           â”‚
â”‚                                                                                                 â”‚
â”‚   â”Œâ”€â”€â”€â”¬â”€â”€â”€â”                                                                                     â”‚
â”‚   â”‚ A â”‚ B â”‚                                                                                     â”‚
â”‚   â”œâ”€â”€â”€â”¼â”€â”€â”€â”¤  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º [A,B,C,D concatenated] â†’ MLP â†’ 1 merged token                    â”‚
â”‚   â”‚ C â”‚ D â”‚                                                                                     â”‚
â”‚   â””â”€â”€â”€â”´â”€â”€â”€â”˜                                                                                     â”‚
â”‚                                                                                                 â”‚
â”‚   Result: 5,329 Ã· 4 = 1,332 tokens (each is 3584-dim to match LLM)                              â”‚
â”‚                                                                                                 â”‚
â”‚  STEP 4: INJECT INTO LLM                                                                        â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                                                        â”‚
â”‚                                                                                                 â”‚
â”‚   Text prompt: "Describe this image <|image_pad|>"                                              â”‚
â”‚                                                                                                 â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚   â”‚  Token IDs:  [Describe] [this] [image] [img_0] [img_1] ... [img_1331]            â”‚         â”‚
â”‚   â”‚                   â†“        â†“      â†“       â†“       â†“           â†“                  â”‚         â”‚
â”‚   â”‚  Embeddings: [text_emb] [text] [text] [vis_0] [vis_1] ... [vis_1331]             â”‚         â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”‚                                           â”‚                                                     â”‚
â”‚                                           â–¼                                                     â”‚
â”‚                                     LLM Transformer                                             â”‚
â”‚                                     (28-80 layers)                                              â”‚
â”‚                                           â”‚                                                     â”‚
â”‚                                           â–¼                                                     â”‚
â”‚                                    Output: "This is a..."                                       â”‚
â”‚                                                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Token Count = Memory + Latency

```
Image Resolution    Patches    After 2Ã—2 Merge    Memory Impact
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
224 Ã— 224           16 Ã— 16    64 tokens          ~0.5 MB
512 Ã— 512           37 Ã— 37    342 tokens         ~2.5 MB
720 Ã— 720           51 Ã— 51    650 tokens         ~5 MB
1024 Ã— 1024         73 Ã— 73    1,332 tokens       ~10 MB
1920 Ã— 1080         137 Ã— 77   2,637 tokens       ~20 MB

More tokens = More memory = Longer processing time
```

---

## Qwen2-VL vs Qwen3-VL Architecture

### Component-by-Component Comparison Table

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    COMPONENT-BY-COMPONENT COMPARISON                                â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                                     â•‘
â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â•‘
â•‘  â”‚ Component            â”‚ Qwen2-VL                â”‚ Qwen3-VL                   â”‚   â•‘
â•‘  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â•‘
â•‘  â”‚ Patch Embedding      â”‚ Conv3D (no bias)        â”‚ Conv3D (WITH bias)         â”‚   â•‘
â•‘  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â•‘
â•‘  â”‚ Position Encoding    â”‚ 3D RoPE only            â”‚ Learned + RoPE + Interp    â”‚   â•‘
â•‘  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â•‘
â•‘  â”‚ MLP Activation       â”‚ QuickGELU               â”‚ SiLU (configurable)        â”‚   â•‘
â•‘  â”‚                      â”‚ x * Ïƒ(1.702x)           â”‚ x * Ïƒ(x)                   â”‚   â•‘
â•‘  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â•‘
â•‘  â”‚ MLP Bias             â”‚ Has bias                â”‚ No bias (linear_fc1/fc2)   â”‚   â•‘
â•‘  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â•‘
â•‘  â”‚ Feature Merging      â”‚ Single merger           â”‚ Main + DeepStack mergers   â”‚   â•‘
â•‘  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â•‘
â•‘  â”‚ Multi-Scale          â”‚ âŒ None                 â”‚ âœ… DeepStack               â”‚   â•‘
â•‘  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â•‘
â•‘  â”‚ Video Pruning        â”‚ âŒ None                 â”‚ âœ… EVS                     â”‚   â•‘
â•‘  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â•‘
â•‘  â”‚ Max Video Frames     â”‚ 14                      â”‚ 24,576                     â”‚   â•‘
â•‘  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â•‘
â•‘  â”‚ Attention Backend    â”‚ FA, SDPA, Xformers,     â”‚ FA, SDPA, ROCm only       â”‚   â•‘
â•‘  â”‚                      â”‚ ROCm, etc.              â”‚ (stricter requirement)     â”‚   â•‘
â•‘  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â•‘
â•‘  â”‚ Speculative Decode   â”‚ Basic                   â”‚ Eagle3 native support      â”‚   â•‘
â•‘  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â•‘
â•‘  â”‚ MoE Variants         â”‚ âŒ None                 â”‚ âœ… Qwen3-VL-30B-A3B        â”‚   â•‘
â•‘  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â•‘
â•‘  â”‚ LLM Backbone         â”‚ Qwen2ForCausalLM        â”‚ Qwen3LLMForCausalLM        â”‚   â•‘
â•‘  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â•‘
â•‘  â”‚ Torch Compile        â”‚ Limited                 â”‚ Decorated support          â”‚   â•‘
â•‘  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â•‘
â•‘                                                                                     â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

### High-Level Comparison

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    QWEN VISION-LANGUAGE MODEL EVOLUTION                               â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                                       â•‘
â•‘   QWEN2-VL (Late 2024)                    QWEN3-VL (2025)                             â•‘
â•‘   â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                      â•â•â•â•â•â•â•â•â•â•â•â•â•â•                              â•‘
â•‘                                                                                       â•‘
â•‘   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â•‘
â•‘   â”‚    Image/Video      â”‚                 â”‚    Image/Video      â”‚                     â•‘
â•‘   â”‚      Inputs         â”‚                 â”‚      Inputs         â”‚                     â•‘
â•‘   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â•‘
â•‘              â”‚                                       â”‚                                â•‘
â•‘              â–¼                                       â–¼                                â•‘
â•‘   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â•‘
â•‘   â”‚  Conv3D Patch Embed â”‚                 â”‚ Conv3D Patch Embed  â”‚                     â•‘
â•‘   â”‚    (no bias)        â”‚                 â”‚   (WITH bias)       â”‚                     â•‘
â•‘   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â•‘
â•‘              â”‚                                       â”‚                                â•‘
â•‘              â”‚                            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â•‘
â•‘              â”‚                            â”‚  Learned Position   â”‚                     â•‘
â•‘              â”‚                            â”‚  Embed + Interpolateâ”‚                     â•‘
â•‘              â”‚                            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â•‘
â•‘              â”‚                                       â”‚                                â•‘
â•‘              â–¼                                       â–¼                                â•‘
â•‘   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â•‘
â•‘   â”‚   Vision Blocks     â”‚                 â”‚   Vision Blocks     â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”            â•‘
â•‘   â”‚   (N layers)        â”‚                 â”‚   (N layers)        â”‚        â”‚            â•‘
â•‘   â”‚   QuickGELU         â”‚                 â”‚   SiLU activation   â”‚        â–¼            â•‘
â•‘   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  DeepStack          â•‘
â•‘              â”‚                                       â”‚             Mergers            â•‘
â•‘              â–¼                                       â–¼               â”‚                â•‘
â•‘   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚                â•‘
â•‘   â”‚   Single Merger     â”‚                 â”‚   Main Merger       â”‚â—„â”€â”€â”€â”˜                â•‘
â•‘   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â•‘
â•‘              â”‚                                       â”‚                                â•‘
â•‘              â–¼                                       â–¼                                â•‘
â•‘   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â•‘
â•‘   â”‚    Qwen2 LLM        â”‚                 â”‚    Qwen3 LLM        â”‚                     â•‘
â•‘   â”‚  (Qwen2ForCausalLM) â”‚                 â”‚ (DeepStack inject)  â”‚                     â•‘
â•‘   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â•‘
â•‘                                                                                       â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

### Qwen2-VL Vision Encoder Pipeline (Detailed)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          QWEN2-VL VISION ENCODER                                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                     â”‚
â”‚  INPUT: Image (H Ã— W Ã— 3) or Video (T Ã— H Ã— W Ã— 3)                                  â”‚
â”‚                                                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  STEP 1: PATCH EMBEDDING (Qwen2VisionPatchEmbed)                            â”‚   â”‚
â”‚  â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                            â”‚   â”‚
â”‚  â”‚                                                                             â”‚   â”‚
â”‚  â”‚    Input: (L, C) where C = 3 Ã— temporal_patch Ã— patchÂ² = 3 Ã— 2 Ã— 14Â² = 1176â”‚   â”‚
â”‚  â”‚                                                                             â”‚   â”‚
â”‚  â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚   â”‚
â”‚  â”‚    â”‚  Conv3D(in=3, out=embed_dim, kernel=(2,14,14))         â”‚             â”‚   â”‚
â”‚  â”‚    â”‚  **NO BIAS** (bias=False)                               â”‚             â”‚   â”‚
â”‚  â”‚    â”‚         â”‚                                               â”‚             â”‚   â”‚
â”‚  â”‚    â”‚         â–¼                                               â”‚             â”‚   â”‚
â”‚  â”‚    â”‚  Reshape: (L, embed_dim) = (L, 1152)                   â”‚             â”‚   â”‚
â”‚  â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚   â”‚
â”‚  â”‚                                                                             â”‚   â”‚
â”‚  â”‚    Output: (num_patches, 1152)                                              â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  STEP 2: ROTARY POSITION EMBEDDING (3D RoPE)                                â”‚   â”‚
â”‚  â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                â”‚   â”‚
â”‚  â”‚                                                                             â”‚   â”‚
â”‚  â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                             â”‚   â”‚
â”‚  â”‚    â”‚ h_pos_idsâ”‚    â”‚ w_pos_idsâ”‚  â† Computed from grid_thw                   â”‚   â”‚
â”‚  â”‚    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜                                             â”‚   â”‚
â”‚  â”‚         â”‚               â”‚                                                    â”‚   â”‚
â”‚  â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                                                    â”‚   â”‚
â”‚  â”‚                 â–¼                                                            â”‚   â”‚
â”‚  â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚   â”‚
â”‚  â”‚    â”‚  cos, sin = rotary_pos_emb.get_cos_sin(max_grid_size)  â”‚             â”‚   â”‚
â”‚  â”‚    â”‚  cos_combined = cos[pos_ids].flatten(1)                 â”‚             â”‚   â”‚
â”‚  â”‚    â”‚  sin_combined = sin[pos_ids].flatten(1)                 â”‚             â”‚   â”‚
â”‚  â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚   â”‚
â”‚  â”‚                                                                             â”‚   â”‚
â”‚  â”‚    RoPE applies FULL rotation to Q and K (no partial_rotary_factor)        â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  STEP 3: VISION TRANSFORMER BLOCKS Ã— N (Qwen2VisionBlock)                   â”‚   â”‚
â”‚  â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                    â”‚   â”‚
â”‚  â”‚                                                                             â”‚   â”‚
â”‚  â”‚    for each block in self.blocks:                                           â”‚   â”‚
â”‚  â”‚                                                                             â”‚   â”‚
â”‚  â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚   â”‚
â”‚  â”‚    â”‚  x                                                             â”‚      â”‚   â”‚
â”‚  â”‚    â”‚  â”‚                                                             â”‚      â”‚   â”‚
â”‚  â”‚    â”‚  â”œâ”€â”€â–¶ LayerNorm â”€â”€â–¶ Attention â”€â”€â–¶ Add â”€â”                       â”‚      â”‚   â”‚
â”‚  â”‚    â”‚  â”‚    (eps=1e-6)    (with RoPE)        â”‚                       â”‚      â”‚   â”‚
â”‚  â”‚    â”‚  â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â”‚      â”‚   â”‚
â”‚  â”‚    â”‚  â”‚                                                             â”‚      â”‚   â”‚
â”‚  â”‚    â”‚  â”œâ”€â”€â–¶ LayerNorm â”€â”€â–¶ MLP â”€â”€â–¶ Add â”€â”€â”€â”€â”€â”€â”€â”                       â”‚      â”‚   â”‚
â”‚  â”‚    â”‚  â”‚    (eps=1e-6)    (QuickGELU)        â”‚                       â”‚      â”‚   â”‚
â”‚  â”‚    â”‚  â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â”‚      â”‚   â”‚
â”‚  â”‚    â”‚  â”‚                                                             â”‚      â”‚   â”‚
â”‚  â”‚    â”‚  â–¼                                                             â”‚      â”‚   â”‚
â”‚  â”‚    â”‚  x (updated)                                                   â”‚      â”‚   â”‚
â”‚  â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚   â”‚
â”‚  â”‚                                                                             â”‚   â”‚
â”‚  â”‚    MLP Structure (Qwen2-VL):                                                â”‚   â”‚
â”‚  â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚   â”‚
â”‚  â”‚    â”‚  fc1: Linear(embed_dim, embed_dim * mlp_ratio, bias=True)    â”‚       â”‚   â”‚
â”‚  â”‚    â”‚  act: QuickGELU = x * sigmoid(1.702 * x)                      â”‚       â”‚   â”‚
â”‚  â”‚    â”‚  fc2: Linear(embed_dim * mlp_ratio, embed_dim, bias=True)    â”‚       â”‚   â”‚
â”‚  â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  STEP 4: PATCH MERGER (Qwen2VisionPatchMerger)                              â”‚   â”‚
â”‚  â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                â”‚   â”‚
â”‚  â”‚                                                                             â”‚   â”‚
â”‚  â”‚    spatial_merge_size = 2 â†’ Merge 2Ã—2 patches into 1                        â”‚   â”‚
â”‚  â”‚                                                                             â”‚   â”‚
â”‚  â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚   â”‚
â”‚  â”‚    â”‚  ln_q: LayerNorm(embed_dim)                                   â”‚       â”‚   â”‚
â”‚  â”‚    â”‚        â”‚                                                       â”‚       â”‚   â”‚
â”‚  â”‚    â”‚        â–¼                                                       â”‚       â”‚   â”‚
â”‚  â”‚    â”‚  reshape: (N, embed_dim) â†’ (N/4, embed_dim Ã— 4)               â”‚       â”‚   â”‚
â”‚  â”‚    â”‚        â”‚                                                       â”‚       â”‚   â”‚
â”‚  â”‚    â”‚        â–¼                                                       â”‚       â”‚   â”‚
â”‚  â”‚    â”‚  mlp[0]: Linear(embed_dim Ã— 4, embed_dim Ã— 4)                 â”‚       â”‚   â”‚
â”‚  â”‚    â”‚  mlp[1]: GELU()                                                â”‚       â”‚   â”‚
â”‚  â”‚    â”‚  mlp[2]: Linear(embed_dim Ã— 4, hidden_size)                   â”‚       â”‚   â”‚
â”‚  â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚   â”‚
â”‚  â”‚                                                                             â”‚   â”‚
â”‚  â”‚    Output: (num_patches / 4, hidden_size) = merged visual tokens            â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                                     â”‚
â”‚  OUTPUT: Visual embeddings ready for LLM integration                               â”‚
â”‚                                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Qwen3-VL Vision Encoder Pipeline (Detailed)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          QWEN3-VL VISION ENCODER                                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                     â”‚
â”‚  INPUT: Image (H Ã— W Ã— 3) or Video (T Ã— H Ã— W Ã— 3)                                  â”‚
â”‚                                                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  STEP 1: PATCH EMBEDDING (Qwen3_VisionPatchEmbed)                           â”‚   â”‚
â”‚  â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                             â”‚   â”‚
â”‚  â”‚                                                                             â”‚   â”‚
â”‚  â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚   â”‚
â”‚  â”‚    â”‚  Conv3D(in=3, out=hidden_size, kernel=(2,14,14))       â”‚             â”‚   â”‚
â”‚  â”‚    â”‚  **WITH BIAS** (bias=True) â—„â”€â”€ KEY DIFFERENCE          â”‚             â”‚   â”‚
â”‚  â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚   â”‚
â”‚  â”‚                                                                             â”‚   â”‚
â”‚  â”‚    The bias allows the model to learn per-channel offsets,                 â”‚   â”‚
â”‚  â”‚    improving representation flexibility                                     â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  STEP 2: LEARNED POSITION EMBEDDING + INTERPOLATION                         â”‚   â”‚
â”‚  â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                      â”‚   â”‚
â”‚  â”‚  **NEW IN QWEN3-VL** - Replaces simple 3D RoPE                              â”‚   â”‚
â”‚  â”‚                                                                             â”‚   â”‚
â”‚  â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚   â”‚
â”‚  â”‚    â”‚  pos_embed = nn.Embedding(num_pos_embeddings, hidden)   â”‚             â”‚   â”‚
â”‚  â”‚    â”‚                                                          â”‚             â”‚   â”‚
â”‚  â”‚    â”‚  BILINEAR INTERPOLATION for variable resolutions:       â”‚             â”‚   â”‚
â”‚  â”‚    â”‚                                                          â”‚             â”‚   â”‚
â”‚  â”‚    â”‚  for each (t, h, w) in grid_thw:                        â”‚             â”‚   â”‚
â”‚  â”‚    â”‚    h_idxs = linspace(0, num_grid-1, h)                  â”‚             â”‚   â”‚
â”‚  â”‚    â”‚    w_idxs = linspace(0, num_grid-1, w)                  â”‚             â”‚   â”‚
â”‚  â”‚    â”‚                                                          â”‚             â”‚   â”‚
â”‚  â”‚    â”‚    # Get 4 corner positions                              â”‚             â”‚   â”‚
â”‚  â”‚    â”‚    h_floor, h_ceil = floor(h_idxs), ceil(h_idxs)        â”‚             â”‚   â”‚
â”‚  â”‚    â”‚    w_floor, w_ceil = floor(w_idxs), ceil(w_idxs)        â”‚             â”‚   â”‚
â”‚  â”‚    â”‚                                                          â”‚             â”‚   â”‚
â”‚  â”‚    â”‚    # Bilinear weights                                    â”‚             â”‚   â”‚
â”‚  â”‚    â”‚    dh = h_idxs - h_floor                                â”‚             â”‚   â”‚
â”‚  â”‚    â”‚    dw = w_idxs - w_floor                                â”‚             â”‚   â”‚
â”‚  â”‚    â”‚    w00 = (1 - dh) * (1 - dw)                            â”‚             â”‚   â”‚
â”‚  â”‚    â”‚    w01 = (1 - dh) * dw                                  â”‚             â”‚   â”‚
â”‚  â”‚    â”‚    w10 = dh * (1 - dw)                                  â”‚             â”‚   â”‚
â”‚  â”‚    â”‚    w11 = dh * dw                                        â”‚             â”‚   â”‚
â”‚  â”‚    â”‚                                                          â”‚             â”‚   â”‚
â”‚  â”‚    â”‚    # Interpolated embedding                              â”‚             â”‚   â”‚
â”‚  â”‚    â”‚    embeds = w00*E[h0,w0] + w01*E[h0,w1]                 â”‚             â”‚   â”‚
â”‚  â”‚    â”‚           + w10*E[h1,w0] + w11*E[h1,w1]                 â”‚             â”‚   â”‚
â”‚  â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚   â”‚
â”‚  â”‚                                                                             â”‚   â”‚
â”‚  â”‚    hidden_states = patch_embed + interpolated_pos_embed                     â”‚   â”‚
â”‚  â”‚                                                                             â”‚   â”‚
â”‚  â”‚    BENEFIT: Handles arbitrary resolutions without retraining!               â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  STEP 3: VISION TRANSFORMER BLOCKS + DEEPSTACK EXTRACTION                   â”‚   â”‚
â”‚  â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                    â”‚   â”‚
â”‚  â”‚                                                                             â”‚   â”‚
â”‚  â”‚    deepstack_visual_indexes = [layer_k, layer_m, ...]  # e.g., [8, 16, 24] â”‚   â”‚
â”‚  â”‚                                                                             â”‚   â”‚
â”‚  â”‚    for layer_num, block in enumerate(self.blocks):                          â”‚   â”‚
â”‚  â”‚                                                                             â”‚   â”‚
â”‚  â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚   â”‚
â”‚  â”‚    â”‚  hidden = block(hidden, cu_seqlens, cos, sin, max_seqlen)      â”‚      â”‚   â”‚
â”‚  â”‚    â”‚                                                                 â”‚      â”‚   â”‚
â”‚  â”‚    â”‚  if layer_num in deepstack_visual_indexes:                     â”‚      â”‚   â”‚
â”‚  â”‚    â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚      â”‚   â”‚
â”‚  â”‚    â”‚    â”‚  deepstack_feature = deepstack_merger[idx](hidden)    â”‚   â”‚      â”‚   â”‚
â”‚  â”‚    â”‚    â”‚  deepstack_features.append(deepstack_feature)         â”‚   â”‚      â”‚   â”‚
â”‚  â”‚    â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚      â”‚   â”‚
â”‚  â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚   â”‚
â”‚  â”‚                                                                             â”‚   â”‚
â”‚  â”‚    Block Structure (Qwen3-VL, different from Qwen2-VL):                     â”‚   â”‚
â”‚  â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚   â”‚
â”‚  â”‚    â”‚  MLP:                                                         â”‚       â”‚   â”‚
â”‚  â”‚    â”‚    linear_fc1: Linear(dim, mlp_hidden_dim, bias=False)       â”‚       â”‚   â”‚
â”‚  â”‚    â”‚    act_fn: SiLU = x * sigmoid(x)  â—„â”€â”€ Different from QuickGELUâ”‚       â”‚   â”‚
â”‚  â”‚    â”‚    linear_fc2: Linear(mlp_hidden_dim, dim, bias=False)       â”‚       â”‚   â”‚
â”‚  â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚   â”‚
â”‚  â”‚                                                                             â”‚   â”‚
â”‚  â”‚    RoPE: partial_rotary_factor=0.5 (only 50% of dims rotated)              â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  STEP 4: MULTI-SCALE FEATURE MERGING                                        â”‚   â”‚
â”‚  â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                       â”‚   â”‚
â”‚  â”‚                                                                             â”‚   â”‚
â”‚  â”‚    # Main merger (similar to Qwen2-VL)                                      â”‚   â”‚
â”‚  â”‚    main_features = self.merger(hidden_states)                               â”‚   â”‚
â”‚  â”‚                                                                             â”‚   â”‚
â”‚  â”‚    # Concatenate with DeepStack features                                    â”‚   â”‚
â”‚  â”‚    output = torch.cat([main_features] + deepstack_features, dim=1)          â”‚   â”‚
â”‚  â”‚                                                                             â”‚   â”‚
â”‚  â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚   â”‚
â”‚  â”‚    â”‚  OUTPUT SHAPE:                                                  â”‚     â”‚   â”‚
â”‚  â”‚    â”‚  (seq_len, hidden_size * (1 + num_deepstack_levels))            â”‚     â”‚   â”‚
â”‚  â”‚    â”‚                                                                  â”‚     â”‚   â”‚
â”‚  â”‚    â”‚  Example: if hidden_size=3584 and 3 deepstack levels:           â”‚     â”‚   â”‚
â”‚  â”‚    â”‚  (seq_len, 3584 * 4) = (seq_len, 14336)                         â”‚     â”‚   â”‚
â”‚  â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### DeepStack Injection into LLM Layers

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     QWEN3-VL DEEPSTACK LLM INTEGRATION                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                     â”‚
â”‚  Vision Output: [main_emb | ds_emb_0 | ds_emb_1 | ds_emb_2]                         â”‚
â”‚                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â”‚
â”‚                                   â”‚                                                 â”‚
â”‚                                   â–¼                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  SPLIT INTO COMPONENTS:                                                     â”‚   â”‚
â”‚  â”‚                                                                             â”‚   â”‚
â”‚  â”‚  multimodal_embeddings_main = output[:, :visual_dim]                        â”‚   â”‚
â”‚  â”‚  multimodal_embeddings_multiscale = output[:, visual_dim:]                  â”‚   â”‚
â”‚  â”‚                                                                             â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                   â”‚                                                 â”‚
â”‚                                   â–¼                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  COMPUTE DEEPSTACK INPUT EMBEDS:                                            â”‚   â”‚
â”‚  â”‚                                                                             â”‚   â”‚
â”‚  â”‚  deepstack_input_embeds = zeros(seq_len, num_levels * hidden_size)          â”‚   â”‚
â”‚  â”‚                                                                             â”‚   â”‚
â”‚  â”‚  # Merge multiscale features at multimodal positions                        â”‚   â”‚
â”‚  â”‚  deepstack_input_embeds[is_multimodal] = multimodal_embeddings_multiscale   â”‚   â”‚
â”‚  â”‚                                                                             â”‚   â”‚
â”‚  â”‚  # Reshape for per-layer injection                                          â”‚   â”‚
â”‚  â”‚  deepstack_input_embeds = reshape(seq_len, num_levels, visual_dim)          â”‚   â”‚
â”‚  â”‚  deepstack_input_embeds = permute(num_levels, seq_len, visual_dim)          â”‚   â”‚
â”‚  â”‚                                                                             â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                   â”‚                                                 â”‚
â”‚                                   â–¼                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  LLM FORWARD WITH DEEPSTACK INJECTION (Qwen3LLMModel):                      â”‚   â”‚
â”‚  â”‚                                                                             â”‚   â”‚
â”‚  â”‚  for layer_idx, layer in enumerate(self.layers):                            â”‚   â”‚
â”‚  â”‚      hidden_states, residual = layer(positions, hidden_states, residual)    â”‚   â”‚
â”‚  â”‚                                                                             â”‚   â”‚
â”‚  â”‚      if layer_idx < len(deepstack_input_embeds):                            â”‚   â”‚
â”‚  â”‚          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚   â”‚
â”‚  â”‚          â”‚  # ADD deepstack features to hidden states                   â”‚  â”‚   â”‚
â”‚  â”‚          â”‚  hidden_states = hidden_states +                              â”‚  â”‚   â”‚
â”‚  â”‚          â”‚                  deepstack_input_embeds[layer_idx]            â”‚  â”‚   â”‚
â”‚  â”‚          â”‚                                                               â”‚  â”‚   â”‚
â”‚  â”‚          â”‚  This injects multi-scale visual features into EARLY layers! â”‚  â”‚   â”‚
â”‚  â”‚          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚   â”‚
â”‚  â”‚                                                                             â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                                     â”‚
â”‚  VISUALIZATION:                                                                     â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                                                     â”‚
â”‚                                                                                     â”‚
â”‚  Layer 0:  hidden + ds_emb_0 (edge/texture features from Vision Layer 8)           â”‚
â”‚  Layer 1:  hidden + ds_emb_1 (shape features from Vision Layer 16)                 â”‚
â”‚  Layer 2:  hidden + ds_emb_2 (pattern features from Vision Layer 24)               â”‚
â”‚  Layer 3+: hidden only (no more DeepStack injection)                               â”‚
â”‚                                                                                     â”‚
â”‚  BENEFIT: Multi-scale visual features are available throughout the LLM,            â”‚
â”‚           not just at the embedding level. Improves fine-grained understanding!    â”‚
â”‚                                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Attention Mechanism Comparison

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      VISION ATTENTION COMPARISON                                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                     â”‚
â”‚  QWEN2-VL ATTENTION:                                                                â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                                                â”‚
â”‚                                                                                     â”‚
â”‚    Input: x (seq_len, batch, embed_dim)                                             â”‚
â”‚                                                                                     â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚    â”‚  1. QKV Projection                                                        â”‚   â”‚
â”‚    â”‚     qkv = Linear(embed_dim, 3 * embed_dim)(x)                             â”‚   â”‚
â”‚    â”‚                                                                           â”‚   â”‚
â”‚    â”‚  2. Split into Q, K, V                                                    â”‚   â”‚
â”‚    â”‚     q, k, v = qkv.chunk(3, dim=-1)                                        â”‚   â”‚
â”‚    â”‚     Reshape: (seq, batch, num_heads, head_dim)                            â”‚   â”‚
â”‚    â”‚                                                                           â”‚   â”‚
â”‚    â”‚  3. Apply Rotary Embedding (FULL ROTATION)                                â”‚   â”‚
â”‚    â”‚     qk = cat([q, k], dim=0)                                               â”‚   â”‚
â”‚    â”‚     qk_rotated = apply_rotary_emb(qk, cos, sin)  # 100% of dims          â”‚   â”‚
â”‚    â”‚     q, k = qk_rotated.chunk(2, dim=0)                                     â”‚   â”‚
â”‚    â”‚                                                                           â”‚   â”‚
â”‚    â”‚  4. Compute Attention                                                     â”‚   â”‚
â”‚    â”‚     out = attention(q, k, v)                                              â”‚   â”‚
â”‚    â”‚                                                                           â”‚   â”‚
â”‚    â”‚  5. Output Projection                                                     â”‚   â”‚
â”‚    â”‚     out = Linear(embed_dim, embed_dim)(out)                               â”‚   â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                                     â”‚
â”‚  QWEN3-VL ATTENTION:                                                                â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                                                â”‚
â”‚                                                                                     â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚    â”‚  Same as Qwen2-VL EXCEPT:                                                 â”‚   â”‚
â”‚    â”‚                                                                           â”‚   â”‚
â”‚    â”‚  3. Apply Rotary Embedding (PARTIAL ROTATION)                             â”‚   â”‚
â”‚    â”‚     partial_rotary_factor = 0.5  # Only 50% of dims rotated              â”‚   â”‚
â”‚    â”‚                                                                           â”‚   â”‚
â”‚    â”‚     rotary_dims = head_dim * 0.5                                          â”‚   â”‚
â”‚    â”‚     q_rot, q_pass = q.split([rotary_dims, head_dim-rotary_dims], dim=-1)  â”‚   â”‚
â”‚    â”‚     k_rot, k_pass = k.split([rotary_dims, head_dim-rotary_dims], dim=-1)  â”‚   â”‚
â”‚    â”‚                                                                           â”‚   â”‚
â”‚    â”‚     q_rot = apply_rotary_emb(q_rot, cos, sin)                             â”‚   â”‚
â”‚    â”‚     k_rot = apply_rotary_emb(k_rot, cos, sin)                             â”‚   â”‚
â”‚    â”‚                                                                           â”‚   â”‚
â”‚    â”‚     q = cat([q_rot, q_pass], dim=-1)  # Combine rotated + non-rotated    â”‚   â”‚
â”‚    â”‚     k = cat([k_rot, k_pass], dim=-1)                                      â”‚   â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                                     â”‚
â”‚  SUPPORTED BACKENDS:                                                                â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                                                â”‚
â”‚                                                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚ Backend            â”‚ GPU Require â”‚ Notes                                  â”‚     â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤     â”‚
â”‚  â”‚ FLASH_ATTN         â”‚ SM â‰¥ 8.0    â”‚ Fastest, A100+                         â”‚     â”‚
â”‚  â”‚ TORCH_SDPA         â”‚ Any         â”‚ Universal fallback, T4 compatible      â”‚     â”‚
â”‚  â”‚ XFORMERS           â”‚ SM â‰¥ 7.0    â”‚ Qwen2-VL only                          â”‚     â”‚
â”‚  â”‚ ROCM_AITER_FA      â”‚ AMD GPUs    â”‚ ROCm support                           â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### DeepStack Multi-Scale Features (Qwen3-VL Only)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              DEEPSTACK EXPLAINED                                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                                 â”‚
â”‚  PROBLEM: Standard vision encoders only output FINAL layer features                            â”‚
â”‚           Early layers have edge/texture info that gets lost!                                  â”‚
â”‚                                                                                                 â”‚
â”‚  SOLUTION: DeepStack extracts features at MULTIPLE layers                                       â”‚
â”‚                                                                                                 â”‚
â”‚   Vision Transformer Layers:                                                                    â”‚
â”‚   â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                                                     â”‚
â”‚                                                                                                 â”‚
â”‚   Layer 0  â”€â”€â–º ... â”€â”€â–º Layer 8  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º DeepStack Merger 0 â”€â”€â”€â”€â”€â”              â”‚
â”‚                           â”‚                                                       â”‚              â”‚
â”‚                           â–¼                                                       â”‚              â”‚
â”‚   Layer 9  â”€â”€â–º ... â”€â”€â–º Layer 16 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º DeepStack Merger 1 â”€â”€â”  â”‚              â”‚
â”‚                           â”‚                                                   â”‚  â”‚              â”‚
â”‚                           â–¼                                                   â”‚  â”‚              â”‚
â”‚   Layer 17 â”€â”€â–º ... â”€â”€â–º Layer 24 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º DeepStack Merger 2 â”€â”â”‚  â”‚              â”‚
â”‚                           â”‚                                                  â”‚â”‚  â”‚              â”‚
â”‚                           â–¼                                                  â–¼â–¼  â–¼              â”‚
â”‚   Layer 25 â”€â”€â–º ... â”€â”€â–º Layer 32 â”€â”€â–º Main Merger â”€â”€â”€â”€â”€â”€â–º [Main | DS0 | DS1 | DS2]               â”‚
â”‚                                                                   â”‚                             â”‚
â”‚                                                                   â–¼                             â”‚
â”‚                                         Concatenated output sent to LLM                         â”‚
â”‚                                                                                                 â”‚
â”‚  BENEFIT FOR GUI AGENTS:                                                                        â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                                                        â”‚
â”‚  â€¢ Layer 8 features: Button borders, icon edges                                                â”‚
â”‚  â€¢ Layer 16 features: UI component shapes                                                       â”‚
â”‚  â€¢ Layer 24 features: Widget patterns                                                          â”‚
â”‚  â€¢ Layer 32 features: Semantic understanding ("Settings button")                               â”‚
â”‚                                                                                                 â”‚
â”‚  All scales available to LLM â†’ Better at finding small UI elements!                            â”‚
â”‚                                                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### EVS: Efficient Video Sampling (Qwen3-VL Only)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              EVS EXPLAINED                                                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                                 â”‚
â”‚  PROBLEM: Long videos = Too many tokens = Out of memory!                                        â”‚
â”‚                                                                                                 â”‚
â”‚  100-frame video Ã— 160 tokens/frame = 16,000 tokens = HUGE memory                               â”‚
â”‚                                                                                                 â”‚
â”‚  SOLUTION: Content-aware pruning of SIMILAR frames                                              â”‚
â”‚                                                                                                 â”‚
â”‚   WITHOUT EVS (Qwen2-VL):                                                                       â”‚
â”‚   Frame 1 â–ˆâ–ˆ Frame 2 â–ˆâ–ˆ Frame 3 â–ˆâ–ˆ Frame 4 â–ˆâ–ˆ ... Frame 100 â–ˆâ–ˆ                                  â”‚
â”‚   ALL tokens sent to LLM â†’ 16,000 tokens â†’ OOM on T4!                                           â”‚
â”‚                                                                                                 â”‚
â”‚   WITH EVS (Qwen3-VL, video_pruning_rate=0.5):                                                  â”‚
â”‚   Frame 1 â–ˆâ–ˆ Frame 2 â–‘â–‘ Frame 3 â–ˆâ–ˆ Frame 4 â–‘â–‘ ... Frame 100 â–ˆâ–ˆ                                  â”‚
â”‚   ONLY different frames kept â†’ 8,000 tokens â†’ Fits on T4!                                       â”‚
â”‚                                                                                                 â”‚
â”‚   HOW IT WORKS:                                                                                 â”‚
â”‚   â•â•â•â•â•â•â•â•â•â•â•â•â•                                                                                 â”‚
â”‚   1. Compute embedding similarity between adjacent frames                                       â”‚
â”‚   2. Frames with similarity > threshold are pruned                                             â”‚
â”‚   3. Keep diverse frames, remove redundant ones                                                â”‚
â”‚                                                                                                 â”‚
â”‚   PERFORMANCE IMPACT:                                                                           â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                            â”‚
â”‚   â”‚ Pruning Rate  â”‚ Tokens Kept  â”‚ Quality Loss â”‚ Speed Gain      â”‚                            â”‚
â”‚   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                            â”‚
â”‚   â”‚ 0.3 (30%)     â”‚ 70%          â”‚ Minimal      â”‚ ~1.4x faster    â”‚                            â”‚
â”‚   â”‚ 0.5 (50%)     â”‚ 50%          â”‚ Slight       â”‚ ~2x faster      â”‚                            â”‚
â”‚   â”‚ 0.7 (70%)     â”‚ 30%          â”‚ Noticeable   â”‚ ~3x faster      â”‚                            â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                            â”‚
â”‚                                                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## GPU Hardware Guide

### Architecture Comparison

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                              GPU ARCHITECTURE COMPARISON                                        â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                                                 â•‘
â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â•‘
â•‘  â”‚ Specification       â”‚ T4 (Turing)   â”‚ A100 (Ampere) â”‚ H100 (Hopper) â”‚ B200 (Blackwell)â”‚    â•‘
â•‘  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â•‘
â•‘  â”‚ Compute Capability  â”‚ SM 7.5        â”‚ SM 8.0        â”‚ SM 9.0        â”‚ SM 10.0         â”‚    â•‘
â•‘  â”‚ VRAM                â”‚ 16 GB         â”‚ 40/80 GB      â”‚ 80 GB         â”‚ 192 GB          â”‚    â•‘
â•‘  â”‚ Memory Bandwidth    â”‚ 320 GB/s      â”‚ 2,039 GB/s    â”‚ 3,350 GB/s    â”‚ 8,000 GB/s      â”‚    â•‘
â•‘  â”‚ FP16 TFLOPS         â”‚ 65            â”‚ 312           â”‚ 1,979         â”‚ ~4,000          â”‚    â•‘
â•‘  â”‚ FP8 TFLOPS          â”‚ âŒ            â”‚ âŒ            â”‚ 3,958         â”‚ ~8,000          â”‚    â•‘
â•‘  â”‚ FP4 TFLOPS          â”‚ âŒ            â”‚ âŒ            â”‚ âŒ            â”‚ ~16,000         â”‚    â•‘
â•‘  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â•‘
â•‘  â”‚ BF16 Support        â”‚ âŒ            â”‚ âœ…            â”‚ âœ…            â”‚ âœ…              â”‚    â•‘
â•‘  â”‚ FlashAttention 2    â”‚ âŒ            â”‚ âœ…            â”‚ âœ…            â”‚ âœ…              â”‚    â•‘
â•‘  â”‚ FlashAttention 3    â”‚ âŒ            â”‚ âŒ            â”‚ âœ…            â”‚ âœ…              â”‚    â•‘
â•‘  â”‚ FP8 Quantization    â”‚ âŒ            â”‚ âŒ            â”‚ âœ…            â”‚ âœ…              â”‚    â•‘
â•‘  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â•‘
â•‘  â”‚ Expected Latency    â”‚ ~1000ms       â”‚ ~300ms        â”‚ ~200ms        â”‚ ~100ms          â”‚    â•‘
â•‘  â”‚ Expected Throughput â”‚ ~1 req/s      â”‚ ~4 req/s      â”‚ ~6 req/s      â”‚ ~15 req/s       â”‚    â•‘
â•‘  â”‚ Max Concurrent      â”‚ 4             â”‚ 32            â”‚ 64            â”‚ 128             â”‚    â•‘
â•‘  â”‚ Max Context         â”‚ 4K            â”‚ 32K           â”‚ 32K           â”‚ 128K            â”‚    â•‘
â•‘  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â•‘
â•‘                                                                                                 â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

### Model Fit by GPU

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              WHICH MODELS FIT ON WHICH GPU?                                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                                 â”‚
â”‚  T4 (16 GB):                                                                                    â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•                                                                                    â”‚
â”‚  âœ… Qwen2-VL-2B (FP16)      - 4 GB weights, comfortable                                        â”‚
â”‚  âœ… Qwen3-VL-4B (4-bit)     - 2 GB weights + EVS helps videos                                  â”‚
â”‚  âš ï¸  Qwen2-VL-7B (4-bit)     - 4 GB weights, tight, small batches                              â”‚
â”‚  âš ï¸  Qwen3-VL-8B (4-bit)     - 4 GB weights, very tight                                        â”‚
â”‚  âŒ Larger models           - Won't fit                                                        â”‚
â”‚                                                                                                 â”‚
â”‚  A100-80GB:                                                                                     â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•                                                                                    â”‚
â”‚  âœ… Qwen2-VL-2B/7B (BF16)   - Plenty of room                                                   â”‚
â”‚  âœ… Qwen3-VL-4B/8B (BF16)   - Excellent, high throughput                                       â”‚
â”‚  âœ… Qwen3-VL-30B-A3B (MoE)  - Fits! Only 3B active at a time                                   â”‚
â”‚  âš ï¸  Qwen2-VL-72B           - Needs tensor parallelism (2 GPUs)                                â”‚
â”‚                                                                                                 â”‚
â”‚  H100-80GB:                                                                                     â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•                                                                                   â”‚
â”‚  âœ… All Qwen2-VL models     - Excellent with FP8                                               â”‚
â”‚  âœ… All Qwen3-VL models     - FlashAttention 3, DeepStack + EVS                                â”‚
â”‚  âœ… Qwen3-VL-30B-A3B (MoE)  - High throughput with FP8                                         â”‚
â”‚                                                                                                 â”‚
â”‚  B200-192GB:                                                                                    â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•                                                                                   â”‚
â”‚  âœ… Qwen2-VL-72B (BF16)     - Single GPU! No tensor parallelism needed                         â”‚
â”‚  âœ… Qwen3-VL-235B-A22B      - Full MoE model fits                                              â”‚
â”‚  âœ… 4K resolution           - max_pixels=4,147,200                                              â”‚
â”‚  âœ… 128K context            - Massive conversation history                                     â”‚
â”‚                                                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### GPU-Specific Optimization Matrix

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                        GPU OPTIMIZATION MATRIX                                      â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                                     â•‘
â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â•‘
â•‘  â”‚                              T4 (16GB, SM 7.5)                              â”‚   â•‘
â•‘  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â•‘
â•‘  â”‚  Qwen2-VL-2B: âœ… FP16 full precision, SDPA attention, 2K context           â”‚   â•‘
â•‘  â”‚  Qwen2-VL-7B: âš ï¸  4-bit required, BitsAndBytes, very limited               â”‚   â•‘
â•‘  â”‚  Qwen3-VL-4B: âœ… 4-bit quantization, small batch, EVS helps videos!        â”‚   â•‘
â•‘  â”‚  Qwen3-VL-8B: âš ï¸  Very tight, needs aggressive 4-bit quantization          â”‚   â•‘
â•‘  â”‚                                                                             â”‚   â•‘
â•‘  â”‚  LIMITATIONS:                                                               â”‚   â•‘
â•‘  â”‚  â”œâ”€ âŒ No FlashAttention 2 (uses TORCH_SDPA)                                â”‚   â•‘
â•‘  â”‚  â”œâ”€ âŒ No BF16 support (FP16 only)                                          â”‚   â•‘
â•‘  â”‚  â”œâ”€ âŒ No FP8 quantization                                                  â”‚   â•‘
â•‘  â”‚  â””â”€ âš ï¸ 320 GB/s bandwidth (memory-bound decode)                             â”‚   â•‘
â•‘  â”‚                                                                             â”‚   â•‘
â•‘  â”‚  BEST CONFIG:                                                               â”‚   â•‘
â•‘  â”‚  enforce_eager=True, max_num_seqs=4, max_pixels=512000, max_model_len=4096 â”‚   â•‘
â•‘  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â•‘
â•‘                                                                                     â•‘
â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â•‘
â•‘  â”‚                            A100 (40/80GB, SM 8.0)                           â”‚   â•‘
â•‘  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â•‘
â•‘  â”‚  Qwen2-VL-2B/7B: âœ… Full precision (BF16), FlashAttention v2               â”‚   â•‘
â•‘  â”‚  Qwen3-VL-4B:    âœ… Excellent, full precision, high throughput              â”‚   â•‘
â•‘  â”‚  Qwen3-VL-8B:    âœ… Full precision (80GB), good concurrency                 â”‚   â•‘
â•‘  â”‚  Qwen3-VL-30B-A3B: âœ… MoE fits in 80GB! Only 3B active per token           â”‚   â•‘
â•‘  â”‚                                                                             â”‚   â•‘
â•‘  â”‚  ADVANTAGES:                                                                â”‚   â•‘
â•‘  â”‚  â”œâ”€ âœ… FlashAttention 2 (2-4x faster attention)                             â”‚   â•‘
â•‘  â”‚  â”œâ”€ âœ… Native BF16 support (better numerical stability)                     â”‚   â•‘
â•‘  â”‚  â”œâ”€ âœ… 2,039 GB/s bandwidth (6x faster than T4)                             â”‚   â•‘
â•‘  â”‚  â””â”€ âœ… Tensor cores for mixed precision                                     â”‚   â•‘
â•‘  â”‚                                                                             â”‚   â•‘
â•‘  â”‚  BEST CONFIG:                                                               â”‚   â•‘
â•‘  â”‚  dtype=bfloat16, max_num_seqs=32, enable_prefix_caching=True               â”‚   â•‘
â•‘  â”‚  max_model_len=32768, max_pixels=2073600                                    â”‚   â•‘
â•‘  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â•‘
â•‘                                                                                     â•‘
â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â•‘
â•‘  â”‚                             H100 (80GB, SM 9.0)                             â”‚   â•‘
â•‘  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â•‘
â•‘  â”‚  All Qwen2-VL: âœ… Excellent with optional FP8 quantization                  â”‚   â•‘
â•‘  â”‚  All Qwen3-VL: âœ… FlashAttention 3, DeepStack + EVS leverage bandwidth      â”‚   â•‘
â•‘  â”‚                                                                             â”‚   â•‘
â•‘  â”‚  ADVANTAGES:                                                                â”‚   â•‘
â•‘  â”‚  â”œâ”€ âœ… FlashAttention 3 (Hopper-specific optimizations)                     â”‚   â•‘
â•‘  â”‚  â”œâ”€ âœ… Native FP8 support (2x throughput vs BF16)                           â”‚   â•‘
â•‘  â”‚  â”œâ”€ âœ… FP8 KV cache (halves KV cache memory)                                â”‚   â•‘
â•‘  â”‚  â”œâ”€ âœ… 3,350 GB/s bandwidth (10x faster than T4)                            â”‚   â•‘
â•‘  â”‚  â””â”€ âœ… Transformer Engine for automatic mixed precision                     â”‚   â•‘
â•‘  â”‚                                                                             â”‚   â•‘
â•‘  â”‚  BEST CONFIG:                                                               â”‚   â•‘
â•‘  â”‚  quantization="fp8", kv_cache_dtype="fp8", max_num_seqs=64                 â”‚   â•‘
â•‘  â”‚  max_model_len=32768, max_pixels=2073600                                    â”‚   â•‘
â•‘  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â•‘
â•‘                                                                                     â•‘
â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â•‘
â•‘  â”‚                            B200 (192GB, SM 10.0)                            â”‚   â•‘
â•‘  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â•‘
â•‘  â”‚  Qwen2-VL-72B:      âœ… Full precision on single GPU!                        â”‚   â•‘
â•‘  â”‚  Qwen3-VL-235B-A22B:âœ… Full MoE model fits                                  â”‚   â•‘
â•‘  â”‚                                                                             â”‚   â•‘
â•‘  â”‚  ADVANTAGES:                                                                â”‚   â•‘
â•‘  â”‚  â”œâ”€ âœ… 192 GB VRAM (12x T4, 2.4x H100)                                      â”‚   â•‘
â•‘  â”‚  â”œâ”€ âœ… 8,000 GB/s bandwidth (25x faster than T4)                            â”‚   â•‘
â•‘  â”‚  â”œâ”€ âœ… FP4 quantization (when available, 4x throughput)                     â”‚   â•‘
â•‘  â”‚  â”œâ”€ âœ… 4K resolution images (max_pixels=4,147,200)                          â”‚   â•‘
â•‘  â”‚  â””â”€ âœ… 128K context length                                                  â”‚   â•‘
â•‘  â”‚                                                                             â”‚   â•‘
â•‘  â”‚  BEST CONFIG:                                                               â”‚   â•‘
â•‘  â”‚  max_num_seqs=128, max_model_len=131072, max_pixels=4147200                â”‚   â•‘
â•‘  â”‚  enable_prefix_caching=True, enable_chunked_prefill=True                   â”‚   â•‘
â•‘  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â•‘
â•‘                                                                                     â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

### Memory Budget Breakdown by GPU

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           T4 MEMORY BUDGET (16 GB)                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                     â”‚
â”‚  QWEN3-VL-4B (4-bit BitsAndBytes):                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Model Weights (4-bit):     ~2.0 GB (12.5%)  â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  â”‚   â”‚
â”‚  â”‚  Vision Encoder:            ~1.5 GB (9.4%)   â–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  â”‚   â”‚
â”‚  â”‚  KV Cache (4K ctx, 4 seqs): ~2.5 GB (15.6%)  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  â”‚   â”‚
â”‚  â”‚  Activations:               ~1.5 GB (9.4%)   â–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  â”‚   â”‚
â”‚  â”‚  CUDA Overhead:             ~1.5 GB (9.4%)   â–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  â”‚   â”‚
â”‚  â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                   â”‚   â”‚
â”‚  â”‚  USED:                      ~9.0 GB (56%)                                    â”‚   â”‚
â”‚  â”‚  FREE:                      ~7.0 GB (44%)   âœ… Comfortable                   â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                                     â”‚
â”‚  QWEN3-VL-8B (4-bit BitsAndBytes):                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Model Weights (4-bit):     ~4.0 GB (25%)    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  â”‚   â”‚
â”‚  â”‚  Vision Encoder:            ~2.0 GB (12.5%)  â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  â”‚   â”‚
â”‚  â”‚  KV Cache (2K ctx, 2 seqs): ~3.0 GB (18.8%)  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  â”‚   â”‚
â”‚  â”‚  Activations:               ~2.0 GB (12.5%)  â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  â”‚   â”‚
â”‚  â”‚  CUDA Overhead:             ~2.0 GB (12.5%)  â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  â”‚   â”‚
â”‚  â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                   â”‚   â”‚
â”‚  â”‚  USED:                     ~13.0 GB (81%)                                    â”‚   â”‚
â”‚  â”‚  FREE:                      ~3.0 GB (19%)   âš ï¸  Very Tight                   â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           A100-80GB MEMORY BUDGET                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                     â”‚
â”‚  QWEN3-VL-8B (BF16 Full Precision):                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Model Weights (BF16):     ~16.0 GB (20%)    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  â”‚   â”‚
â”‚  â”‚  Vision Encoder:            ~4.0 GB (5%)     â–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  â”‚   â”‚
â”‚  â”‚  KV Cache (32K, 32 seqs):  ~20.0 GB (25%)    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  â”‚   â”‚
â”‚  â”‚  Activations:               ~5.0 GB (6.3%)   â–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  â”‚   â”‚
â”‚  â”‚  CUDA Graphs:               ~3.0 GB (3.8%)   â–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  â”‚   â”‚
â”‚  â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                   â”‚   â”‚
â”‚  â”‚  USED:                     ~48.0 GB (60%)                                    â”‚   â”‚
â”‚  â”‚  FREE:                     ~32.0 GB (40%)   âœ… Plenty of room                â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                                     â”‚
â”‚  QWEN3-VL-30B-A3B (MoE, BF16):                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Model Weights (all experts): ~60.0 GB (75%) â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  â”‚   â”‚
â”‚  â”‚  Active Weights (3B):         ~6.0 GB        (compute like a 3B model!)      â”‚   â”‚
â”‚  â”‚  Vision Encoder:              ~4.0 GB (5%)   â–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  â”‚   â”‚
â”‚  â”‚  KV Cache (16K, 16 seqs):    ~8.0 GB (10%)   â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  â”‚   â”‚
â”‚  â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                   â”‚   â”‚
â”‚  â”‚  USED:                      ~72.0 GB (90%)                                   â”‚   â”‚
â”‚  â”‚  FREE:                       ~8.0 GB (10%)  âš ï¸  Tight but works              â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           H100-80GB MEMORY BUDGET (WITH FP8)                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                     â”‚
â”‚  QWEN3-VL-8B (FP8 Quantization):                                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Model Weights (FP8):       ~8.0 GB (10%)    â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  â”‚   â”‚
â”‚  â”‚  Vision Encoder:            ~4.0 GB (5%)     â–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  â”‚   â”‚
â”‚  â”‚  KV Cache (FP8, 32K, 64):  ~16.0 GB (20%)    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  â”‚   â”‚
â”‚  â”‚  Activations:               ~4.0 GB (5%)     â–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  â”‚   â”‚
â”‚  â”‚  CUDA Graphs:               ~4.0 GB (5%)     â–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  â”‚   â”‚
â”‚  â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                   â”‚   â”‚
â”‚  â”‚  USED:                     ~36.0 GB (45%)                                    â”‚   â”‚
â”‚  â”‚  FREE:                     ~44.0 GB (55%)   âœ… Room for 64+ concurrent       â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                                     â”‚
â”‚  FP8 BENEFITS:                                                                      â”‚
â”‚  â”œâ”€ Weights: 16 GB â†’ 8 GB (50% reduction)                                          â”‚
â”‚  â”œâ”€ KV Cache: 32 GB â†’ 16 GB (50% reduction)                                        â”‚
â”‚  â”œâ”€ Throughput: ~2x faster matmul operations                                       â”‚
â”‚  â””â”€ Quality: <1% accuracy loss for most tasks                                      â”‚
â”‚                                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           B200-192GB MEMORY BUDGET                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                     â”‚
â”‚  QWEN3-VL-235B-A22B (Full MoE, BF16):                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Model Weights (all experts): ~140 GB (73%)  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  â”‚   â”‚
â”‚  â”‚  Active Weights (22B):        ~44 GB         (compute like a 22B model!)     â”‚   â”‚
â”‚  â”‚  Vision Encoder:              ~8.0 GB (4%)   â–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  â”‚   â”‚
â”‚  â”‚  KV Cache (128K, 128 seqs):  ~30.0 GB (16%)  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  â”‚   â”‚
â”‚  â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                   â”‚   â”‚
â”‚  â”‚  USED:                      ~178 GB (93%)                                    â”‚   â”‚
â”‚  â”‚  FREE:                       ~14 GB (7%)    âš ï¸  Tight but workable           â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                                     â”‚
â”‚  ALTERNATIVE: QWEN3-VL-32B (Dense) with room for 4K images + 128K context          â”‚
â”‚                                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Performance Benchmarks

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    EXPECTED PERFORMANCE (Image Inference)                           â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                                     â•‘
â•‘  Single Image (1024Ã—1024), 256 output tokens:                                       â•‘
â•‘                                                                                     â•‘
â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â•‘
â•‘  â”‚ Model              â”‚ T4 (16GB)       â”‚ H100 (80GB)     â”‚ B200 (192GB)      â”‚    â•‘
â•‘  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â•‘
â•‘  â”‚ Qwen2-VL-2B        â”‚ ~800ms, 20 t/s  â”‚ ~150ms, 120 t/s â”‚ ~80ms, 200 t/s    â”‚    â•‘
â•‘  â”‚ Qwen2-VL-7B        â”‚ ~2000ms*, 8 t/s â”‚ ~250ms, 80 t/s  â”‚ ~120ms, 150 t/s   â”‚    â•‘
â•‘  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â•‘
â•‘  â”‚ Qwen3-VL-4B        â”‚ ~1000ms, 18 t/s â”‚ ~120ms, 150 t/s â”‚ ~60ms, 280 t/s    â”‚    â•‘
â•‘  â”‚ Qwen3-VL-8B        â”‚ ~1800ms*, 10 t/sâ”‚ ~180ms, 100 t/s â”‚ ~90ms, 200 t/s    â”‚    â•‘
â•‘  â”‚ Qwen3-VL-30B-A3B   â”‚ âŒ OOM          â”‚ ~300ms, 60 t/s  â”‚ ~150ms, 120 t/s   â”‚    â•‘
â•‘  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â•‘
â•‘  * = Requires 4-bit quantization                                                    â•‘
â•‘  t/s = tokens per second                                                            â•‘
â•‘                                                                                     â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    EXPECTED PERFORMANCE (Video Inference)                           â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                                     â•‘
â•‘  60-second video (30 fps â†’ 1800 frames â†’ sampled to ~100 frames):                   â•‘
â•‘                                                                                     â•‘
â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â•‘
â•‘  â”‚ Model              â”‚ A100 (80GB)     â”‚ H100 (80GB)     â”‚ B200 (192GB)      â”‚    â•‘
â•‘  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â•‘
â•‘  â”‚ Qwen2-VL-7B        â”‚ ~5s, 16K tokens â”‚ ~2s, 16K tokens â”‚ ~1s, 16K tokens   â”‚    â•‘
â•‘  â”‚ (no pruning)       â”‚                 â”‚                 â”‚                   â”‚    â•‘
â•‘  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â•‘
â•‘  â”‚ Qwen3-VL-8B        â”‚ ~3s, 8K tokens  â”‚ ~1.2s, 8K tokensâ”‚ ~0.6s, 8K tokens  â”‚    â•‘
â•‘  â”‚ (EVS 50%)          â”‚ 50% pruned!     â”‚ 50% pruned!     â”‚ 50% pruned!       â”‚    â•‘
â•‘  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â•‘
â•‘                                                                                     â•‘
â•‘  EVS IMPACT: ~2x speedup on long videos with minimal quality degradation           â•‘
â•‘                                                                                     â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    THROUGHPUT COMPARISON (Concurrent Users)                         â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                                     â•‘
â•‘  Qwen3-VL-8B, 1024Ã—1024 images, 256 tokens output:                                  â•‘
â•‘                                                                                     â•‘
â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â•‘
â•‘  â”‚ GPU                â”‚ Max Batch   â”‚ Throughput   â”‚ p95 Latency                 â”‚ â•‘
â•‘  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â•‘
â•‘  â”‚ T4 (4-bit)         â”‚ 4           â”‚ ~1 req/s     â”‚ ~2000ms                     â”‚ â•‘
â•‘  â”‚ A100-80GB          â”‚ 32          â”‚ ~4 req/s     â”‚ ~800ms                      â”‚ â•‘
â•‘  â”‚ H100 (FP8)         â”‚ 64          â”‚ ~8 req/s     â”‚ ~400ms                      â”‚ â•‘
â•‘  â”‚ B200               â”‚ 128         â”‚ ~20 req/s    â”‚ ~200ms                      â”‚ â•‘
â•‘  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â•‘
â•‘                                                                                     â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

---

## vLLM Configuration Parameters

### Parameter Reference

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         VLLM CONFIGURATION PARAMETERS EXPLAINED                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                                 â”‚
â”‚  MEMORY PARAMETERS                                                                              â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                                                              â”‚
â”‚                                                                                                 â”‚
â”‚  gpu_memory_utilization (0.0-1.0)                                                               â”‚
â”‚  â””â”€ What % of GPU memory vLLM can use                                                          â”‚
â”‚     â€¢ T4:   0.90-0.92 (leave room for CUDA overhead)                                           â”‚
â”‚     â€¢ A100: 0.95 (more stable)                                                                 â”‚
â”‚     â€¢ H100: 0.95                                                                               â”‚
â”‚                                                                                                 â”‚
â”‚  max_model_len (integer)                                                                        â”‚
â”‚  â””â”€ Maximum tokens in context window (prompt + response)                                       â”‚
â”‚     â€¢ T4:   2048-4096 (limited memory)                                                         â”‚
â”‚     â€¢ A100: 8192-32768                                                                         â”‚
â”‚     â€¢ H100: 16384-65536                                                                        â”‚
â”‚     â€¢ Each 1K tokens â‰ˆ 50-100 MB memory for KV cache                                           â”‚
â”‚                                                                                                 â”‚
â”‚  max_num_seqs (integer)                                                                         â”‚
â”‚  â””â”€ Maximum concurrent requests (batch size)                                                   â”‚
â”‚     â€¢ T4:   4-8                                                                                â”‚
â”‚     â€¢ A100: 16-32                                                                              â”‚
â”‚     â€¢ H100: 32-64                                                                              â”‚
â”‚     â€¢ More concurrent = higher throughput but more memory                                      â”‚
â”‚                                                                                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                                 â”‚
â”‚  PRECISION PARAMETERS                                                                           â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                                                           â”‚
â”‚                                                                                                 â”‚
â”‚  dtype ("half" | "bfloat16" | "auto")                                                           â”‚
â”‚  â””â”€ Data type for model weights                                                                â”‚
â”‚     â€¢ "half" (FP16): T4 only option, 2 bytes per parameter                                     â”‚
â”‚     â€¢ "bfloat16": Better numerical stability, A100+ recommended                                â”‚
â”‚     â€¢ "auto": Let vLLM choose based on GPU                                                     â”‚
â”‚                                                                                                 â”‚
â”‚  quantization (null | "bitsandbytes" | "awq" | "gptq" | "fp8")                                  â”‚
â”‚  â””â”€ Compress model weights to use less memory                                                  â”‚
â”‚     â€¢ null: Full precision (best quality)                                                      â”‚
â”‚     â€¢ "bitsandbytes": 4-bit, easy to use, slight quality loss                                  â”‚
â”‚     â€¢ "awq": 4-bit, optimized for inference                                                    â”‚
â”‚     â€¢ "fp8": 8-bit, H100 only, 2x faster with minimal loss                                     â”‚
â”‚                                                                                                 â”‚
â”‚  kv_cache_dtype ("auto" | "fp8")                                                                â”‚
â”‚  â””â”€ Data type for key-value cache                                                              â”‚
â”‚     â€¢ "auto": Same as model weights                                                            â”‚
â”‚     â€¢ "fp8": H100 only, saves 50% KV cache memory                                              â”‚
â”‚                                                                                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                                 â”‚
â”‚  PERFORMANCE PARAMETERS                                                                         â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                                                         â”‚
â”‚                                                                                                 â”‚
â”‚  enforce_eager (true | false)                                                                   â”‚
â”‚  â””â”€ Disable CUDA graph compilation                                                             â”‚
â”‚     â€¢ true: Slower but uses less memory, better for T4                                         â”‚
â”‚     â€¢ false: Faster via CUDA graphs, needs more memory                                         â”‚
â”‚                                                                                                 â”‚
â”‚  enable_prefix_caching (true | false)                                                           â”‚
â”‚  â””â”€ Cache repeated prompt prefixes (like system prompts)                                       â”‚
â”‚     â€¢ true: Faster for repeated prompts, small memory overhead                                 â”‚
â”‚     â€¢ false: Recompute every time                                                              â”‚
â”‚                                                                                                 â”‚
â”‚  enable_chunked_prefill (true | false)                                                          â”‚
â”‚  â””â”€ Process long prompts in chunks                                                             â”‚
â”‚     â€¢ true: Better for mixed short/long requests                                               â”‚
â”‚     â€¢ false: Process entire prompt at once                                                     â”‚
â”‚                                                                                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                                 â”‚
â”‚  VISION PARAMETERS                                                                              â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                                                              â”‚
â”‚                                                                                                 â”‚
â”‚  limit_mm_per_prompt (dict)                                                                     â”‚
â”‚  â””â”€ Maximum images/videos per prompt                                                           â”‚
â”‚     â€¢ {"image": 4, "video": 1}: Max 4 images OR 1 video                                        â”‚
â”‚                                                                                                 â”‚
â”‚  mm_processor_kwargs (dict)                                                                     â”‚
â”‚  â””â”€ Vision processor settings                                                                  â”‚
â”‚     â€¢ min_pixels: Minimum image size (default 784 = 28Ã—28)                                     â”‚
â”‚     â€¢ max_pixels: Maximum image size (memory vs quality tradeoff)                              â”‚
â”‚       - T4:   500,000 (~700Ã—700)                                                               â”‚
â”‚       - A100: 2,073,600 (1920Ã—1080)                                                            â”‚
â”‚       - B200: 4,147,200 (3840Ã—1080 or 2KÃ—2K)                                                   â”‚
â”‚     â€¢ video_pruning_rate (Qwen3-VL only): 0.0-0.7                                              â”‚
â”‚       - 0.0: Keep all frames                                                                   â”‚
â”‚       - 0.5: Keep ~50% most different frames                                                   â”‚
â”‚                                                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### What Happens When You Change Each Number

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      IMPACT OF CHANGING EACH PARAMETER                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                                 â”‚
â”‚  max_pixels: 500,000 â†’ 2,000,000                                                                â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                                               â”‚
â”‚  BEFORE: 720Ã—720 max image, ~650 tokens, ~5 MB per image                                        â”‚
â”‚  AFTER:  1920Ã—1080 max image, ~2600 tokens, ~20 MB per image                                    â”‚
â”‚  IMPACT: 4x more detail, 4x more memory, 2-3x slower                                           â”‚
â”‚                                                                                                 â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚                                                                                                 â”‚
â”‚  max_model_len: 4096 â†’ 16384                                                                    â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                                                   â”‚
â”‚  BEFORE: 4K context, 1 image + short conversation                                               â”‚
â”‚  AFTER:  16K context, 4 images + long conversation history                                      â”‚
â”‚  IMPACT: 4x longer conversations, 4x more KV cache memory (~400 MB â†’ ~1.6 GB)                  â”‚
â”‚                                                                                                 â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚                                                                                                 â”‚
â”‚  max_num_seqs: 4 â†’ 16                                                                           â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                                                           â”‚
â”‚  BEFORE: 4 concurrent users, low throughput                                                     â”‚
â”‚  AFTER:  16 concurrent users, 4x throughput potential                                           â”‚
â”‚  IMPACT: 4x more KV cache memory needed, may cause OOM on small GPUs                           â”‚
â”‚                                                                                                 â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚                                                                                                 â”‚
â”‚  video_pruning_rate: 0.0 â†’ 0.5                                                                  â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                                                   â”‚
â”‚  BEFORE: All 100 video frames processed, 16,000 tokens                                          â”‚
â”‚  AFTER:  ~50 frames kept, 8,000 tokens                                                          â”‚
â”‚  IMPACT: 50% less memory, 2x faster, slight quality loss on fast-changing videos               â”‚
â”‚                                                                                                 â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚                                                                                                 â”‚
â”‚  quantization: null â†’ "bitsandbytes"                                                            â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                                           â”‚
â”‚  BEFORE: 8B model = 16 GB weights (BF16)                                                        â”‚
â”‚  AFTER:  8B model = 4 GB weights (4-bit)                                                        â”‚
â”‚  IMPACT: 4x smaller, fits on smaller GPUs, ~5-10% quality loss                                 â”‚
â”‚                                                                                                 â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚                                                                                                 â”‚
â”‚  enforce_eager: false â†’ true                                                                    â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                                                    â”‚
â”‚  BEFORE: CUDA graphs enabled, 0.5 GB extra memory, fast decode                                  â”‚
â”‚  AFTER:  CUDA graphs disabled, saves memory, ~20% slower decode                                â”‚
â”‚  IMPACT: Use on T4 to save memory, avoid on H100                                               â”‚
â”‚                                                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Optimization Decision Tree

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              VLLM OPTIMIZATION DECISION TREE                                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                                 â”‚
â”‚  START: What GPU do you have?                                                                   â”‚
â”‚                                                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                                                                                          â”‚   â”‚
â”‚  â”‚                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                     â”‚   â”‚
â”‚  â”‚                              â”‚  What is your GPU?  â”‚                                     â”‚   â”‚
â”‚  â”‚                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                     â”‚   â”‚
â”‚  â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”‚   â”‚
â”‚  â”‚              â–¼                          â–¼                          â–¼                     â”‚   â”‚
â”‚  â”‚      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚   â”‚
â”‚  â”‚      â”‚     T4       â”‚          â”‚  A100/H100   â”‚          â”‚     B200     â”‚               â”‚   â”‚
â”‚  â”‚      â”‚   (16 GB)    â”‚          â”‚  (40-80 GB)  â”‚          â”‚   (192 GB)   â”‚               â”‚   â”‚
â”‚  â”‚      â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚   â”‚
â”‚  â”‚             â”‚                          â”‚                          â”‚                      â”‚   â”‚
â”‚  â”‚             â–¼                          â–¼                          â–¼                      â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚   â”‚
â”‚  â”‚  â”‚ dtype="half"         â”‚  â”‚ dtype="bfloat16"     â”‚  â”‚ dtype="bfloat16"     â”‚           â”‚   â”‚
â”‚  â”‚  â”‚ quantization=        â”‚  â”‚                       â”‚  â”‚ max_model_len=131072 â”‚           â”‚   â”‚
â”‚  â”‚  â”‚   "bitsandbytes"     â”‚  â”‚ Is it H100?          â”‚  â”‚ max_num_seqs=128     â”‚           â”‚   â”‚
â”‚  â”‚  â”‚ enforce_eager=True   â”‚  â”‚   Yesâ†’ quantization= â”‚  â”‚ max_pixels=4147200   â”‚           â”‚   â”‚
â”‚  â”‚  â”‚ max_model_len=4096   â”‚  â”‚         "fp8"        â”‚  â”‚                       â”‚           â”‚   â”‚
â”‚  â”‚  â”‚ max_num_seqs=4       â”‚  â”‚   No â†’ None          â”‚  â”‚                       â”‚           â”‚   â”‚
â”‚  â”‚  â”‚ max_pixels=512000    â”‚  â”‚                       â”‚  â”‚                       â”‚           â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚   â”‚
â”‚  â”‚                                                                                          â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                                                 â”‚
â”‚  ADDITIONAL DECISIONS:                                                                          â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                                                          â”‚
â”‚                                                                                                 â”‚
â”‚  Do you process VIDEOS?                                                                         â”‚
â”‚  â”œâ”€ Yes + Qwen3-VL â†’ Set video_pruning_rate=0.3-0.5                                            â”‚
â”‚  â”œâ”€ Yes + Qwen2-VL â†’ Reduce max_pixels, limit frames                                           â”‚
â”‚  â””â”€ No â†’ video_pruning_rate=0.0 or omit                                                        â”‚
â”‚                                                                                                 â”‚
â”‚  Do you have REPEATED SYSTEM PROMPTS?                                                           â”‚
â”‚  â”œâ”€ Yes â†’ enable_prefix_caching=True                                                           â”‚
â”‚  â””â”€ No  â†’ enable_prefix_caching=False                                                          â”‚
â”‚                                                                                                 â”‚
â”‚  Do you have MIXED SHORT/LONG PROMPTS?                                                          â”‚
â”‚  â”œâ”€ Yes â†’ enable_chunked_prefill=True                                                          â”‚
â”‚  â””â”€ No  â†’ enable_chunked_prefill=False                                                         â”‚
â”‚                                                                                                 â”‚
â”‚  Are you MEMORY CONSTRAINED?                                                                    â”‚
â”‚  â”œâ”€ Yes â†’ enforce_eager=True (disables CUDA graphs, saves ~0.5 GB)                             â”‚
â”‚  â””â”€ No  â†’ enforce_eager=False (faster decode)                                                  â”‚
â”‚                                                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Configuration Checklist

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              BEFORE DEPLOYING: CHECK THESE                                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                                 â”‚
â”‚  â–¡ Match dtype to GPU: FP16 for T4, BF16 for A100+                                             â”‚
â”‚  â–¡ Set max_model_len to fit your longest expected input                                        â”‚
â”‚  â–¡ Set max_num_seqs based on your memory budget                                                â”‚
â”‚  â–¡ Enable prefix caching if you have repeated system prompts                                   â”‚
â”‚  â–¡ Enable chunked prefill if you have mixed long/short prompts                                 â”‚
â”‚  â–¡ For Qwen3-VL with videos: Set video_pruning_rate (0.3-0.5)                                  â”‚
â”‚  â–¡ Set max_pixels based on how much detail you need                                            â”‚
â”‚  â–¡ Use FP8 on H100 for 2x throughput                                                           â”‚
â”‚  â–¡ Use 4-bit quantization on T4 for larger models                                              â”‚
â”‚  â–¡ Test memory usage with gpu_memory_utilization=0.9 first                                     â”‚
â”‚                                                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## MAI-UI: GUI Agents with Reinforcement Learning

### What is MAI-UI?

MAI-UI is a family of GUI agents developed by Tongyi Lab (Alibaba) that uses Qwen3-VL as its vision-language backbone, trained with reinforcement learning to automate mobile and desktop applications.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              MAI-UI: GUI AGENTS POWERED BY QWEN-VL                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                                 â”‚
â”‚  WHAT IT DOES:                                                                                  â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•                                                                                  â”‚
â”‚                                                                                                 â”‚
â”‚   User Task: "Send a message to John saying 'Hello!'"                                           â”‚
â”‚                                                                                                 â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚
â”‚   â”‚ Screenshot      â”‚        â”‚ Qwen3-VL        â”‚        â”‚ Action          â”‚                    â”‚
â”‚   â”‚ of phone        â”‚â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚ Model           â”‚â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚ CLICK(150, 500) â”‚                    â”‚
â”‚   â”‚ home screen     â”‚        â”‚ (MAI-UI-8B)     â”‚        â”‚                 â”‚                    â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚
â”‚                                                                   â”‚                             â”‚
â”‚                                                                   â–¼                             â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚
â”‚   â”‚ Messages app    â”‚        â”‚ Qwen3-VL        â”‚        â”‚ Action          â”‚                    â”‚
â”‚   â”‚ opened          â”‚â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚ Model           â”‚â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚ CLICK(300, 200) â”‚                    â”‚
â”‚   â”‚                 â”‚        â”‚                 â”‚        â”‚                 â”‚                    â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚
â”‚                                                                   â”‚                             â”‚
â”‚                                         ... continues until task complete ...                   â”‚
â”‚                                                                                                 â”‚
â”‚  MODEL VARIANTS:                                                                                â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                                                                â”‚
â”‚  â€¢ MAI-UI-2B:   Based on Qwen3-VL-2B  â†’ Runs on T4!                                            â”‚
â”‚  â€¢ MAI-UI-8B:   Based on Qwen3-VL-8B  â†’ A100/H100                                              â”‚
â”‚  â€¢ MAI-UI-32B:  Based on Qwen3-VL-32B â†’ H100/B200                                              â”‚
â”‚  â€¢ MAI-UI-235B: MoE (235B total, 22B active) â†’ Multi-GPU                                       â”‚
â”‚                                                                                                 â”‚
â”‚  PERFORMANCE (Dec 2025):                                                                        â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                                                        â”‚
â”‚  â€¢ 76.7% on AndroidWorld (mobile navigation) - SOTA!                                           â”‚
â”‚  â€¢ 73.5% on ScreenSpot-Pro (GUI grounding)                                                     â”‚
â”‚  â€¢ Beats Gemini-3-Pro and Seed1.8 on several benchmarks                                        â”‚
â”‚                                                                                                 â”‚
â”‚  Paper: https://arxiv.org/abs/2512.22047                                                       â”‚
â”‚  GitHub: https://github.com/Tongyi-MAI/MAI-UI                                                  â”‚
â”‚                                                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### GRPO Reinforcement Learning Training

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      HOW MAI-UI IS TRAINED WITH REINFORCEMENT LEARNING                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                                 â”‚
â”‚  STAGE 1: SUPERVISED FINE-TUNING (SFT)                                                          â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                                          â”‚
â”‚  â€¢ Start with pre-trained Qwen3-VL                                                              â”‚
â”‚  â€¢ Train on (screenshot, instruction, action) triplets from human demos                        â”‚
â”‚  â€¢ Learn basic GUI understanding and action prediction                                          â”‚
â”‚                                                                                                 â”‚
â”‚  STAGE 2: ONLINE REINFORCEMENT LEARNING (GRPO)                                                  â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                                 â”‚
â”‚                                                                                                 â”‚
â”‚  GRPO = Group Relative Policy Optimization                                                      â”‚
â”‚                                                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚                                THE GRPO ALGORITHM                                       â”‚    â”‚
â”‚  â”‚                                                                                         â”‚    â”‚
â”‚  â”‚   for each state s (screenshot + task):                                                 â”‚    â”‚
â”‚  â”‚                                                                                         â”‚    â”‚
â”‚  â”‚       # 1. Sample N actions from current policy                                         â”‚    â”‚
â”‚  â”‚       actions = [model.generate() for _ in range(8)]                                   â”‚    â”‚
â”‚  â”‚       # e.g., [CLICK(100,200), CLICK(105,198), CLICK(500,300), ...]                    â”‚    â”‚
â”‚  â”‚                                                                                         â”‚    â”‚
â”‚  â”‚       # 2. Compute reward for each action                                               â”‚    â”‚
â”‚  â”‚       rewards = [1.0 if inside_target_box(a) else 0.0 for a in actions]                â”‚    â”‚
â”‚  â”‚       # e.g., [1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]                                 â”‚    â”‚
â”‚  â”‚                                                                                         â”‚    â”‚
â”‚  â”‚       # 3. Normalize within group (KEY INNOVATION!)                                     â”‚    â”‚
â”‚  â”‚       mean_r = mean(rewards)  # 0.375                                                   â”‚    â”‚
â”‚  â”‚       std_r = std(rewards)    # 0.48                                                    â”‚    â”‚
â”‚  â”‚       advantages = [(r - mean_r) / std_r for r in rewards]                              â”‚    â”‚
â”‚  â”‚       # [+1.3, +1.3, -0.78, -0.78, +1.3, -0.78, -0.78, -0.78]                          â”‚    â”‚
â”‚  â”‚                                                                                         â”‚    â”‚
â”‚  â”‚       # 4. Policy gradient update                                                       â”‚    â”‚
â”‚  â”‚       loss = -sum(log_prob(a) * adv for a, adv in zip(actions, advantages))             â”‚    â”‚
â”‚  â”‚       optimizer.step(loss)                                                              â”‚    â”‚
â”‚  â”‚                                                                                         â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                                                 â”‚
â”‚  WHY GRPO IS SIMPLER THAN PPO:                                                                  â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                                                  â”‚
â”‚  â€¢ PPO needs a separate "critic" network to estimate value                                     â”‚
â”‚  â€¢ GRPO just normalizes rewards within the sampled group                                       â”‚
â”‚  â€¢ No critic = less GPU memory = larger batch sizes = faster training                          â”‚
â”‚                                                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Why Qwen3-VL is Ideal for GUI Agents

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          WHY QWEN3-VL IS IDEAL FOR GUI AGENTS                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                                 â”‚
â”‚  1. DEEPSTACK = FINE-GRAINED UI DETECTION                                                       â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                                      â”‚
â”‚                                                                                                 â”‚
â”‚     GUI Challenge: Buttons and icons are TINY (20Ã—20 pixels on a 1080Ã—2400 screen)             â”‚
â”‚                                                                                                 â”‚
â”‚     DeepStack Solution:                                                                         â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚     â”‚ Vision Layer 8:  Edge detection, button borders â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚      â”‚
â”‚     â”‚ Vision Layer 16: Shape patterns, icon outlines â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚â”‚      â”‚
â”‚     â”‚ Vision Layer 24: Widget structures, UI components â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚   â”‚â”‚      â”‚
â”‚     â”‚ Vision Layer 32: Semantic meaning ("Settings button") â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚      â”‚   â”‚â”‚      â”‚
â”‚     â”‚                                                                 â”‚      â”‚      â”‚   â”‚â”‚      â”‚
â”‚     â”‚                     LLM Layer 0  â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”˜â”‚      â”‚
â”‚     â”‚                     LLM Layer 1  â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”˜    â”‚      â”‚
â”‚     â”‚                     LLM Layer 2  â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”˜           â”‚      â”‚
â”‚     â”‚                     LLM Layer 3+ â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚      â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚                                                                                                 â”‚
â”‚     All scales available to LLM â†’ Better at finding small UI elements!                         â”‚
â”‚                                                                                                 â”‚
â”‚  2. HIGH RESOLUTION SUPPORT                                                                     â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                                                     â”‚
â”‚                                                                                                 â”‚
â”‚     Phone screens: 1080Ã—2400 (very tall!)                                                       â”‚
â”‚     Tablets: 2560Ã—1600                                                                          â”‚
â”‚     Desktop: 1920Ã—1080 or higher                                                                â”‚
â”‚                                                                                                 â”‚
â”‚     Qwen3-VL handles this via:                                                                  â”‚
â”‚     â€¢ Learned position embeddings with bilinear interpolation                                  â”‚
â”‚     â€¢ Dynamic resolution (no fixed aspect ratio)                                               â”‚
â”‚     â€¢ Up to 24,576 visual tokens possible                                                       â”‚
â”‚                                                                                                 â”‚
â”‚  3. EVS FOR EFFICIENT TRAINING DATA PROCESSING                                                  â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                                  â”‚
â”‚                                                                                                 â”‚
â”‚     Training data: Screen recordings of humans using apps                                       â”‚
â”‚     Problem: Most frames are nearly identical (user reading, not scrolling)                    â”‚
â”‚     Solution: EVS prunes similar frames automatically                                           â”‚
â”‚                                                                                                 â”‚
â”‚     50-frame video:                                                                             â”‚
â”‚     â€¢ Without EVS: 50 frames Ã— 2000 tokens = 100,000 tokens (OOM!)                              â”‚
â”‚     â€¢ With EVS (50% pruning): 25 frames Ã— 2000 = 50,000 tokens                                 â”‚
â”‚                                                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### MAI-UI Inference Pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        MAI-UI INFERENCE PIPELINE                                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                                 â”‚
â”‚  USER: "Send a message to John saying 'Hello!'"                                                 â”‚
â”‚                                                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚                          STEP 1: CAPTURE SCREENSHOT                                     â”‚    â”‚
â”‚  â”‚                                                                                         â”‚    â”‚
â”‚  â”‚   Android Device/Emulator                                                               â”‚    â”‚
â”‚  â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                         â”‚    â”‚
â”‚  â”‚   â”‚ ğŸ“± Home Screen            â”‚                                                         â”‚    â”‚
â”‚  â”‚   â”‚                           â”‚  â†’ Capture 1080Ã—2400 screenshot                         â”‚    â”‚
â”‚  â”‚   â”‚  [Messages] [Chrome]      â”‚  â†’ Resize to fit max_pixels                              â”‚    â”‚
â”‚  â”‚   â”‚  [Camera]   [Settings]    â”‚  â†’ ~2000 visual tokens                                   â”‚    â”‚
â”‚  â”‚   â”‚                           â”‚                                                         â”‚    â”‚
â”‚  â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                                         â”‚    â”‚
â”‚  â”‚                                                                                         â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                           â”‚                                                     â”‚
â”‚                                           â–¼                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚                          STEP 2: PROCESS WITH QWEN3-VL                                  â”‚    â”‚
â”‚  â”‚                                                                                         â”‚    â”‚
â”‚  â”‚   Prompt template:                                                                      â”‚    â”‚
â”‚  â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚    â”‚
â”‚  â”‚   â”‚ <|im_start|>system                                                              â”‚  â”‚    â”‚
â”‚  â”‚   â”‚ You are a GUI agent. Given a screenshot and task, output the next action.       â”‚  â”‚    â”‚
â”‚  â”‚   â”‚ <|im_end|>                                                                      â”‚  â”‚    â”‚
â”‚  â”‚   â”‚ <|im_start|>user                                                                â”‚  â”‚    â”‚
â”‚  â”‚   â”‚ <|vision_start|><|image_pad|><|vision_end|>                                     â”‚  â”‚    â”‚
â”‚  â”‚   â”‚ Task: Send a message to John saying 'Hello!'                                    â”‚  â”‚    â”‚
â”‚  â”‚   â”‚ Current step: 1/10                                                              â”‚  â”‚    â”‚
â”‚  â”‚   â”‚ Previous actions: None                                                          â”‚  â”‚    â”‚
â”‚  â”‚   â”‚ <|im_end|>                                                                      â”‚  â”‚    â”‚
â”‚  â”‚   â”‚ <|im_start|>assistant                                                           â”‚  â”‚    â”‚
â”‚  â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚    â”‚
â”‚  â”‚                                                                                         â”‚    â”‚
â”‚  â”‚   Model output: "CLICK(150, 500)"  # Click on Messages app                             â”‚    â”‚
â”‚  â”‚                                                                                         â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                           â”‚                                                     â”‚
â”‚                                           â–¼                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚                          STEP 3: EXECUTE ACTION                                         â”‚    â”‚
â”‚  â”‚                                                                                         â”‚    â”‚
â”‚  â”‚   Parse action: CLICK(150, 500)                                                         â”‚    â”‚
â”‚  â”‚   Send ADB command: adb shell input tap 150 500                                         â”‚    â”‚
â”‚  â”‚   Wait for screen to update (~500ms)                                                    â”‚    â”‚
â”‚  â”‚                                                                                         â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                           â”‚                                                     â”‚
â”‚                                           â–¼                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚                          STEP 4: REPEAT UNTIL DONE                                      â”‚    â”‚
â”‚  â”‚                                                                                         â”‚    â”‚
â”‚  â”‚   Screenshot: Messages app opened                                                       â”‚    â”‚
â”‚  â”‚   Model output: "CLICK(300, 200)"  # Click on John's conversation                      â”‚    â”‚
â”‚  â”‚   Execute: adb shell input tap 300 200                                                  â”‚    â”‚
â”‚  â”‚                                                                                         â”‚    â”‚
â”‚  â”‚   Screenshot: Conversation with John                                                    â”‚    â”‚
â”‚  â”‚   Model output: "CLICK(540, 2300)"  # Click on text input field                        â”‚    â”‚
â”‚  â”‚   Execute: adb shell input tap 540 2300                                                 â”‚    â”‚
â”‚  â”‚                                                                                         â”‚    â”‚
â”‚  â”‚   Screenshot: Keyboard visible                                                          â”‚    â”‚
â”‚  â”‚   Model output: "TYPE('Hello!')"  # Type the message                                   â”‚    â”‚
â”‚  â”‚   Execute: adb shell input text "Hello!"                                                â”‚    â”‚
â”‚  â”‚                                                                                         â”‚    â”‚
â”‚  â”‚   Screenshot: Message typed                                                             â”‚    â”‚
â”‚  â”‚   Model output: "CLICK(1000, 2300)"  # Click send button                               â”‚    â”‚
â”‚  â”‚   Execute: adb shell input tap 1000 2300                                                â”‚    â”‚
â”‚  â”‚                                                                                         â”‚    â”‚
â”‚  â”‚   Model output: "DONE"  # Task completed!                                               â”‚    â”‚
â”‚  â”‚                                                                                         â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Device-Cloud Collaboration

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        DEVICE-CLOUD COLLABORATION                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                                 â”‚
â”‚  PROBLEM: Large models (8B+) can't run on-device (phone, tablet)                                â”‚
â”‚  SOLUTION: Route tasks based on complexity                                                      â”‚
â”‚                                                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚                 â”‚                    â”‚                   CLOUD                          â”‚    â”‚
â”‚  â”‚  ğŸ“± DEVICE      â”‚                    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚    â”‚
â”‚  â”‚                 â”‚                    â”‚  â”‚ MAI-UI-8B/32B/235B                          â”‚â”‚    â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚    Complex task    â”‚  â”‚ Running on H100/B200                        â”‚â”‚    â”‚
â”‚  â”‚  â”‚ MAI-UI-2B â”‚  â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º â”‚  â”‚                                             â”‚â”‚    â”‚
â”‚  â”‚  â”‚ (on-device)â”‚ â”‚                    â”‚  â”‚ â€¢ High accuracy                             â”‚â”‚    â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚                    â”‚  â”‚ â€¢ Complex UI understanding                  â”‚â”‚    â”‚
â”‚  â”‚       â”‚         â”‚                    â”‚  â”‚ â€¢ Multi-step planning                       â”‚â”‚    â”‚
â”‚  â”‚       â”‚         â”‚                    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚    â”‚
â”‚  â”‚  Simple task    â”‚                    â”‚                                                  â”‚    â”‚
â”‚  â”‚       â”‚         â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚  â”‚       â–¼         â”‚                                                                           â”‚
â”‚  â”‚  Execute        â”‚                                                                           â”‚
â”‚  â”‚  locally        â”‚                                                                           â”‚
â”‚  â”‚                 â”‚                                                                           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                                                           â”‚
â”‚                                                                                                 â”‚
â”‚  ROUTING LOGIC:                                                                                 â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                                                                 â”‚
â”‚                                                                                                 â”‚
â”‚  def route_task(task, screenshot):                                                              â”‚
â”‚      complexity = estimate_complexity(task)  # NLP classifier                                  â”‚
â”‚                                                                                                 â”‚
â”‚      if complexity == "simple":  # e.g., "Click the back button"                               â”‚
â”‚          return device_model.predict(screenshot)  # Fast, private                              â”‚
â”‚      else:  # e.g., "Book a flight to Tokyo for next week"                                     â”‚
â”‚          return cloud_model.predict(screenshot)   # Accurate, powerful                         â”‚
â”‚                                                                                                 â”‚
â”‚  BENEFITS:                                                                                      â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                                                      â”‚
â”‚  â€¢ Privacy: Simple actions stay on-device (no data sent to cloud)                              â”‚
â”‚  â€¢ Latency: Simple actions are instant (~100ms on-device vs ~500ms cloud)                      â”‚
â”‚  â€¢ Accuracy: Complex tasks get the best model (8B+ parameters)                                 â”‚
â”‚  â€¢ Cost: Only pay for cloud compute when needed                                                â”‚
â”‚                                                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### MAI-UI Memory Requirements

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        MAI-UI MEMORY REQUIREMENTS BY GPU                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                                 â”‚
â”‚  Model             â”‚ Weights  â”‚ KV Cache â”‚ Vision  â”‚ Total    â”‚ GPU Required                   â”‚
â”‚                    â”‚          â”‚ (2K ctx) â”‚ Encoder â”‚          â”‚                                â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• â”‚
â”‚  MAI-UI-2B         â”‚ ~4.5 GB  â”‚ ~1 GB    â”‚ ~2 GB   â”‚ ~8 GB    â”‚ T4 (16GB) âœ…                   â”‚
â”‚  MAI-UI-2B (4-bit) â”‚ ~1.5 GB  â”‚ ~1 GB    â”‚ ~2 GB   â”‚ ~5 GB    â”‚ T4 (16GB) âœ…âœ…                 â”‚
â”‚  MAI-UI-8B         â”‚ ~17 GB   â”‚ ~3 GB    â”‚ ~4 GB   â”‚ ~25 GB   â”‚ A100-40GB âœ…                   â”‚
â”‚  MAI-UI-8B (FP8)   â”‚ ~9 GB    â”‚ ~2 GB    â”‚ ~4 GB   â”‚ ~15 GB   â”‚ T4 âŒ, H100 âœ…                 â”‚
â”‚  MAI-UI-32B        â”‚ ~65 GB   â”‚ ~10 GB   â”‚ ~6 GB   â”‚ ~82 GB   â”‚ H100-80GB âš ï¸ tight             â”‚
â”‚  MAI-UI-235B-A22B  â”‚ ~50 GB*  â”‚ ~8 GB    â”‚ ~6 GB   â”‚ ~65 GB   â”‚ H100-80GB âœ… (MoE sparse)      â”‚
â”‚                    â”‚ *active  â”‚          â”‚         â”‚          â”‚                                â”‚
â”‚                                                                                                 â”‚
â”‚  LATENCY EXPECTATIONS:                                                                          â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                                                          â”‚
â”‚  T4 + MAI-UI-2B (4-bit): ~1.5-2s per action                                                    â”‚
â”‚  A100 + MAI-UI-8B:       ~300-500ms per action                                                 â”‚
â”‚  H100 + MAI-UI-8B (FP8): ~150-300ms per action                                                 â”‚
â”‚  B200 + MAI-UI-235B:     ~200-400ms per action                                                 â”‚
â”‚                                                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Complete Code Examples

### GPU-Specific Configurations

```python
from vllm import LLM, SamplingParams

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# T4 (16GB) - 4-bit Quantization
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def create_qwen3_vl_t4():
    """
    Qwen3-VL-4B on T4 with 4-bit quantization.
    
    Memory: ~4 GB weights + ~2 GB KV cache + ~2 GB vision = ~8 GB used
    Latency: ~1-1.5s per image
    """
    return LLM(
        model="Qwen/Qwen3-VL-4B-Instruct",
        trust_remote_code=True,
        dtype="half",                        # FP16 (T4 doesn't support BF16)
        quantization="bitsandbytes",         # 4-bit quantization
        load_format="bitsandbytes",
        gpu_memory_utilization=0.92,
        max_model_len=4096,
        enforce_eager=True,                  # Save memory by disabling CUDA graphs
        max_num_seqs=4,
        limit_mm_per_prompt={"image": 2, "video": 1},
        mm_processor_kwargs={
            "min_pixels": 784,
            "max_pixels": 500000,            # ~700Ã—700 max resolution
            "video_pruning_rate": 0.5,       # Keep 50% of video frames
        },
    )

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# A100-80GB - Full Precision
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def create_qwen3_vl_a100():
    """
    Qwen3-VL-8B on A100 with full BF16 precision.
    
    Memory: ~16 GB weights + ~8 GB KV cache + ~4 GB vision = ~28 GB used
    Latency: ~300-500ms per image
    """
    return LLM(
        model="Qwen/Qwen3-VL-8B-Instruct",
        trust_remote_code=True,
        dtype="bfloat16",
        gpu_memory_utilization=0.95,
        max_model_len=16384,
        enforce_eager=False,                 # Enable CUDA graphs for speed
        max_num_seqs=16,
        limit_mm_per_prompt={"image": 8, "video": 2},
        mm_processor_kwargs={
            "min_pixels": 784,
            "max_pixels": 2073600,           # 1920Ã—1080 full HD
            "video_pruning_rate": 0.3,
        },
        enable_prefix_caching=True,
        enable_chunked_prefill=True,
    )

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# H100 (80GB) - FP8 for Maximum Throughput
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def create_qwen3_vl_h100():
    """
    Qwen3-VL-8B on H100 with FP8 quantization.
    
    Memory: ~8 GB weights + ~8 GB KV cache + ~4 GB vision = ~20 GB used
    Latency: ~150-300ms per image
    """
    return LLM(
        model="Qwen/Qwen3-VL-8B-Instruct",
        trust_remote_code=True,
        dtype="bfloat16",
        quantization="fp8",                  # FP8 weights (2x smaller)
        kv_cache_dtype="fp8",                # FP8 KV cache
        gpu_memory_utilization=0.95,
        max_model_len=32768,
        enforce_eager=False,
        max_num_seqs=32,                     # High concurrency
        limit_mm_per_prompt={"image": 16, "video": 4},
        mm_processor_kwargs={
            "min_pixels": 784,
            "max_pixels": 2073600,
            "video_pruning_rate": 0.3,
        },
        enable_prefix_caching=True,
        enable_chunked_prefill=True,
    )

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# B200 (192GB) - Maximum Everything
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def create_qwen3_vl_b200():
    """
    Qwen3-VL-30B-A3B MoE on B200.
    
    Memory: ~60 GB weights + ~20 GB KV cache + ~6 GB vision = ~86 GB used
    Latency: ~200-400ms per image (MoE overhead)
    """
    return LLM(
        model="Qwen/Qwen3-VL-30B-A3B-Instruct",
        trust_remote_code=True,
        dtype="bfloat16",
        gpu_memory_utilization=0.95,
        max_model_len=65536,                 # 64K context
        enforce_eager=False,
        max_num_seqs=64,
        limit_mm_per_prompt={"image": 32, "video": 8},
        mm_processor_kwargs={
            "min_pixels": 784,
            "max_pixels": 4147200,           # 4K resolution
            "video_pruning_rate": 0.2,
        },
        enable_prefix_caching=True,
        enable_chunked_prefill=True,
    )
```

### GUI Agent Inference Example

```python
from vllm import SamplingParams

def run_gui_agent_step(llm, screenshot_path: str, task: str, history: list[str]):
    """
    Execute one step of GUI agent reasoning.
    
    Args:
        llm: vLLM model instance
        screenshot_path: Path to current screenshot
        task: User's task description
        history: List of previous actions taken
        
    Returns:
        Action string like "CLICK(542, 1203)" or "TYPE('Hello!')"
    """
    
    prompt = f"""<|im_start|>system
You are a GUI agent. Given a screenshot and task, output the next action.
Available actions:
- CLICK(x, y): Click at coordinates
- TYPE("text"): Type text
- SCROLL(x1, y1, x2, y2): Scroll from start to end
- PRESS_KEY(key): Press key (back, home, enter)
- DONE: Task is complete
<|im_end|>
<|im_start|>user
<|vision_start|><|image_pad|><|vision_end|>

Task: {task}
Previous actions: {history if history else 'None'}

What is the next action?
<|im_end|>
<|im_start|>assistant
"""
    
    inputs = [{
        "prompt": prompt,
        "multi_modal_data": {"image": screenshot_path}
    }]
    
    sampling_params = SamplingParams(
        temperature=0.0,      # Deterministic for GUI tasks
        max_tokens=50,
        stop=["<|im_end|>"]
    )
    
    outputs = llm.generate(inputs, sampling_params)
    return outputs[0].outputs[0].text.strip()


# Example usage
if __name__ == "__main__":
    import torch
    
    # Auto-select GPU configuration
    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9
    
    if gpu_memory < 20:
        llm = create_qwen3_vl_t4()
    elif gpu_memory < 50:
        llm = create_qwen3_vl_a100()
    else:
        llm = create_qwen3_vl_h100()
    
    # Run agent loop
    task = "Open Settings and enable Dark Mode"
    history = []
    
    for step in range(10):
        screenshot = f"screenshot_{step}.png"
        action = run_gui_agent_step(llm, screenshot, task, history)
        
        print(f"Step {step + 1}: {action}")
        
        if action == "DONE":
            print("Task completed!")
            break
            
        history.append(action)
```

---

## Summary: Key Differences at a Glance

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              FINAL COMPARISON TABLE                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ Feature            â”‚ Qwen2-VL                â”‚ Qwen3-VL                                â”‚    â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”‚
â”‚  â”‚ Release            â”‚ 2024                    â”‚ 2025                                    â”‚    â”‚
â”‚  â”‚ LLM Backbone       â”‚ Qwen2                   â”‚ Qwen3                                   â”‚    â”‚
â”‚  â”‚ Vision Encoder     â”‚ 32 layers, QuickGELU    â”‚ 32 layers, SiLU                         â”‚    â”‚
â”‚  â”‚ Patch Embedding    â”‚ Conv3D, no bias         â”‚ Conv3D, with bias                       â”‚    â”‚
â”‚  â”‚ Position Encoding  â”‚ 3D RoPE                 â”‚ Learned + RoPE + Interpolation          â”‚    â”‚
â”‚  â”‚ RoPE Application   â”‚ 100% of dims            â”‚ 50% of dims (partial_rotary_factor)     â”‚    â”‚
â”‚  â”‚ MLP Bias           â”‚ Has bias                â”‚ No bias                                 â”‚    â”‚
â”‚  â”‚ Multi-Scale        â”‚ âŒ                      â”‚ âœ… DeepStack                            â”‚    â”‚
â”‚  â”‚ Video Pruning      â”‚ âŒ                      â”‚ âœ… EVS                                  â”‚    â”‚
â”‚  â”‚ Max Video Frames   â”‚ 14                      â”‚ 24,576                                  â”‚    â”‚
â”‚  â”‚ Eagle3 Speculative â”‚ âŒ                      â”‚ âœ…                                      â”‚    â”‚
â”‚  â”‚ MoE Variants       â”‚ âŒ                      â”‚ âœ… Qwen3-VL-30B-A3B                     â”‚    â”‚
â”‚  â”‚ Best for T4        â”‚ 2B model (full prec)    â”‚ 4B model (4-bit + EVS)                  â”‚    â”‚
â”‚  â”‚ Best for H100      â”‚ 7B model                â”‚ 8B or 30B-A3B (MoE)                     â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                                                 â”‚
â”‚  WHEN TO USE WHICH:                                                                             â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                                                             â”‚
â”‚                                                                                                 â”‚
â”‚  Choose Qwen2-VL if:                                                                            â”‚
â”‚  â€¢ You have a T4 and want simplest setup                                                        â”‚
â”‚  â€¢ You don't process videos                                                                     â”‚
â”‚  â€¢ You need Xformers attention backend                                                          â”‚
â”‚  â€¢ You have existing Qwen2-VL fine-tuned weights                                               â”‚
â”‚                                                                                                 â”‚
â”‚  Choose Qwen3-VL if:                                                                            â”‚
â”‚  â€¢ You need better fine-grained visual understanding (DeepStack)                                â”‚
â”‚  â€¢ You process videos (EVS dramatically reduces token count)                                    â”‚
â”‚  â€¢ You want faster inference with Eagle3 speculative decoding                                   â”‚
â”‚  â€¢ You have A100+ and want best quality                                                         â”‚
â”‚  â€¢ You're building GUI agents (MAI-UI is based on Qwen3-VL)                                    â”‚
â”‚                                                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Key Takeaways

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                  KEY TAKEAWAYS                                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                                 â”‚
â”‚  1. ARCHITECTURE EVOLUTION                                                                      â”‚
â”‚     â€¢ Qwen3-VL adds DeepStack (multi-scale features) for better fine-grained detection         â”‚
â”‚     â€¢ Qwen3-VL adds EVS for efficient video processing (50%+ token reduction)                  â”‚
â”‚     â€¢ Qwen3-VL uses learned position embeddings with interpolation (better variable res)       â”‚
â”‚     â€¢ Qwen3-VL changes activation from QuickGELU to SiLU                                       â”‚
â”‚                                                                                                 â”‚
â”‚  2. GPU OPTIMIZATION                                                                            â”‚
â”‚     â€¢ T4: Use 4-bit quantization, FP16, enforce_eager=True, max_model_len=4096                 â”‚
â”‚     â€¢ A100: Use BF16, FlashAttention 2, enable_prefix_caching, max_model_len=32768             â”‚
â”‚     â€¢ H100: Use FP8 quantization + FP8 KV cache for 2x throughput                              â”‚
â”‚     â€¢ B200: Can run 72B dense or 235B MoE models on single GPU                                 â”‚
â”‚                                                                                                 â”‚
â”‚  3. VLLM CONFIGURATION                                                                          â”‚
â”‚     â€¢ max_pixels: Controls image resolution (500K for T4, 2M for A100+)                        â”‚
â”‚     â€¢ max_model_len: Controls context length (affects KV cache memory)                         â”‚
â”‚     â€¢ max_num_seqs: Controls concurrent requests (affects throughput)                          â”‚
â”‚     â€¢ video_pruning_rate: Qwen3-VL only, 0.3-0.5 recommended for videos                        â”‚
â”‚                                                                                                 â”‚
â”‚  4. MAI-UI GUI AGENTS                                                                           â”‚
â”‚     â€¢ Uses Qwen3-VL backbone with DeepStack for small UI element detection                     â”‚
â”‚     â€¢ Trained with GRPO (Group Relative Policy Optimization)                                   â”‚
â”‚     â€¢ SOTA results: 76.7% AndroidWorld, 73.5% ScreenSpot-Pro                                   â”‚
â”‚     â€¢ Supports device-cloud collaboration for privacy + accuracy                               â”‚
â”‚                                                                                                 â”‚
â”‚  5. PRACTICAL DEPLOYMENT                                                                        â”‚
â”‚     â€¢ Start with smaller models and quantization on limited GPUs                               â”‚
â”‚     â€¢ Use prefix caching for repeated system prompts                                           â”‚
â”‚     â€¢ Use chunked prefill for mixed short/long requests                                        â”‚
â”‚     â€¢ Monitor memory with gpu_memory_utilization=0.9 first                                     â”‚
â”‚                                                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## References

- [Qwen2-VL Paper](https://arxiv.org/abs/2409.12191)
- [Qwen3-VL (2025 successor to Qwen2-VL)]
- [MAI-UI Paper (arXiv:2512.22047)](https://arxiv.org/abs/2512.22047)
- [MAI-UI Project Page](https://tongyi-mai.github.io/MAI-UI/)
- [MAI-UI GitHub](https://github.com/Tongyi-MAI/MAI-UI)
- [GRPO for GUI Grounding (HuggingFace Blog)](https://huggingface.co/blog/HelloKKMe/grounding-r1)
- [vLLM Documentation](https://docs.vllm.ai/)
- [vLLM Vision-Language Models](https://docs.vllm.ai/en/latest/models/vlm.html)
- [vLLM Qwen3-VL Support](https://github.com/vllm-project/vllm) - `Qwen3VLForConditionalGeneration` in model registry

