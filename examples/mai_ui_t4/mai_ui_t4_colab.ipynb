{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ðŸ–¥ï¸ MAI-UI on T4: Optimized GUI Agent with vLLM\n",
        "\n",
        "This notebook runs MAI-UI on Google Colab's free T4 GPU with optimized vLLM settings.\n",
        "\n",
        "**Requirements:** Google Colab with T4 GPU (free tier works!)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 1: Check GPU and Install Dependencies\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"ðŸ” GPU DETECTION\")\n",
        "print(\"=\" * 60)\n",
        "!nvidia-smi --query-gpu=name,memory.total,compute_cap --format=csv\n",
        "\n",
        "import torch\n",
        "if torch.cuda.is_available():\n",
        "    gpu_name = torch.cuda.get_device_name(0)\n",
        "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / (1024**3)\n",
        "    print(f\"\\nâœ… GPU: {gpu_name}\")\n",
        "    print(f\"âœ… Memory: {gpu_memory:.1f} GB\")\n",
        "else:\n",
        "    print(\"âŒ No GPU! Enable in Runtime -> Change runtime type\")\n",
        "    sys.exit(1)\n",
        "\n",
        "# Install dependencies\n",
        "print(\"\\nðŸ“¦ Installing dependencies...\")\n",
        "%pip install -q vllm>=0.6.0 pillow requests jinja2\n",
        "print(\"âœ… Dependencies installed!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 2: Initialize vLLM with T4-Optimized Config\n",
        "from vllm import LLM, SamplingParams\n",
        "import time\n",
        "\n",
        "T4_CONFIG = {\n",
        "    \"model\": \"Tongyi-MAI/MAI-UI-2B\",\n",
        "    \"trust_remote_code\": True,\n",
        "    \"dtype\": \"half\",\n",
        "    \"max_model_len\": 2048,\n",
        "    \"gpu_memory_utilization\": 0.90,\n",
        "    \"enforce_eager\": True,\n",
        "    \"max_num_seqs\": 4,\n",
        "    \"limit_mm_per_prompt\": {\"image\": 1, \"video\": 0},\n",
        "    \"mm_processor_kwargs\": {\"min_pixels\": 784, \"max_pixels\": 512000},\n",
        "}\n",
        "\n",
        "print(\"ðŸš€ Initializing vLLM (downloading ~4GB model)...\")\n",
        "init_start = time.time()\n",
        "llm = LLM(**T4_CONFIG)\n",
        "print(f\"âœ… Engine initialized in {time.time() - init_start:.1f}s\")\n",
        "\n",
        "# Memory check\n",
        "allocated = torch.cuda.memory_allocated() / (1024**3)\n",
        "print(f\"ðŸ“Š GPU Memory: {allocated:.2f} GB used\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 3: Define MAI-UI Prompt Format\n",
        "import re\n",
        "import json\n",
        "\n",
        "MAI_GROUNDING_PROMPT = \"\"\"You are a GUI grounding agent. Given a screenshot and instruction, locate the UI element.\n",
        "Output: <grounding_think>[reasoning]</grounding_think><answer>{\"coordinate\": [x, y]}</answer>\n",
        "Coordinates: [0, 999] range where (0,0)=top-left.\"\"\"\n",
        "\n",
        "def build_prompt(instruction):\n",
        "    return (f\"<|im_start|>system\\n{MAI_GROUNDING_PROMPT}<|im_end|>\\n\"\n",
        "            f\"<|im_start|>user\\n<|vision_start|><|image_pad|><|vision_end|>{instruction}<|im_end|>\\n\"\n",
        "            \"<|im_start|>assistant\\n\")\n",
        "\n",
        "def parse_response(text):\n",
        "    result = {\"thinking\": None, \"coordinate\": None, \"raw\": text}\n",
        "    think = re.search(r\"<grounding_think>(.*?)</grounding_think>\", text, re.DOTALL)\n",
        "    if think: result[\"thinking\"] = think.group(1).strip()\n",
        "    answer = re.search(r\"<answer>(.*?)</answer>\", text, re.DOTALL)\n",
        "    if answer:\n",
        "        try:\n",
        "            data = json.loads(answer.group(1).strip())\n",
        "            if \"coordinate\" in data:\n",
        "                result[\"coordinate\"] = [data[\"coordinate\"][0]/999, data[\"coordinate\"][1]/999]\n",
        "        except: pass\n",
        "    return result\n",
        "\n",
        "print(\"âœ… Prompt functions defined\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 4: Create Test Screenshot\n",
        "from PIL import Image, ImageDraw\n",
        "\n",
        "def create_test_image():\n",
        "    img = Image.new('RGB', (1080, 1920), '#f5f5f5')\n",
        "    draw = ImageDraw.Draw(img)\n",
        "    draw.rectangle([0, 0, 1080, 80], fill='#1976D2')\n",
        "    draw.text((40, 30), \"9:41\", fill='white')\n",
        "    draw.rectangle([0, 80, 1080, 200], fill='#2196F3')\n",
        "    draw.text((40, 120), \"Settings\", fill='white')\n",
        "    for label, y in [(\"Wi-Fi\", 280), (\"Bluetooth\", 400), (\"Cellular\", 520)]:\n",
        "        draw.rectangle([0, y, 1080, y+100], fill='white', outline='#e0e0e0')\n",
        "        draw.text((40, y+35), label, fill='#333')\n",
        "        draw.ellipse([960, y+30, 1020, y+70], fill='#4CAF50')\n",
        "    draw.rectangle([0, 1800, 1080, 1920], fill='white')\n",
        "    for i, label in enumerate([\"Home\", \"Search\", \"Settings\", \"Profile\"]):\n",
        "        draw.text((60 + i*270, 1840), label, fill='#666')\n",
        "    return img\n",
        "\n",
        "test_image = create_test_image()\n",
        "print(f\"ðŸ“¸ Created test image: {test_image.size}\")\n",
        "\n",
        "# Display\n",
        "thumb = test_image.copy()\n",
        "thumb.thumbnail((250, 400))\n",
        "display(thumb)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 5: Run MAI-UI Grounding Inference\n",
        "sampling_params = SamplingParams(temperature=0.0, max_tokens=512, stop=[\"<|im_end|>\"])\n",
        "\n",
        "instructions = [\"Click on Wi-Fi\", \"Click on Bluetooth\", \"Click on Settings\", \"Click on Home\"]\n",
        "results = []\n",
        "\n",
        "print(\"ðŸ¤– Running inference...\")\n",
        "for i, inst in enumerate(instructions, 1):\n",
        "    prompt = build_prompt(inst)\n",
        "    inputs = {\"prompt\": prompt, \"multi_modal_data\": {\"image\": test_image}}\n",
        "    \n",
        "    start = time.time()\n",
        "    outputs = llm.generate([inputs], sampling_params=sampling_params)\n",
        "    latency = (time.time() - start) * 1000\n",
        "    \n",
        "    parsed = parse_response(outputs[0].outputs[0].text)\n",
        "    results.append({\"instruction\": inst, \"latency_ms\": latency, \"parsed\": parsed})\n",
        "    \n",
        "    if parsed[\"coordinate\"]:\n",
        "        x, y = parsed[\"coordinate\"]\n",
        "        print(f\"[{i}] {inst}: ({x:.3f}, {y:.3f}) - {latency:.0f}ms\")\n",
        "    else:\n",
        "        print(f\"[{i}] {inst}: No coordinate - {latency:.0f}ms\")\n",
        "\n",
        "print(\"âœ… Inference complete!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 6: Visualize Results\n",
        "def visualize_clicks(image, results):\n",
        "    img = image.copy()\n",
        "    draw = ImageDraw.Draw(img)\n",
        "    colors = ['#FF0000', '#00FF00', '#0000FF', '#FF00FF']\n",
        "    for i, r in enumerate(results):\n",
        "        coord = r[\"parsed\"].get(\"coordinate\")\n",
        "        if coord:\n",
        "            x, y = int(coord[0] * image.width), int(coord[1] * image.height)\n",
        "            draw.ellipse([x-25, y-25, x+25, y+25], outline=colors[i], width=4)\n",
        "            draw.line([x-35, y, x+35, y], fill=colors[i], width=3)\n",
        "            draw.line([x, y-35, x, y+35], fill=colors[i], width=3)\n",
        "    return img\n",
        "\n",
        "vis = visualize_clicks(test_image, results)\n",
        "vis_thumb = vis.copy()\n",
        "vis_thumb.thumbnail((300, 500))\n",
        "display(vis_thumb)\n",
        "\n",
        "print(\"\\nðŸ“Š Summary:\")\n",
        "for i, r in enumerate(results, 1):\n",
        "    coord = r[\"parsed\"].get(\"coordinate\", \"N/A\")\n",
        "    print(f\"  [{i}] {r['instruction']}: {coord}\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
